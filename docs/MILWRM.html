<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>MILWRM.MILWRM API documentation</title>
<meta name="description" content="Classes for assigning tissue domain IDs to multiplex immunofluorescence (MxIF) or 10X
Visium spatial transcriptomic (ST) and histological imaging data" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>MILWRM.MILWRM</code></h1>
</header>
<section id="section-intro">
<p>Classes for assigning tissue domain IDs to multiplex immunofluorescence (MxIF) or 10X
Visium spatial transcriptomic (ST) and histological imaging data</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Classes for assigning tissue domain IDs to multiplex immunofluorescence (MxIF) or 10X 
Visium spatial transcriptomic (ST) and histological imaging data
&#34;&#34;&#34;
import os
from tkinter import E
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import itertools
import seaborn as sns
import umap

sns.set_style(&#34;white&#34;)

from math import ceil
from joblib import Parallel, delayed
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from .MxIF import checktype, img
from .ST import assemble_pita
from .ST import blur_features_st


def kMeansRes(scaled_data, k, alpha_k=0.02, random_state=18):
    &#34;&#34;&#34;
    Calculates inertia value for a given k value by fitting k-means model to scaled data

    Adapted from
    https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c

    Parameters
    ----------
    scaled_data: np.array
        Scaled data. Rows are samples and columns are features for clustering
    k: int
        Current k for applying KMeans
    alpha_k: float
        Manually tuned factor that gives penalty to the number of clusters

    Returns
    -------
    scaled_inertia: float
        Scaled inertia value for current k
    &#34;&#34;&#34;
    inertia_o = np.square((scaled_data - scaled_data.mean(axis=0))).sum()
    # fit k-means
    kmeans = KMeans(n_clusters=k, random_state=random_state).fit(scaled_data)
    scaled_inertia = kmeans.inertia_ / inertia_o + alpha_k * k
    return scaled_inertia


def chooseBestKforKMeansParallel(scaled_data, k_range, n_jobs=-1, **kwargs):
    &#34;&#34;&#34;
    Determines optimal k value by fitting k-means models to scaled data and minimizing
    scaled inertia

    Adapted from
    https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c

    Parameters
    ----------
    scaled_data: np.array
        Scaled data. Rows are samples and columns are features for clustering.
    k_range: list of int
        k range for applying KMeans
    n_jobs : int
        Number of cores to parallelize k-choosing across
    **kwargs
        Arguments to pass to `kMeansRes()` (i.e. `alpha_k`, `random_state`)

    Returns
    -------
    best_k: int
        Chosen value of k out of the given k range. Chosen k is k with the minimum
        scaled inertia value.
    results: pd.DataFrame
        Adjusted inertia value for each k in k_range
    &#34;&#34;&#34;
    ans = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(kMeansRes)(scaled_data, k, **kwargs) for k in k_range
    )
    ans = list(zip(k_range, ans))
    results = pd.DataFrame(ans, columns=[&#34;k&#34;, &#34;Scaled Inertia&#34;]).set_index(&#34;k&#34;)
    best_k = results.idxmin()[0]
    return best_k, results


def prep_data_single_sample_st(
    adata,
    adata_i,
    use_rep,
    features,
    histo,
    fluor_channels,
    spatial_graph_key=None,
    n_rings=1,
):
    &#34;&#34;&#34;
    Prepare dataframe for tissue-level clustering from a single AnnData sample

    Parameters
    ----------
    adata : anndata.AnnData
        AnnData object containing Visium data
    adata_i : int
        Index of AnnData object for identification within `st_labeler` object
    use_rep : str
        Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
    features : list of int or None, optional (default=`None`)
        List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
        use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
        all features from `adata.obsm[use_rep]`
    histo : bool, optional (default `False`)
        Use histology data from Visium anndata object (R,G,B brightfield features)
        in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
        than brightfield, use `fluor_channels` argument instead.
    fluor_channels : list of int or None, optional (default `None`)
        Channels from fluorescent image to use for model training (e.g. [1,3] for
        channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
        use imaging data for training.
    spatial_graph_key : str, optional (default=`None`)
        Key in `adata.obsp` containing spatial graph connectivities (i.e.
        `&#34;spatial_connectivities&#34;`). If `None`, compute new spatial graph using
        `n_rings` in `squidpy`.
    n_rings : int, optional (default=1)
        Number of hexagonal rings around each spatial transcriptomics spot to blur
        features by for capturing regional information. Assumes 10X Genomics Visium
        platform.

    Returns
    -------
    pd.DataFrame
        Clustering data from `adata.obsm[use_rep]`
    &#34;&#34;&#34;
    tmp = pd.DataFrame()
    tmp[[use_rep + &#34;_{}&#34;.format(x) for x in features]] = adata.obsm[use_rep][
        :, features
    ]
    if histo:
        assert (
            fluor_channels is None
        ), &#34;If histo is True, fluor_channels must be None. \
            Histology specifies brightfield H&amp;E with three (3) features.&#34;
        print(&#34;Adding mean RGB histology features for adata #{}&#34;.format(adata_i))
        tmp[[&#34;R_mean&#34;, &#34;G_mean&#34;, &#34;B_mean&#34;]] = adata.obsm[&#34;image_means&#34;]
    if fluor_channels:
        assert (
            histo is False
        ), &#34;If fluorescence channels are given, histo must be False. \
            Histology specifies brightfield H&amp;E with three (3) features.&#34;
        print(
            &#34;Adding mean fluorescent channels {} for adata #{}&#34;.format(
                fluor_channels, adata_i
            )
        )
        tmp[[&#34;ch_{}_mean&#34;.format(x) for x in fluor_channels]] = adata.obsm[
            &#34;image_means&#34;
        ][:, fluor_channels]
    if n_rings &gt; 0:
        # blur the features extracted in tmp
        tmp = blur_features_st(
            adata, tmp, spatial_graph_key=spatial_graph_key, n_rings=n_rings
        )
    return tmp


def prep_data_single_sample_mxif(
    image, use_path, mean, filter_name, sigma, features, fract, path_save
):
    &#34;&#34;&#34;
    Perform log normalization, and blurring on the given image data

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    mean : numpy array
        Containing mean for each channel for that batch
    filter_name : str
        Name of the filter to use - gaussian, median or bilateral
    sigma : float, optional
        Standard deviation of Gaussian kernel for blurring
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    fract : float, optional
        Fraction of cluster data from each image to randomly select for model
        building
    path_save : str
        Path to save final preprocessed files
    Returns
    -------
    Subsampled_data : np.array
        np.array containing randomly sampled pixels for that image
    file_save : str
        path to save preprocessed img object
    &#34;&#34;&#34;
    if use_path == True:  # if images are given as path to the compressed npz file
        if path_save == None:  # check if path to save final processed file is given
            raise Exception(
                &#34;Path to save final preprocessed npz files is requird when given path to image files&#34;
            )
        image_path = image
        image = img.from_npz(image_path + &#34;.npz&#34;)
    # batch correction
    image.log_normalize(mean=mean)
    # apply the desired filter
    image.blurring(filter_name=filter_name, sigma=sigma)
    # min max scaling of each channel
    # for i in range(image.img.shape[2]):
    #     img_ar = image.img[:, :, i][image.mask != 0]
    #     img_ar_max = img_ar.max()
    #     img_ar_min = img_ar.min()
    #     # print(img_ar_max, img_ar_min)
    #     image_ar_scaled = (image.img[:, :, i] - img_ar_min) / (img_ar_max - img_ar_min)
    #     image.img[:, :, i] = image_ar_scaled
    # subsample pixels to build the kmeans model
    subsampled_data = image.subsample_pixels(features, fract)
    if use_path == True:
        new_image_path = os.path.join(path_save, &#34;_final_preprocessed_images&#34;)
        if not os.path.exists(new_image_path):
            os.mkdir(new_image_path)
        file_name = image_path.split(&#34;/&#34;)[-1] + &#34;_final_preprocessed&#34;
        file_save = os.path.join(new_image_path, file_name)
        image.to_npz(file_save)
        return subsampled_data, file_save
    return subsampled_data


def add_tissue_ID_single_sample_mxif(image, use_path, features, kmeans, scaler):
    &#34;&#34;&#34;
    Label pixels in a single MxIF sample with kmeans results

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    kmeans : sklearn.kmeans
        Trained k-means model

    Returns
    -------
    tID : np.array
        Image where pixel values are kmeans cluster IDs
    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    # subset to features used in prep_cluster_data
    tmp = image.img[:, :, features]
    w, h, d = tuple(tmp.shape)
    image_array = tmp.reshape((w * h, d))
    scaled_image_array = scaler.transform(image_array)
    tID = kmeans.predict(scaled_image_array).reshape(w, h)
    tID = tID.astype(float)  # TODO: Figure out dtypes
    tID[image.mask == 0] = np.nan  # set masked-out pixels to NaN
    return tID


def estimate_percentage_variance_mxif(
    image, use_path, scaler, centroids, features, tissue_ID
):
    &#34;&#34;&#34;
    Estimate percentage variance explained by clustering for an image

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    tissue_ID : np.ndarray
        numpy array containing kmeans labels on image

    Returns
    -------
    S_square_pct : float
        percentage variance in data explained by the kmeans clustering

    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    # getting the channels used for MILWRM clustering and scaling the image
    w, h, d = image.img[:, :, features].shape
    img_ar = image.img[:, :, features].reshape((w * h), d)
    scaled_img_ar = scaler.transform(img_ar)
    tissue_ID = tissue_ID.reshape(w * h)
    # init a numpy array of image shape to store the distance from pixels to centroids
    dc = np.zeros(scaled_img_ar.shape)
    for i in range(centroids.shape[0]):
        dc[tissue_ID == i] = ((scaled_img_ar[tissue_ID == i]) - (centroids[i])) ** 2
    # estimating the difference between pixels and the image mean
    dm = ((scaled_img_ar) - (scaled_img_ar.mean(axis=0))) ** 2
    # taking ratio of sum of differences for all points from centroids and data mean
    S_square = np.sum(dc) / np.sum(dm)
    S_square_pct = S_square * 100
    return S_square_pct


def perform_umap(cluster_data, centroids, batch_labels, kmeans_labels, frac):
    &#34;&#34;&#34;
    Compute umap coordinates for the given cluster_data

    Parameters
    ----------
    cluster_data : np.ndarray
        containing data used to build kmeans model
    centroids : np.ndarray
        kmeans cluster centroids
    batch_labels : list
        list containing batch label for each datapoint
    kmeans_label : list
        list containing tissue ID labels for each datapoint
    frac : None or float
        if None entire cluster_data is used to compute umap if float
        that fraction of data is used to compute the umap

    Returns
    -------
    umap_centroid_data : pd.DataFrame
        combined dataframe with cluster_data used for computation
        of Umap, centroids, batch_labels and kmeans_labels
    standard_embedding : pd.DataFrame
        containing umap coordinates
    &#34;&#34;&#34;
    df = pd.DataFrame(cluster_data, batch_labels)
    df[&#34;Kmeans_labels&#34;] = kmeans_labels
    # if cluster_data is too big randomly subsample a fraction of it otherwise use the
    # entire data
    if frac:
        umap_data = pd.DataFrame()
        for i in np.unique(batch_labels):
            umap_data = pd.concat([umap_data, df.loc[i].sample(frac=frac)])
    else:
        umap_data = df
    # append the centroids to the dataframe with a different index and kmeans labels
    centroids = pd.DataFrame(
        centroids, index=[umap_data.index[-1] + 1] * len(centroids)
    )
    centroids[&#34;Kmeans_labels&#34;] = [kmeans_labels.max() + 1] * len(centroids)
    umap_centroid_data = pd.concat([umap_data, centroids])
    # compute umap
    neighbours = int(len(umap_centroid_data) ** 0.5)
    mapper = umap.UMAP(random_state=42, n_neighbors=neighbours).fit(
        umap_centroid_data.loc[:, umap_centroid_data.columns != &#34;Kmeans_labels&#34;]
    )
    standard_embedding = mapper.transform(
        umap_centroid_data.loc[:, umap_centroid_data.columns != &#34;Kmeans_labels&#34;]
    )
    return umap_centroid_data, standard_embedding


def estimate_confidence_score_mxif(
    image, use_path, scaler, centroids, features, tissue_ID
):
    &#34;&#34;&#34;
    Estimate confidence score for the assigned tissue_IDs in MxIF slide by
    taking difference between distance to the second closest centroid and the
    assigned centroid divided by distance to the second closest centroid.

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    tissue_ID : np.ndarray
        numpy array containing kmeans labels on image

    Returns
    -------
    Conf_ID : np.ndarray
        overall confidence score for each pixel&#39;s cluster assignment
    mean_conf_score : dict
        mean confidence score for each tissue ID (keys for the dictionary)
    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    w, h, d = image.img[:, :, features].shape
    img_ar = image.img[:, :, features].reshape((w * h), d)
    scaled_img_ar = scaler.transform(img_ar)
    img_sc = scaled_img_ar.reshape((w, h, d))
    # initializing an empty numpy array to store distance to each centroid along axis = 2
    dist_ar = np.zeros((w, h, len(centroids)))
    for i, centroid in enumerate(centroids):
        dist = ((img_sc) - (centroid)) ** 2
        dist_cp = np.sum(dist, axis=2)
        dist_ar[:, :, i] = dist_ar[:, :, i] + dist_cp
    # sorting the numpy array according to distance from centroids
    new_dist_ar = np.sort(dist_ar, axis=2)
    # estimating new confidence score
    cID = ((new_dist_ar[:, :, 1]) - (new_dist_ar[:, :, 0])) / new_dist_ar[:, :, 1]
    cID[image.mask == 0] = np.nan
    # estimating average confidence score in that image
    mean_conf_score = {}
    for i in range(len(centroids)):
        mean_conf_score[i] = np.mean(cID[tissue_ID == i])
    return cID, mean_conf_score


def estimate_mse_mxif(images, use_path, tissue_IDs, scaler, centroids, features, k):
    &#34;&#34;&#34;
    Estimate mean square error for each tissue ID for each MxIF images

    Parameters
    ----------
    images : list
        list of MILWRM.MxIF.img objects or path to images (str)
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    tissue_IDs : list
        list of predicted tissue_ID for each image
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    k : int
        number of tissue domains

    Returns
    -------
    mse_id : dict
        containing mean square error for each tissue for each visium slide
    &#34;&#34;&#34;
    mse_temp = {}
    for image_index, image in enumerate(images):
        if use_path == True:
            image_path = image + &#34;.npz&#34;
            image = img.from_npz(image_path)
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        if isinstance(features, str):  # force features into int if single string
            features = [image.ch.index(features)]
        if checktype(features):  # force features into list of int if list of strings
            features = [image.ch.index(x) for x in features]
        if features is None:  # if no features are given, use all of them
            features = [x for x in range(image.n_ch)]
        # getting the channels used for MILWRM clustering and scaling the image
        img_ar = image.img[:, :, features]
        w, h, d = img_ar.shape
        scaled_img_ar = scaler.transform(img_ar.reshape((w * h, d)))
        scaled_img_ar = scaled_img_ar.reshape((w, h, d))
        ar = tissue_IDs[image_index]
        mse = {}
        for i in range(k):
            x = (
                (scaled_img_ar[ar == i]) - (centroids[i])
            ) ** 2  # estimating mse for each tissue ID for that image
            mse[i] = x.mean(axis=0)
        mse_temp[image_index] = mse
    mse_id = {}  # reorganizing within a new dictionary with keys as tissue IDs
    for i in range(k):
        mse_l = []
        for image_index, image in enumerate(images):
            mse_l.append(mse_temp[image_index][i])
            mse_id[i] = mse_l
    return mse_id


def estimate_percentage_variance_st(sub_cluster_data, adata, centroids):
    &#34;&#34;&#34;
    Estimate percentage variance explained by clustering for a visium slide

    Parameters
    ----------
    sub_cluster_data : np.ndarray
        np.ndarray containing data for that visium slide used for kmeans
    adata : anndata.AnnData
        AnnData object containing Visium data
    centroids : np.ndarray
        kmeans cluster centroids

    Returns
    -------
    S_square_pct : float
        percentage variance in data explained by the kmeans clustering

    &#34;&#34;&#34;
    dc = []
    df = pd.DataFrame(adata.obs[&#34;tissue_ID&#34;])
    ids = pd.unique(df[&#34;tissue_ID&#34;])
    df[&#34;index&#34;] = list(range(adata.n_obs))
    for i in ids:
        # estimating euclidean distance from the data point to closest centroid
        diff = (
            (sub_cluster_data[df[df[&#34;tissue_ID&#34;] == i][&#34;index&#34;]]) - (centroids[i])
        ) ** 2
        dc.append(diff)
    dc = np.row_stack(dc)
    # estimating euclidean distance from each data point to the mean of the data
    dm = (sub_cluster_data - sub_cluster_data.mean(axis=0)) ** 2
    # getting sum across features
    # taking ratio of sum of distances for all data points from centroids and data mean
    S = np.sum(dc) / np.sum(dm)
    S_square_pct = S * 100
    return S_square_pct


def estimate_confidence_score_st(sub_cluster_data, adata, centroids):
    &#34;&#34;&#34;
    Estimate confidence score for the assigned tissue_IDs in a visium slide by
    taking difference between distance to the second closest centroid and the
    assigned centroid divided by distance to the second closest centroid.

    Parameters
    ----------
    sub_cluster_data : np.ndarray
        np.ndarray containing data for that visium slide used for kmeans
    adata : anndata.AnnData
        AnnData object containing Visium data
    centroids : np.ndarray
        kmeans cluster centroids

    Returns
    -------
    Confidence_score added to adata.obs
    mean_conf_score : dict
        mean confidence score for each tissue ID (keys for the dictionary)
    &#34;&#34;&#34;
    # initializing zeros array to store distances
    dist_mx = np.zeros((sub_cluster_data.shape[0], len(centroids)))
    # calculating distance to each centroid
    for i, centroid in enumerate(centroids):
        dist_cp = ((sub_cluster_data) - (centroid)) ** 2
        dist = np.sum(dist_cp, axis=1)
        dist_mx[:, i] = dist_mx[:, i] + dist
    # sorting distances according to distance from centroids
    new_dist_ar = np.sort(dist_mx, axis=1)
    # using assigned and second closest centroid to estimate confidence score
    cID = ((new_dist_ar[:, 1]) - (new_dist_ar[:, 0])) / new_dist_ar[:, 1]
    adata.obs[&#34;confidence_score&#34;] = cID
    score_df = pd.DataFrame(cID, columns=[&#34;score&#34;])
    score_df[&#34;tissue_ID&#34;] = adata.obs[&#34;tissue_ID&#34;].values
    mean_conf_score = {}
    for i in range(len(centroids)):
        if (adata.obs[&#34;tissue_ID&#34;] == i).any():
            mean_conf_score[i] = score_df[score_df[&#34;tissue_ID&#34;] == i][&#34;score&#34;].mean()
        else:
            mean_conf_score[i] = np.nan
    return mean_conf_score


def estimate_mse_st(cluster_data, adatas, centroids, k):
    &#34;&#34;&#34;
    Estimate mean square error for each tissue ID for each visium slide

    Parameters
    ----------
    cluster_data : np.ndarray
        np.ndarray containing cluster_data used for kmeans
    adatas :  list
        list of anndata.AnnData objects for visium slides
    centroids : np.ndarray
        kmeans cluster centroids
    k : int
        number of tissue domains

    Returns
    -------
    mse_id : dict
        containing mean square error for each tissue for each visium slide
    &#34;&#34;&#34;
    mse_id = {}
    for i in range(k):
        i_slice = 0
        j_slice = 0
        diff = []
        for adata in adatas:
            j_slice = j_slice + adata.n_obs
            df = pd.DataFrame(adata.obs[&#34;tissue_ID&#34;])
            df[&#34;index&#34;] = list(range(adata.n_obs))
            data = cluster_data[
                i_slice:j_slice
            ]  # slicing cluster data for sub_cluster_data for that visium slide
            x = (
                (data[df[df[&#34;tissue_ID&#34;] == i][&#34;index&#34;]]) - (centroids[i])
            ) ** 2  # difference between each data point and centroids
            if len(x) == 0:
                diff.append(np.zeros((centroids.shape[1])))
            else:
                mse = x.mean(axis=0)  # mean of all the differences
                # diff.append(mse.mean(axis = 0))
                diff.append(mse)
            i_slice = adata.n_obs
        mse_id[i] = diff
    return mse_id


class tissue_labeler:
    &#34;&#34;&#34;
    Master tissue domain labeling class
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;
        Initialize tissue labeler parent class
        &#34;&#34;&#34;
        self.cluster_data = None  # start out with no data to cluster on
        self.k = None  # start out with no k value

    def find_optimal_k(self, plot_out=False, alpha=0.05, random_state=18, n_jobs=-1):
        &#34;&#34;&#34;
        Uses scaled inertia to decide on k clusters for clustering in the
        corresponding `anndata` objects

        Parameters
        ----------
        plot_out : boolean, optional (default=FALSE)
            Determines if scaled inertia graph should be output
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        random_state : int, optional (default=18)
            Seed for k-means clustering models
        n_jobs : int
            Number of cores to parallelize k-choosing across

        Returns
        -------
        Does not return anything. `self.k` contains integer value for number of
        clusters. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is None:
            raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
        self.random_state = random_state

        k_range = range(2, 21)  # choose k range
        # compute scaled inertia
        best_k, results = chooseBestKforKMeansParallel(
            self.cluster_data,
            k_range,
            n_jobs=n_jobs,
            random_state=random_state,
            alpha_k=alpha,
        )
        if plot_out:
            # plot the results
            plt.figure(figsize=(7, 4))
            plt.plot(results, &#34;o&#34;)
            plt.title(&#34;Adjusted Inertia for each K&#34;)
            plt.xlabel(&#34;K&#34;)
            plt.ylabel(&#34;Adjusted Inertia&#34;)
            plt.xticks(range(2, 21, 1))
            plt.show()
        # save optimal k to object
        print(&#34;The optimal number of clusters is {}&#34;.format(best_k))
        self.k = best_k

    def find_tissue_regions(self, k=None, random_state=18):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        `anndata` objects.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue domains to define
        random_state : int, optional (default=18)
            Seed for k-means clustering model.

        Returns
        -------
        Does not return anything. `self.kmeans` contains trained `sklearn` clustering
        model. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is None:
            raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
        if k is None and self.k is None:
            raise Exception(
                &#34;No k found or provided. Run find_optimal_k() first or pass a k value.&#34;
            )
        if k is not None:
            print(&#34;Overriding optimal k value with k={}.&#34;.format(k))
            self.k = k
        # save the hyperparams as object attributes
        self.random_state = random_state
        print(&#34;Performing k-means clustering with {} target clusters&#34;.format(self.k))
        self.kmeans = KMeans(n_clusters=self.k, random_state=random_state).fit(
            self.cluster_data
        )

    def plot_feature_proportions(self, labels=None, figsize=(10, 7), save_to=None):
        &#34;&#34;&#34;
        Plots contributions of each training feature to k-means cluster centers as
        percentages of total

        Parameters
        ----------
        labels : list of str, optional (default=`None`)
            Labels corresponding to each MILWRM training feature. If `None`, features
            will be numbered 0 through p.
        figsize : tuple of float, optional (default=(10,7))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `plt.figure` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        if &#34;st_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
                if self.histo:
                    labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
                if self.fluor_channels is not None:
                    labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
        elif &#34;mxif_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = self.model_features
        # create pandas df and calculate percentages of total
        ctr_df = pd.DataFrame(self.kmeans.cluster_centers_, columns=labels)
        totals = ctr_df.sum(axis=1)
        ctr_df_prop = ctr_df.div(totals, axis=0).multiply(100)
        # make plot
        fig, ax = plt.subplots(1, 1, figsize=figsize)
        ctr_df_prop.plot.bar(stacked=True, ax=ax, width=0.85)
        for p in ax.patches:
            ax.annotate(
                &#34;{} %&#34;.format(str(np.round(p.get_height(), 2))),
                (p.get_x() + 0.05, p.get_y() + (p.get_height() * 0.4)),
                fontsize=10,
            )
        plt.ylim([0, 100])
        plt.xlabel(&#34;tissue_ID&#34;)
        plt.xticks(rotation=0)
        plt.ylabel(&#34;% K-Means Loading&#34;)
        plt.legend(bbox_to_anchor=(1, 1), loc=&#34;upper left&#34;, title=&#34;Feature&#34;)
        plt.tight_layout()
        if save_to is not None:
            print(&#34;Saving feature proportions to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return fig

    def plot_feature_loadings(
        self,
        ncols=None,
        nfeatures=None,
        labels=None,
        titles=None,
        figsize=(5, 5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plots contributions of each training feature to k-means cluster centers

        Parameters
        ----------
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        nfeatures : int, optional (default=`None`)
            Number of top-loaded features to show for each tissue domain
        labels : list of str, optional (default=`None`)
            Labels corresponding to each MILWRM training feature. If `None`, features
            will be numbered 0 through p.
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        if &#34;st_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
                if self.histo:
                    labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
                if self.fluor_channels is not None:
                    labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
        elif &#34;mxif_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = self.model_features
        if titles is None:
            titles = [
                &#34;tissue_ID &#34; + str(x)
                for x in range(self.kmeans.cluster_centers_.shape[0])
            ]
        if nfeatures is None:
            nfeatures = len(labels)
        scores = self.kmeans.cluster_centers_.copy()
        n_panels = len(titles)
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            wspace=0.1,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for iscore, score in enumerate(scores):
            plt.subplot(gs[iscore])
            indices = np.argsort(score)[::-1][: nfeatures + 1]
            for ig, g in enumerate(indices[::-1]):
                plt.text(
                    x=score[g],
                    y=ig,
                    s=labels[g],
                    color=&#34;black&#34;,
                    verticalalignment=&#34;center&#34;,
                    horizontalalignment=&#34;right&#34;,
                    fontsize=&#34;medium&#34;,
                    fontstyle=&#34;italic&#34;,
                )
            plt.title(titles[iscore], fontsize=&#34;x-large&#34;)
            plt.ylim(-0.9, ig + 0.9)
            score_min, score_max = np.min(score[indices]), np.max(score[indices])
            plt.xlim(
                (0.95 if score_min &gt; 0 else 1.05) * score_min,
                (1.05 if score_max &gt; 0 else 0.95) * score_max,
            )
            plt.xticks(rotation=45)
            plt.tick_params(labelsize=&#34;medium&#34;)
            plt.tick_params(
                axis=&#34;y&#34;,  # changes apply to the y-axis
                which=&#34;both&#34;,  # both major and minor ticks are affected
                left=False,
                right=False,
                labelleft=False,
            )
            plt.grid(False)
        gs.tight_layout(fig)
        if save_to is not None:
            print(&#34;Saving feature loadings to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return gs


class st_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue domain labeling class for spatial transcriptomics (ST) data
    &#34;&#34;&#34;

    def __init__(self, adatas):
        &#34;&#34;&#34;
        Initialize ST tissue labeler class

        Parameters
        ----------
        adatas : list of anndata.AnnData
            Single anndata object or list of objects to label consensus tissue domains

        Returns
        -------
        Does not return anything. `self.adatas` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        if not isinstance(adatas, list):  # force single anndata object to list
            adatas = [adatas]
        print(&#34;Initiating ST labeler with {} anndata objects&#34;.format(len(adatas)))
        self.adatas = adatas
        self.raw = adatas.copy()

    def prep_cluster_data(
        self,
        use_rep,
        features=None,
        n_rings=1,
        histo=False,
        fluor_channels=None,
        spatial_graph_key=None,
        n_jobs=-1,
    ):
        &#34;&#34;&#34;
        Prepare master dataframe for tissue-level clustering

        Parameters
        ----------
        use_rep : str
            Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
        features : list of int or None, optional (default=`None`)
            List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
            use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
            all features from `adata.obsm[use_rep]`
        n_rings : int, optional (default=1)
            Number of hexagonal rings around each spatial transcriptomics spot to blur
            features by for capturing regional information. Assumes 10X Genomics Visium
            platform.
        histo : bool, optional (default `False`)
            Use histology data from Visium anndata object (R,G,B brightfield features)
            in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
            than brightfield, use `fluor_channels` argument instead.
        fluor_channels : list of int or None, optional (default `None`)
            Channels from fluorescent image to use for model training (e.g. [1,3] for
            channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
            use imaging data for training.
        spatial_graph_key : str, optional (default=`None`)
            Key in `adata.obsp` containing spatial graph connectivities (i.e.
            `&#34;spatial_connectivities&#34;`). If `None`, compute new spatial graph using
            `n_rings` in `squidpy`.
        n_jobs : int, optional (default=-1)
            Number of cores to parallelize over. Default all available cores.

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;blur_*&#34; features
        to `.obs` if `n_rings &gt; 0`.
        `self.cluster_data` becomes master `np.array` for cluster training.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        if features is None:
            self.features = [x for x in range(self.adatas[0].obsm[use_rep].shape[1])]
        else:
            self.features = features
        # save the hyperparams as object attributes
        self.rep = use_rep
        self.histo = histo
        self.fluor_channels = fluor_channels
        self.n_rings = n_rings
        # collect clustering data from self.adatas in parallel
        print(
            &#34;Collecting and blurring {} features from .obsm[{}]...&#34;.format(
                len(self.features),
                use_rep,
            )
        )
        cluster_data = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(prep_data_single_sample_st)(
                adata,
                adata_i,
                use_rep,
                self.features,
                histo,
                fluor_channels,
                spatial_graph_key,
                n_rings,
            )
            for adata_i, adata in enumerate(self.adatas)
        )
        batch_labels = [
            [x] * len(cluster_data[x]) for x in range(len(cluster_data))
        ]  # batch labels for umap
        self.merged_batch_labels = list(itertools.chain(*batch_labels))
        # concatenate blurred features into cluster_data df for cluster training
        subsampled_data = pd.concat(cluster_data)
        # perform z-scaling on final cluster data
        scaler = StandardScaler()
        self.scaler = scaler.fit(subsampled_data)
        scaled_data = scaler.transform(subsampled_data)
        self.cluster_data = scaled_data
        print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        `anndata` objects.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if scaled inertia plot should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model.
        n_jobs : int
            Number of cores to parallelize k-choosing across

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;tissue_ID&#34; field
        to `.obs`. `self.kmeans` contains trained `sklearn` clustering model.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                plot_out=plot_out, alpha=alpha, random_state=random_state, n_jobs=n_jobs
            )
        # call k-means model from parent class
        self.find_tissue_regions(k=k, random_state=random_state)
        # loop through anndata object and add tissue labels to adata.obs dataframe
        start = 0
        print(&#34;Adding tissue_ID label to anndata objects&#34;)
        for i in range(len(self.adatas)):
            IDs = self.kmeans.labels_
            self.adatas[i].obs[&#34;tissue_ID&#34;] = IDs[start : start + self.adatas[i].n_obs]
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].astype(&#34;category&#34;)
            )
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].cat.set_categories(np.unique(IDs))
            )
            start += self.adatas[i].n_obs

    def confidence_score(self):
        &#34;&#34;&#34;
        estimate confidence score for each visium slide

        Parameters
        ----------

        Returns
        -------
        self.adatas[i].obs.confidence_IDs and self.confidence_score_df are added
        containing confidence score for each tissue ID assignment and mean confidence
        score for each tissue ID within each visium slide
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        i_slice = 0
        j_slice = 0
        confidence_score_df = pd.DataFrame()
        adatas = self.adatas
        cluster_data = self.cluster_data
        centroids = self.kmeans.cluster_centers_
        for i, adata in enumerate(adatas):
            j_slice = j_slice + adata.n_obs
            data = cluster_data[i_slice:j_slice]
            scores_dict = estimate_confidence_score_st(data, adata, centroids)
            df = pd.DataFrame(scores_dict.values(), columns=[i])
            confidence_score_df = pd.concat([confidence_score_df, df], axis=1)
            i_slice = i_slice + adata.n_obs
        self.confidence_score_df = confidence_score_df

    def plot_gene_loadings(
        self,
        PC_loadings,
        n_genes=10,
        ncols=None,
        titles=None,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot MILWRM loadings in gene space specifically for MILWRM done with PCs

        Parameters
        ----------
        PC_loadings : numpy.ndarray
            numpy.ndarray containing PC loadings shape format (genes, components)
        n_genes : int, optional (default=10)
            number of genes to plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object and PC loadings in gene space set as self.gene_loadings_df
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        assert (
            PC_loadings.shape[0] == self.adatas[0].n_vars
        ), f&#34;loadings matrix does not, \
        contain enough genes, there should be {self.adatas[0].n_vars} genes&#34;
        assert (
            PC_loadings.shape[1] &gt;= self.kmeans.cluster_centers_.shape[1]
        ), f&#34;loadings matrix \
        does not contain enough components, there should be atleast {self.adatas[0].n_vars} components&#34;
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        centroids = self.kmeans.cluster_centers_
        temp = PC_loadings.T
        loadings = temp[range(self.kmeans.cluster_centers_.shape[1])]
        gene_loadings = np.matmul(centroids, loadings)
        gene_loadings_df = pd.DataFrame(gene_loadings)
        gene_loadings_df = gene_loadings_df.T
        gene_loadings_df[&#34;genes&#34;] = self.adatas[0].var_names
        self.gene_loadings_df = gene_loadings_df
        n_panels = self.k
        if ncols is None:
            ncols = self.k
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=((ncols * n_cols, ncols * n_rows)))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in range(self.k):
            df = (
                gene_loadings_df[[i, &#34;genes&#34;]]
                .sort_values(i, axis=0, ascending=False)[:n_genes]
                .reset_index(drop=True)
            )
            plt.subplot(gs[i])
            df_rev = df.sort_values(i).reset_index(drop=True)
            for j, score in enumerate((df_rev[i])):
                plt.text(
                    x=score,
                    y=j + 0.1,
                    s=df_rev.loc[j, &#34;genes&#34;],
                    color=&#34;black&#34;,
                    verticalalignment=&#34;center&#34;,
                    horizontalalignment=&#34;right&#34;,
                    fontsize=&#34;medium&#34;,
                    fontstyle=&#34;italic&#34;,
                )
                plt.ylim([0, j + 1])
                plt.xlim([0, df.max().values[0] + 0.1])
                plt.tick_params(
                    axis=&#34;y&#34;,  # changes apply to the y-axis
                    which=&#34;both&#34;,  # both major and minor ticks are affected
                    left=False,
                    right=False,
                    labelleft=False,
                )
                plt.title(titles[i])
        gs.tight_layout(fig)
        if save_to is not None:
            print(&#34;Saving feature loadings to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return gs

    def plot_percentage_variance_explained(
        self, fig_size=(5, 5), R_square=False, save_to=None
    ):
        &#34;&#34;&#34;
        plot percentage variance_explained or not explained by clustering

        Parameters
        ----------
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        R_square : Boolean
            Decides if R_square is plotted or S_square
        save_to : str or None
            Path to image file to save results. If `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        centroids = self.kmeans.cluster_centers_
        adatas = self.adatas
        cluster_data = self.cluster_data
        S_squre_for_each_st = []
        R_squre_for_each_st = []
        i_slice = 0
        j_slice = 0
        for adata in adatas:
            j_slice = j_slice + adata.n_obs
            sub_cluster_data = cluster_data[i_slice:j_slice]
            S_square = estimate_percentage_variance_st(
                sub_cluster_data, adata, centroids
            )
            S_squre_for_each_st.append(S_square)
            R_squre_for_each_st.append(100 - S_square)
            i_slice = i_slice + adata.n_obs

        if R_square:
            fig = plt.figure(figsize=fig_size)
            plt.scatter(
                range(len(R_squre_for_each_st)), R_squre_for_each_st, color=&#34;black&#34;
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(R_squre_for_each_st),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        else:
            fig = plt.figure(figsize=fig_size)
            fig = plt.figure(figsize=(5, 5))
            plt.scatter(
                range(len(S_squre_for_each_st)), S_squre_for_each_st, color=&#34;black&#34;
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(S_squre_for_each_st),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def plot_mse_st(
        self,
        figsize=(5, 5),
        ncols=None,
        labels=None,
        titles=None,
        loc=&#34;lower right&#34;,
        bbox_coordinates=(0, 0, 1.5, 1.5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        estimate mean square error within each tissue ID

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        labels : list of str, optional (default=`None`)
            Labels corresponding to each image in legend. If `None`, numeric index is
            used for each imaage
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        loc : str, optional (default = &#39;lower right&#39;)
            str for legend position
        bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
            coordinates for the legend box
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        cluster_data = self.cluster_data
        adatas = self.adatas
        k = self.k
        features = self.features
        centroids = self.kmeans.cluster_centers_
        mse_id = estimate_mse_st(cluster_data, adatas, centroids, k)
        colors = plt.cm.tab20(np.linspace(0, 1, len(adatas)))
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        if labels is None:
            labels = range(len(adatas))
        n_panels = len(mse_id.keys())
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in mse_id.keys():
            plt.subplot(gs[i])
            df = pd.DataFrame.from_dict(mse_id[i])
            plt.boxplot(df, positions=features, showfliers=False)
            for col in df:
                for k in range(len(df[col])):
                    dots = plt.scatter(
                        col,
                        df[col][k],
                        s=k + 1,
                        color=colors[k],
                        label=labels[k] if col == 0 else &#34;&#34;,
                    )
                    offsets = dots.get_offsets()
                    jittered_offsets = offsets
                    # only jitter in the x-direction
                    jittered_offsets[:, 0] += np.random.uniform(
                        -0.3, 0.3, offsets.shape[0]
                    )
                    dots.set_offsets(jittered_offsets)
            plt.xlabel(&#34;slides&#34;)
            plt.ylabel(&#34;mean square error&#34;)
            plt.title(titles[i])
        plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates)
        gs.tight_layout(fig)
        if save_to:
            plt.savefig(fname=save_to, transparent=True, dpi=300)
        return fig

    def plot_tissue_ID_proportions_st(
        self,
        tID_labels=None,
        slide_labels=None,
        figsize=(5, 5),
        cmap=&#34;tab20&#34;,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot proportion of each tissue ID within each slide

        Parameters
        ----------
        tID_labels : list of str, optional (default=`None`)
            List of labels corresponding to MILWRM tissue IDs for plotting legend
        slide_labels : list of str, optional (default=`None`)
            List of labels for each slide batch for labeling x-axis
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        cmap : str, optional (default = `&#34;tab20&#34;`)
            Colormap from matplotlib
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        df_count = pd.DataFrame()
        for adata in self.adatas:
            df = adata.obs[&#34;tissue_ID&#34;].value_counts(normalize=True, sort=False)
            df_count = pd.concat([df_count, df], axis=1)
        df_count = df_count.T.reset_index(drop=True)
        if tID_labels:
            assert (
                len(tID_labels) == df_count.shape[1]
            ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
            df_count.columns = tID_labels
        if slide_labels:
            assert (
                len(slide_labels) == df_count.shape[0]
            ), &#34;Length of given slide labels does not match number of slides!&#34;
            df_count.index = slide_labels
        ax = df_count.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
        ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
        ax.set_xlabel(&#34;slides&#34;)
        ax.set_ylabel(&#34;tissue ID proportion&#34;)
        ax.set_ylim((0, 1))
        plt.tight_layout()
        if save_to is not None:
            ax.figure.savefig(save_to)
        else:
            return ax

    def show_feature_overlay(
        self,
        adata_index,
        pita,
        features=None,
        histo=None,
        cmap=&#34;tab20&#34;,
        label=&#34;feature&#34;,
        ncols=4,
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot tissue_ID with individual pita features as alpha values to distinguish
        expression in identified tissue domains

        Parameters
        ----------
        adata_index : int
            Index of adata from `self.adatas` to plot overlays for (e.g. 0 for first
            adata object)
        pita : np.array
            Image of desired expression in pixel space from `.assemble_pita()`
        features : list of int, optional (default=`None`)
            List of features by index to show in plot. If `None`, use all features.
        histo : np.array or `None`, optional (default=`None`)
            Histology image to show along with pita in gridspec. If `None`, ignore.
        cmap : str, optional (default=&#34;tab20&#34;)
            Matplotlib colormap to use for plotting tissue IDs
        label : str
            What to title each panel of the gridspec (i.e. &#34;PC&#34; or &#34;usage&#34;) or each
            channel in RGB image. Can also pass list of names e.g. [&#34;NeuN&#34;,&#34;GFAP&#34;,
            &#34;DAPI&#34;] corresponding to channels.
        ncols : int
            Number of columns for gridspec
        save_to : str or None
            Path to image file to save results. if `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        assert pita.ndim &gt; 1, &#34;Pita does not have enough dimensions: {} given&#34;.format(
            pita.ndim
        )
        assert pita.ndim &lt; 4, &#34;Pita has too many dimensions: {} given&#34;.format(pita.ndim)
        # create tissue_ID pita for plotting
        tIDs = assemble_pita(
            self.adatas[adata_index],
            features=&#34;tissue_ID&#34;,
            use_rep=&#34;obs&#34;,
            plot_out=False,
            verbose=False,
        )
        # if pita has multiple features, plot them in gridspec
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        # if no features are given, use all of them
        elif features is None:
            features = [x + 1 for x in range(pita.shape[2])]
        else:
            assert (
                pita.ndim &gt; 2
            ), &#34;Not enough features in pita: shape {}, expecting 3rd dim with length {}&#34;.format(
                pita.shape, len(features)
            )
            assert (
                len(features) &lt;= pita.shape[2]
            ), &#34;Too many features given: pita has {}, expected {}&#34;.format(
                pita.shape[2], len(features)
            )
        # min-max scale each feature in pita to convert to interpretable alpha values
        mms = MinMaxScaler()
        if pita.ndim == 3:
            pita_tmp = mms.fit_transform(
                pita.reshape((pita.shape[0] * pita.shape[1], pita.shape[2]))
            )
        elif pita.ndim == 2:
            pita_tmp = mms.fit_transform(
                pita.reshape((pita.shape[0] * pita.shape[1], 1))
            )
        # reshape back to original
        pita = pita_tmp.reshape(pita.shape)
        # figure out labels for gridspec plots
        if isinstance(label, str):
            # if label is single string, name channels numerically
            labels = [&#34;{}_{}&#34;.format(label, x) for x in features]
        else:
            assert len(label) == len(
                features
            ), &#34;Please provide the same number of labels as features; {} labels given, {} features given.&#34;.format(
                len(label), len(features)
            )
            labels = label
        # calculate gridspec dimensions
        if histo is not None:
            # determine where the histo image is in anndata
            assert (
                histo
                in self.adatas[adata_index]
                .uns[&#34;spatial&#34;][
                    list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
                ][&#34;images&#34;]
                .keys()
            ), &#34;Must provide one of {} for histo&#34;.format(
                self.adatas[adata_index]
                .uns[&#34;spatial&#34;][
                    list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
                ][&#34;images&#34;]
                .keys()
            )
            histo = self.adatas[adata_index].uns[&#34;spatial&#34;][
                list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
            ][&#34;images&#34;][histo]
            if len(features) + 2 &lt;= ncols:
                n_rows, n_cols = 1, len(features) + 2
            else:
                n_rows, n_cols = ceil((len(features) + 2) / ncols), ncols
            labels = [&#34;Histology&#34;, &#34;tissue_ID&#34;] + labels  # append to front of labels
        else:
            if len(features) + 1 &lt;= ncols:
                n_rows, n_cols = 1, len(features) + 1
            else:
                n_rows, n_cols = ceil(len(features) + 1 / ncols), ncols
            labels = [&#34;tissue_ID&#34;] + labels  # append to front of labels
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        if histo is not None:
            # add histology plot to first axes
            ax = plt.subplot(gs[i])
            im = ax.imshow(histo, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=labels[i],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        # plot tissue_ID first with colorbar
        ax = plt.subplot(gs[i])
        im = ax.imshow(tIDs, cmap=cmap, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        # colorbar scale for tissue_IDs
        _ = plt.colorbar(im, shrink=0.7)
        i = i + 1
        for feature in features:
            ax = plt.subplot(gs[i])
            im = ax.imshow(tIDs, alpha=pita[:, :, feature - 1], cmap=cmap, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=labels[i],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig


class mxif_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue domain labeling class for multiplex immunofluorescence (MxIF) data
    &#34;&#34;&#34;

    def __init__(self, image_df):
        &#34;&#34;&#34;
        Initialize MxIF tissue labeler class

        Parameters
        ----------
        image_df : pd.DataFrame object
            Containing MILWRM.MxIF.img objects or str path to compressed npz files,
            batch names, mean estimator and pixel count for each image in the
            following column order [&#39;Img&#39;, &#39;batch_names&#39;, &#39;mean estimators&#39;, &#39;pixels&#39;]

        Returns
        -------
        Does not return anything. `self.images` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        # validate the format of the image_df dataframe
        if np.all(
            image_df.columns == [&#34;Img&#34;, &#34;batch_names&#34;, &#34;mean estimators&#34;, &#34;pixels&#34;]
        ):
            self.image_df = image_df
        else:
            raise Exception(
                &#34;Image_df must be given with these columns in this format [&#39;Img&#39;, &#39;batch_names&#39;, &#39;mean estimators&#39;, &#39;pixels&#39;]&#34;
            )
        if self.image_df[&#34;Img&#34;].apply(isinstance, args=[img]).all():
            self.use_paths = False
        elif self.image_df[&#34;Img&#34;].apply(isinstance, args=[str]).all():
            self.use_paths = True
        else:
            raise Exception(
                &#34;Img column in the dataframe should be either str for paths to the files or mxif.img object&#34;
            )

    def prep_cluster_data(
        self, features, filter_name=&#34;gaussian&#34;, sigma=2, fract=0.2, path_save=None
    ):
        &#34;&#34;&#34;
        Prepare master array for tissue level clustering

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        filter_name : str
            Name of the filter to use - gaussian, median or bilateral
        sigma : float, optional (default=2)
            Standard deviation of Gaussian kernel for blurring
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select for model
            building
        path_save : str (default = None)
            Path to save final preprocessed files, if self.use_path is True
            default path_save will raise Exception

        Returns
        -------
        Does not return anything. `self.images` are normalized, blurred and scaled
        according to user parameters. `self.cluster_data` becomes master `np.array`
        for cluster training. Parameters are also captured as attributes for posterity.

        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        # save the hyperparams as object attributes
        self.model_features = features
        use_path = self.use_paths
        # calculate the batch wise means
        mean_for_each_batch = {}
        for batch in self.image_df[&#34;batch_names&#34;].unique():
            list_mean_estimators = list(
                self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;mean estimators&#34;]
            )
            mean_estimator_batch = sum(map(np.array, list_mean_estimators))
            pixels = sum(self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;pixels&#34;])
            mean_for_each_batch[batch] = mean_estimator_batch / pixels
        # log_normalize, apply blurring filter, minmax scale each channel and subsample
        subsampled_data = []
        path_to_blurred_npz = []
        for image, batch in zip(self.image_df[&#34;Img&#34;], self.image_df[&#34;batch_names&#34;]):
            tmp = prep_data_single_sample_mxif(
                image,
                use_path=use_path,
                mean=mean_for_each_batch[batch],
                filter_name=filter_name,
                sigma=sigma,
                features=self.model_features,
                fract=fract,
                path_save=path_save,
            )
            if self.use_paths == True:
                subsampled_data.append(tmp[0])
                path_to_blurred_npz.append(tmp[1])
            else:
                subsampled_data.append(tmp)
        batch_labels = [
            [x] * len(subsampled_data[x]) for x in range(len(subsampled_data))
        ]  # batch labels for umap
        self.merged_batch_labels = list(itertools.chain(*batch_labels))
        if self.use_paths == True:
            self.image_df[&#34;Img&#34;] = path_to_blurred_npz
        cluster_data = np.row_stack(subsampled_data)
        # perform z-score normalization on cluster_Data
        scaler = StandardScaler()
        self.scaler = scaler.fit(cluster_data)
        scaled_data = scaler.transform(cluster_data)
        self.cluster_data = scaled_data

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        images.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if scaled inertia plot should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model
        n_jobs : int
            Number of cores to parallelize k-choosing and tissue ID assignment across.
            Default all available cores.

        Returns
        -------
        Does not return anything. `self.tissue_ID` is added, containing image with
        final tissue region IDs. `self.kmeans` contains trained `sklearn` clustering
        model. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # save the hyperparams as object attributes
        use_path = self.use_paths
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                alpha=alpha,
                plot_out=plot_out,
                random_state=random_state,
                n_jobs=n_jobs,
            )
        # call k-means model from parent class
        self.find_tissue_regions(k=k, random_state=random_state)
        # loop through image objects and create tissue label images
        print(&#34;Creating tissue_ID images for image objects...&#34;)
        self.tissue_IDs = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(add_tissue_ID_single_sample_mxif)(
                image, use_path, self.model_features, self.kmeans, self.scaler
            )
            for image in self.image_df[&#34;Img&#34;]
        )

    def plot_percentage_variance_explained(
        self, fig_size=(5, 5), R_square=False, save_to=None
    ):
        &#34;&#34;&#34;
        plot percentage variance_explained or not explained by clustering

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        R_square : Boolean
            Decides if R_square is plotted or S_square
        save_to : str or None
            Path to image file to save results. If `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        use_path = self.use_paths
        S_squre_for_each_image = []
        R_squre_for_each_image = []
        for image, tissue_ID in zip(self.image_df[&#34;Img&#34;], self.tissue_IDs):
            S_square = estimate_percentage_variance_mxif(
                image, use_path, scaler, centroids, features, tissue_ID
            )
            S_squre_for_each_image.append(S_square)
            R_squre_for_each_image.append(100 - S_square)

        if R_square == True:
            fig = plt.figure(figsize=fig_size)
            fig = plt.figure(figsize=(5, 5))
            plt.scatter(
                range(len(R_squre_for_each_image)),
                R_squre_for_each_image,
                color=&#34;black&#34;,
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(R_squre_for_each_image),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        else:
            fig = plt.figure(figsize=fig_size)
            plt.scatter(
                range(len(S_squre_for_each_image)),
                S_squre_for_each_image,
                color=&#34;black&#34;,
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(S_squre_for_each_image),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def confidence_score_images(self):
        &#34;&#34;&#34;
        estimate confidence score for each image

        Parameters
        ----------

        Returns
        -------
        self.confidence_IDs and self.confidence_score_df is added containing
        confidence score for each tissue ID assignment and mean confidence score for
        each tissue ID within each image
        &#34;&#34;&#34;
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        tissue_IDs = self.tissue_IDs
        use_path = self.use_paths
        # confidence score estimation for each image
        confidence_IDs = []
        confidence_score_df = pd.DataFrame()
        for i, image in enumerate(self.image_df[&#34;Img&#34;]):
            cID, scores_dict = estimate_confidence_score_mxif(
                image, use_path, scaler, centroids, features, tissue_IDs[i]
            )
            confidence_IDs.append(cID)
            df = pd.DataFrame(scores_dict.values(), columns=[i])
            confidence_score_df = pd.concat(
                [confidence_score_df, df.T], ignore_index=True
            )
        # adding confidence_IDs and confidence_score_df to tissue labeller object
        self.confidence_IDs = confidence_IDs
        self.confidence_score_df = confidence_score_df

    def plot_mse_mxif(
        self,
        figsize=(5, 5),
        ncols=None,
        labels=None,
        legend_cols=2,
        titles=None,
        loc=&#34;lower right&#34;,
        bbox_coordinates=(0, 0, 1.5, 1.5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        estimate mean square error within each tissue ID

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        labels : list of str, optional (default=`None`)
            Labels corresponding to each image in legend. If `None`, numeric index is
            used for each imaage
        legend_cols : int, optional (default = `2`)
            n_cols for legend
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        loc : str, optional (default = &#39;lower right&#39;)
            str for legend position
        bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
            coordinates for the legend box
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        images = self.image_df[&#34;Img&#34;]
        use_path = self.use_paths
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        k = self.k
        features = self.model_features
        tissue_IDs = self.tissue_IDs
        mse_id = estimate_mse_mxif(
            images, use_path, tissue_IDs, scaler, centroids, features, k
        )
        if labels is None:
            labels = range(len(images))
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        n_panels = len(mse_id.keys())
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        colors = plt.cm.tab20(np.linspace(0, 1, len(images)))
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in mse_id.keys():
            plt.subplot(gs[i])
            df = pd.DataFrame.from_dict(mse_id[i])
            plt.boxplot(df, positions=range(len(features)), showfliers=False)
            plt.xticks(
                ticks=range(len(features)),
                labels=self.model_features,
                rotation=60,
                fontsize=8,
            )
            for col in df:
                for k in range(len(images)):
                    dots = plt.scatter(
                        col,
                        df[col][k],
                        s=k + 1,
                        color=colors[k],
                        label=labels[k] if col == 0 else &#34;&#34;,
                    )
                    offsets = dots.get_offsets()
                    jittered_offsets = offsets
                    # only jitter in the x-direction
                    jittered_offsets[:, 0] += np.random.uniform(
                        -0.3, 0.3, offsets.shape[0]
                    )
                    dots.set_offsets(jittered_offsets)
            plt.xlabel(&#34;marker&#34;)
            plt.ylabel(&#34;mean square error&#34;)
            plt.title(titles[i])
        plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates, ncol=legend_cols)
        gs.tight_layout(fig)
        if save_to:
            plt.savefig(fname=save_to, transparent=True, dpi=300)
        return fig

    def plot_tissue_ID_proportions_mxif(
        self,
        tID_labels=None,
        slide_labels=None,
        figsize=(5, 5),
        cmap=&#34;tab20&#34;,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot proportion of each tissue ID within each slide

        Parameters
        ----------
        tID_labels : list of str, optional (default=`None`)
            List of labels corresponding to MILWRM tissue IDs for plotting legend
        slide_labels : list of str, optional (default=`None`)
            List of labels for each slide batch for labeling x-axis
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        cmap : str, optional (default = `&#34;tab20&#34;`)
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        df_count = pd.DataFrame()
        for i in range(len(self.tissue_IDs)):
            unique, counts = np.unique(self.tissue_IDs[i], return_counts=True)
            dict_ = dict(zip(unique, counts))
            n_counts = []
            for k in range(self.k):
                if k not in dict_.keys():
                    n_counts.append(0)
                else:
                    n_counts.append(dict_[k])
            df = pd.DataFrame(n_counts, columns=[i])
            df_count = pd.concat([df_count, df], axis=1)
        df_count = df_count / df_count.sum()
        if tID_labels:
            assert (
                len(tID_labels) == df_count.shape[1]
            ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
            df_count.columns = tID_labels
        if slide_labels:
            assert (
                len(slide_labels) == df_count.shape[0]
            ), &#34;Length of given slide labels does not match number of slides!&#34;
            df_count.index = slide_labels
        self.tissue_ID_proportion = df_count
        ax = df_count.T.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
        ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
        ax.set_xlabel(&#34;images&#34;)
        ax.set_ylabel(&#34;tissue ID proportion&#34;)
        ax.set_ylim((0, 1))
        plt.tight_layout()
        if save_to is not None:
            ax.figure.savefig(save_to)
        else:
            return ax

    def make_umap(self, frac=None, cmap=&#34;tab20&#34;, save_to=None, alpha=0.8):
        &#34;&#34;&#34;
        plot umap for the cluster data

        Parameters
        ----------
        frac : None or float
            if None entire cluster data is used for the computation of umap
            else that percentage of cluster data is used.
        cmap : str
            str for cmap used for plotting. Default `&#34;tab20&#34;`.
        save_to : str or None
            Path to image file to save results. if `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        cluster_data = self.cluster_data
        centroids = self.kmeans.cluster_centers_
        batch_labels = self.merged_batch_labels
        kmeans_labels = self.kmeans.labels_
        k = self.k
        # perform umap on the cluster data
        umap_centroid_data, standard_embedding_1 = perform_umap(
            cluster_data=cluster_data,
            centroids=centroids,
            batch_labels=batch_labels,
            kmeans_labels=kmeans_labels,
            frac=frac,
        )
        # defining a size of datapoints for scatter plot and tick labels
        size = [0.01] * len(umap_centroid_data.index)
        size[-k:] = [10] * k
        ticks = np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;]))
        tick_label = list(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
        tick_label[-1] = &#34;centroids&#34;
        # plotting a fig with two subplots
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
        # defining color_map
        # TODO : add alpha here
        disc_cmap_1 = plt.cm.get_cmap(
            cmap, len(np.unique(np.array(umap_centroid_data.index)))
        )
        disc_cmap_2 = plt.cm.get_cmap(
            cmap, len(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
        )
        plot_1 = ax1.scatter(
            standard_embedding_1[:, 0],
            standard_embedding_1[:, 1],
            s=0.01,
            c=umap_centroid_data.index,
            cmap=disc_cmap_1,
            alpha=alpha,
        )
        ax1.set_title(&#34;Umap with batch labels&#34;)
        cbar_1 = plt.colorbar(plot_1, ax=ax1)
        plot_2 = ax2.scatter(
            standard_embedding_1[:, 0],
            standard_embedding_1[:, 1],
            s=size,
            c=umap_centroid_data[&#34;Kmeans_labels&#34;],
            cmap=disc_cmap_2,
            alpha=alpha,
        )
        ax2.set_title(&#34;Umap with tissue IDs&#34;)
        cbar_2 = plt.colorbar(plot_2, ax=ax2, ticks=ticks)
        cbar_2.ax.set_yticklabels(tick_label)
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def show_marker_overlay(
        self,
        image_index,
        channels=None,
        cmap=&#34;Set1&#34;,
        mask_out=True,
        ncols=4,
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot tissue_ID with individual markers as alpha values to distinguish
        expression in identified tissue domains

        Parameters
        ----------
        image_index : int
            Index of image from `self.images` to plot overlays for (e.g. 0 for first
            image)
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        cmap : str, optional (default=&#34;plasma&#34;)
            Matplotlib colormap to use for plotting tissue IDs
        mask_out : bool, optional (default=`True`)
            Mask out non-tissue pixels prior to showing
        ncols : int
            Number of columns for gridspec if plotting individual channels.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        # if image has multiple channels, plot them in gridspec
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self[image_index].ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self[image_index].ch.index(x) for x in channels]
        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self[image_index].n_ch)]
        assert (
            len(channels) &lt;= self[image_index].n_ch
        ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
            self[image_index].n_ch, len(channels)
        )
        # creating a copy of the image
        image_cp = self[image_index].copy()
        # re-scaling to set pixel value range between 0 to 1
        image_cp.scale()
        # defining cmap for discrete color bar
        cmap = plt.cm.get_cmap(cmap, self.k)
        # calculate gridspec dimensions
        if len(channels) + 1 &lt;= ncols:
            n_rows, n_cols = 1, len(channels) + 1
        else:
            n_rows, n_cols = ceil(len(channels) + 1 / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # plot tissue_ID first with colorbar
        ax = plt.subplot(gs[0])
        im = ax.imshow(self.tissue_IDs[image_index], cmap=cmap, **kwargs)
        ax.set_title(
            label=&#34;tissue_ID&#34;,
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        # colorbar scale for tissue_IDs
        _ = plt.colorbar(im, ticks=range(self.k), shrink=0.7)
        # add plots to axes
        i = 1
        for channel in channels:
            ax = plt.subplot(gs[i])
            # make copy for alpha
            im_tmp = image_cp.img[:, :, channel].copy()
            if self[image_index].mask is not None and mask_out:
                # area outside mask NaN
                self.tissue_IDs[image_index][self[image_index].mask == 0] = np.nan
                im = ax.imshow(
                    self.tissue_IDs[image_index], cmap=cmap, alpha=im_tmp, **kwargs
                )
            else:
                ax.imshow(self.tissue_IDs[image_index], alpha=im_tmp, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=self[image_index].ch[channel],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="MILWRM.MILWRM.add_tissue_ID_single_sample_mxif"><code class="name flex">
<span>def <span class="ident">add_tissue_ID_single_sample_mxif</span></span>(<span>image, use_path, features, kmeans, scaler)</span>
</code></dt>
<dd>
<div class="desc"><p>Label pixels in a single MxIF sample with kmeans results</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code><a title="MILWRM.MxIF.img" href="MxIF.html#MILWRM.MxIF.img">img</a></code> or <code>str</code></dt>
<dd>np.array containing MxIF data or path to the compressed npz file</dd>
<dt><strong><code>use_path</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>True if image is given as a path to the compressed npz file, False if image is
given as MILWRM.MxIF.img object</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>kmeans</code></strong> :&ensp;<code>sklearn.kmeans</code></dt>
<dd>Trained k-means model</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tID</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Image where pixel values are kmeans cluster IDs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_tissue_ID_single_sample_mxif(image, use_path, features, kmeans, scaler):
    &#34;&#34;&#34;
    Label pixels in a single MxIF sample with kmeans results

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    kmeans : sklearn.kmeans
        Trained k-means model

    Returns
    -------
    tID : np.array
        Image where pixel values are kmeans cluster IDs
    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    # subset to features used in prep_cluster_data
    tmp = image.img[:, :, features]
    w, h, d = tuple(tmp.shape)
    image_array = tmp.reshape((w * h, d))
    scaled_image_array = scaler.transform(image_array)
    tID = kmeans.predict(scaled_image_array).reshape(w, h)
    tID = tID.astype(float)  # TODO: Figure out dtypes
    tID[image.mask == 0] = np.nan  # set masked-out pixels to NaN
    return tID</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.chooseBestKforKMeansParallel"><code class="name flex">
<span>def <span class="ident">chooseBestKforKMeansParallel</span></span>(<span>scaled_data, k_range, n_jobs=-1, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Determines optimal k value by fitting k-means models to scaled data and minimizing
scaled inertia</p>
<p>Adapted from
<a href="https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c">https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scaled_data</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Scaled data. Rows are samples and columns are features for clustering.</dd>
<dt><strong><code>k_range</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>k range for applying KMeans</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing across</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code><a title="MILWRM.MILWRM.kMeansRes" href="#MILWRM.MILWRM.kMeansRes">kMeansRes()</a></code> (i.e. <code>alpha_k</code>, <code>random_state</code>)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>best_k</code></strong> :&ensp;<code>int</code></dt>
<dd>Chosen value of k out of the given k range. Chosen k is k with the minimum
scaled inertia value.</dd>
<dt><strong><code>results</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Adjusted inertia value for each k in k_range</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chooseBestKforKMeansParallel(scaled_data, k_range, n_jobs=-1, **kwargs):
    &#34;&#34;&#34;
    Determines optimal k value by fitting k-means models to scaled data and minimizing
    scaled inertia

    Adapted from
    https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c

    Parameters
    ----------
    scaled_data: np.array
        Scaled data. Rows are samples and columns are features for clustering.
    k_range: list of int
        k range for applying KMeans
    n_jobs : int
        Number of cores to parallelize k-choosing across
    **kwargs
        Arguments to pass to `kMeansRes()` (i.e. `alpha_k`, `random_state`)

    Returns
    -------
    best_k: int
        Chosen value of k out of the given k range. Chosen k is k with the minimum
        scaled inertia value.
    results: pd.DataFrame
        Adjusted inertia value for each k in k_range
    &#34;&#34;&#34;
    ans = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(kMeansRes)(scaled_data, k, **kwargs) for k in k_range
    )
    ans = list(zip(k_range, ans))
    results = pd.DataFrame(ans, columns=[&#34;k&#34;, &#34;Scaled Inertia&#34;]).set_index(&#34;k&#34;)
    best_k = results.idxmin()[0]
    return best_k, results</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_confidence_score_mxif"><code class="name flex">
<span>def <span class="ident">estimate_confidence_score_mxif</span></span>(<span>image, use_path, scaler, centroids, features, tissue_ID)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate confidence score for the assigned tissue_IDs in MxIF slide by
taking difference between distance to the second closest centroid and the
assigned centroid divided by distance to the second closest centroid.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code><a title="MILWRM.MxIF.img" href="MxIF.html#MILWRM.MxIF.img">img</a></code> or <code>str</code></dt>
<dd>np.array containing MxIF data or path to the compressed npz file</dd>
<dt><strong><code>use_path</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>True if image is given as a path to the compressed npz file, False if image is
given as MILWRM.MxIF.img object</dd>
<dt><strong><code>scaler</code></strong> :&ensp;<code>standardscaler() object</code></dt>
<dd>standard scaler used for cluster data normalization</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>tissue_ID</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>numpy array containing kmeans labels on image</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>Conf_ID</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>overall confidence score for each pixel's cluster assignment</dd>
<dt><strong><code>mean_conf_score</code></strong> :&ensp;<code>dict</code></dt>
<dd>mean confidence score for each tissue ID (keys for the dictionary)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_confidence_score_mxif(
    image, use_path, scaler, centroids, features, tissue_ID
):
    &#34;&#34;&#34;
    Estimate confidence score for the assigned tissue_IDs in MxIF slide by
    taking difference between distance to the second closest centroid and the
    assigned centroid divided by distance to the second closest centroid.

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    tissue_ID : np.ndarray
        numpy array containing kmeans labels on image

    Returns
    -------
    Conf_ID : np.ndarray
        overall confidence score for each pixel&#39;s cluster assignment
    mean_conf_score : dict
        mean confidence score for each tissue ID (keys for the dictionary)
    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    w, h, d = image.img[:, :, features].shape
    img_ar = image.img[:, :, features].reshape((w * h), d)
    scaled_img_ar = scaler.transform(img_ar)
    img_sc = scaled_img_ar.reshape((w, h, d))
    # initializing an empty numpy array to store distance to each centroid along axis = 2
    dist_ar = np.zeros((w, h, len(centroids)))
    for i, centroid in enumerate(centroids):
        dist = ((img_sc) - (centroid)) ** 2
        dist_cp = np.sum(dist, axis=2)
        dist_ar[:, :, i] = dist_ar[:, :, i] + dist_cp
    # sorting the numpy array according to distance from centroids
    new_dist_ar = np.sort(dist_ar, axis=2)
    # estimating new confidence score
    cID = ((new_dist_ar[:, :, 1]) - (new_dist_ar[:, :, 0])) / new_dist_ar[:, :, 1]
    cID[image.mask == 0] = np.nan
    # estimating average confidence score in that image
    mean_conf_score = {}
    for i in range(len(centroids)):
        mean_conf_score[i] = np.mean(cID[tissue_ID == i])
    return cID, mean_conf_score</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_confidence_score_st"><code class="name flex">
<span>def <span class="ident">estimate_confidence_score_st</span></span>(<span>sub_cluster_data, adata, centroids)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate confidence score for the assigned tissue_IDs in a visium slide by
taking difference between distance to the second closest centroid and the
assigned centroid divided by distance to the second closest centroid.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sub_cluster_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>np.ndarray containing data for that visium slide used for kmeans</dd>
<dt><strong><code>adata</code></strong> :&ensp;<code>anndata.AnnData</code></dt>
<dd>AnnData object containing Visium data</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Confidence_score added to adata.obs</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>mean_conf_score</code></strong> :&ensp;<code>dict</code></dt>
<dd>mean confidence score for each tissue ID (keys for the dictionary)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_confidence_score_st(sub_cluster_data, adata, centroids):
    &#34;&#34;&#34;
    Estimate confidence score for the assigned tissue_IDs in a visium slide by
    taking difference between distance to the second closest centroid and the
    assigned centroid divided by distance to the second closest centroid.

    Parameters
    ----------
    sub_cluster_data : np.ndarray
        np.ndarray containing data for that visium slide used for kmeans
    adata : anndata.AnnData
        AnnData object containing Visium data
    centroids : np.ndarray
        kmeans cluster centroids

    Returns
    -------
    Confidence_score added to adata.obs
    mean_conf_score : dict
        mean confidence score for each tissue ID (keys for the dictionary)
    &#34;&#34;&#34;
    # initializing zeros array to store distances
    dist_mx = np.zeros((sub_cluster_data.shape[0], len(centroids)))
    # calculating distance to each centroid
    for i, centroid in enumerate(centroids):
        dist_cp = ((sub_cluster_data) - (centroid)) ** 2
        dist = np.sum(dist_cp, axis=1)
        dist_mx[:, i] = dist_mx[:, i] + dist
    # sorting distances according to distance from centroids
    new_dist_ar = np.sort(dist_mx, axis=1)
    # using assigned and second closest centroid to estimate confidence score
    cID = ((new_dist_ar[:, 1]) - (new_dist_ar[:, 0])) / new_dist_ar[:, 1]
    adata.obs[&#34;confidence_score&#34;] = cID
    score_df = pd.DataFrame(cID, columns=[&#34;score&#34;])
    score_df[&#34;tissue_ID&#34;] = adata.obs[&#34;tissue_ID&#34;].values
    mean_conf_score = {}
    for i in range(len(centroids)):
        if (adata.obs[&#34;tissue_ID&#34;] == i).any():
            mean_conf_score[i] = score_df[score_df[&#34;tissue_ID&#34;] == i][&#34;score&#34;].mean()
        else:
            mean_conf_score[i] = np.nan
    return mean_conf_score</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_mse_mxif"><code class="name flex">
<span>def <span class="ident">estimate_mse_mxif</span></span>(<span>images, use_path, tissue_IDs, scaler, centroids, features, k)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate mean square error for each tissue ID for each MxIF images</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>list</code></dt>
<dd>list of MILWRM.MxIF.img objects or path to images (str)</dd>
<dt><strong><code>use_path</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>True if image is given as a path to the compressed npz file, False if image is
given as MILWRM.MxIF.img object</dd>
<dt><strong><code>tissue_IDs</code></strong> :&ensp;<code>list</code></dt>
<dd>list of predicted tissue_ID for each image</dd>
<dt><strong><code>scaler</code></strong> :&ensp;<code>standardscaler() object</code></dt>
<dd>standard scaler used for cluster data normalization</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code></dt>
<dd>number of tissue domains</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mse_id</code></strong> :&ensp;<code>dict</code></dt>
<dd>containing mean square error for each tissue for each visium slide</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_mse_mxif(images, use_path, tissue_IDs, scaler, centroids, features, k):
    &#34;&#34;&#34;
    Estimate mean square error for each tissue ID for each MxIF images

    Parameters
    ----------
    images : list
        list of MILWRM.MxIF.img objects or path to images (str)
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    tissue_IDs : list
        list of predicted tissue_ID for each image
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    k : int
        number of tissue domains

    Returns
    -------
    mse_id : dict
        containing mean square error for each tissue for each visium slide
    &#34;&#34;&#34;
    mse_temp = {}
    for image_index, image in enumerate(images):
        if use_path == True:
            image_path = image + &#34;.npz&#34;
            image = img.from_npz(image_path)
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        if isinstance(features, str):  # force features into int if single string
            features = [image.ch.index(features)]
        if checktype(features):  # force features into list of int if list of strings
            features = [image.ch.index(x) for x in features]
        if features is None:  # if no features are given, use all of them
            features = [x for x in range(image.n_ch)]
        # getting the channels used for MILWRM clustering and scaling the image
        img_ar = image.img[:, :, features]
        w, h, d = img_ar.shape
        scaled_img_ar = scaler.transform(img_ar.reshape((w * h, d)))
        scaled_img_ar = scaled_img_ar.reshape((w, h, d))
        ar = tissue_IDs[image_index]
        mse = {}
        for i in range(k):
            x = (
                (scaled_img_ar[ar == i]) - (centroids[i])
            ) ** 2  # estimating mse for each tissue ID for that image
            mse[i] = x.mean(axis=0)
        mse_temp[image_index] = mse
    mse_id = {}  # reorganizing within a new dictionary with keys as tissue IDs
    for i in range(k):
        mse_l = []
        for image_index, image in enumerate(images):
            mse_l.append(mse_temp[image_index][i])
            mse_id[i] = mse_l
    return mse_id</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_mse_st"><code class="name flex">
<span>def <span class="ident">estimate_mse_st</span></span>(<span>cluster_data, adatas, centroids, k)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate mean square error for each tissue ID for each visium slide</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cluster_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>np.ndarray containing cluster_data used for kmeans</dd>
<dt><strong><code>adatas</code></strong> :&ensp;<code> list</code></dt>
<dd>list of anndata.AnnData objects for visium slides</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code></dt>
<dd>number of tissue domains</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mse_id</code></strong> :&ensp;<code>dict</code></dt>
<dd>containing mean square error for each tissue for each visium slide</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_mse_st(cluster_data, adatas, centroids, k):
    &#34;&#34;&#34;
    Estimate mean square error for each tissue ID for each visium slide

    Parameters
    ----------
    cluster_data : np.ndarray
        np.ndarray containing cluster_data used for kmeans
    adatas :  list
        list of anndata.AnnData objects for visium slides
    centroids : np.ndarray
        kmeans cluster centroids
    k : int
        number of tissue domains

    Returns
    -------
    mse_id : dict
        containing mean square error for each tissue for each visium slide
    &#34;&#34;&#34;
    mse_id = {}
    for i in range(k):
        i_slice = 0
        j_slice = 0
        diff = []
        for adata in adatas:
            j_slice = j_slice + adata.n_obs
            df = pd.DataFrame(adata.obs[&#34;tissue_ID&#34;])
            df[&#34;index&#34;] = list(range(adata.n_obs))
            data = cluster_data[
                i_slice:j_slice
            ]  # slicing cluster data for sub_cluster_data for that visium slide
            x = (
                (data[df[df[&#34;tissue_ID&#34;] == i][&#34;index&#34;]]) - (centroids[i])
            ) ** 2  # difference between each data point and centroids
            if len(x) == 0:
                diff.append(np.zeros((centroids.shape[1])))
            else:
                mse = x.mean(axis=0)  # mean of all the differences
                # diff.append(mse.mean(axis = 0))
                diff.append(mse)
            i_slice = adata.n_obs
        mse_id[i] = diff
    return mse_id</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_percentage_variance_mxif"><code class="name flex">
<span>def <span class="ident">estimate_percentage_variance_mxif</span></span>(<span>image, use_path, scaler, centroids, features, tissue_ID)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate percentage variance explained by clustering for an image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code><a title="MILWRM.MxIF.img" href="MxIF.html#MILWRM.MxIF.img">img</a></code> or <code>str</code></dt>
<dd>np.array containing MxIF data or path to the compressed npz file</dd>
<dt><strong><code>use_path</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>True if image is given as a path to the compressed npz file, False if image is
given as MILWRM.MxIF.img object</dd>
<dt><strong><code>scaler</code></strong> :&ensp;<code>standardscaler() object</code></dt>
<dd>standard scaler used for cluster data normalization</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>tissue_ID</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>numpy array containing kmeans labels on image</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>S_square_pct</code></strong> :&ensp;<code>float</code></dt>
<dd>percentage variance in data explained by the kmeans clustering</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_percentage_variance_mxif(
    image, use_path, scaler, centroids, features, tissue_ID
):
    &#34;&#34;&#34;
    Estimate percentage variance explained by clustering for an image

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    scaler : standardscaler() object
        standard scaler used for cluster data normalization
    centroids : np.ndarray
        kmeans cluster centroids
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    tissue_ID : np.ndarray
        numpy array containing kmeans labels on image

    Returns
    -------
    S_square_pct : float
        percentage variance in data explained by the kmeans clustering

    &#34;&#34;&#34;
    if use_path == True:
        image_path = image + &#34;.npz&#34;
        image = img.from_npz(image_path)
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    if isinstance(features, str):  # force features into int if single string
        features = [image.ch.index(features)]
    if checktype(features):  # force features into list of int if list of strings
        features = [image.ch.index(x) for x in features]
    if features is None:  # if no features are given, use all of them
        features = [x for x in range(image.n_ch)]
    # getting the channels used for MILWRM clustering and scaling the image
    w, h, d = image.img[:, :, features].shape
    img_ar = image.img[:, :, features].reshape((w * h), d)
    scaled_img_ar = scaler.transform(img_ar)
    tissue_ID = tissue_ID.reshape(w * h)
    # init a numpy array of image shape to store the distance from pixels to centroids
    dc = np.zeros(scaled_img_ar.shape)
    for i in range(centroids.shape[0]):
        dc[tissue_ID == i] = ((scaled_img_ar[tissue_ID == i]) - (centroids[i])) ** 2
    # estimating the difference between pixels and the image mean
    dm = ((scaled_img_ar) - (scaled_img_ar.mean(axis=0))) ** 2
    # taking ratio of sum of differences for all points from centroids and data mean
    S_square = np.sum(dc) / np.sum(dm)
    S_square_pct = S_square * 100
    return S_square_pct</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.estimate_percentage_variance_st"><code class="name flex">
<span>def <span class="ident">estimate_percentage_variance_st</span></span>(<span>sub_cluster_data, adata, centroids)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate percentage variance explained by clustering for a visium slide</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sub_cluster_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>np.ndarray containing data for that visium slide used for kmeans</dd>
<dt><strong><code>adata</code></strong> :&ensp;<code>anndata.AnnData</code></dt>
<dd>AnnData object containing Visium data</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>S_square_pct</code></strong> :&ensp;<code>float</code></dt>
<dd>percentage variance in data explained by the kmeans clustering</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_percentage_variance_st(sub_cluster_data, adata, centroids):
    &#34;&#34;&#34;
    Estimate percentage variance explained by clustering for a visium slide

    Parameters
    ----------
    sub_cluster_data : np.ndarray
        np.ndarray containing data for that visium slide used for kmeans
    adata : anndata.AnnData
        AnnData object containing Visium data
    centroids : np.ndarray
        kmeans cluster centroids

    Returns
    -------
    S_square_pct : float
        percentage variance in data explained by the kmeans clustering

    &#34;&#34;&#34;
    dc = []
    df = pd.DataFrame(adata.obs[&#34;tissue_ID&#34;])
    ids = pd.unique(df[&#34;tissue_ID&#34;])
    df[&#34;index&#34;] = list(range(adata.n_obs))
    for i in ids:
        # estimating euclidean distance from the data point to closest centroid
        diff = (
            (sub_cluster_data[df[df[&#34;tissue_ID&#34;] == i][&#34;index&#34;]]) - (centroids[i])
        ) ** 2
        dc.append(diff)
    dc = np.row_stack(dc)
    # estimating euclidean distance from each data point to the mean of the data
    dm = (sub_cluster_data - sub_cluster_data.mean(axis=0)) ** 2
    # getting sum across features
    # taking ratio of sum of distances for all data points from centroids and data mean
    S = np.sum(dc) / np.sum(dm)
    S_square_pct = S * 100
    return S_square_pct</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.kMeansRes"><code class="name flex">
<span>def <span class="ident">kMeansRes</span></span>(<span>scaled_data, k, alpha_k=0.02, random_state=18)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates inertia value for a given k value by fitting k-means model to scaled data</p>
<p>Adapted from
<a href="https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c">https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scaled_data</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Scaled data. Rows are samples and columns are features for clustering</dd>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code></dt>
<dd>Current k for applying KMeans</dd>
<dt><strong><code>alpha_k</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor that gives penalty to the number of clusters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>scaled_inertia</code></strong> :&ensp;<code>float</code></dt>
<dd>Scaled inertia value for current k</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kMeansRes(scaled_data, k, alpha_k=0.02, random_state=18):
    &#34;&#34;&#34;
    Calculates inertia value for a given k value by fitting k-means model to scaled data

    Adapted from
    https://towardsdatascience.com/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c

    Parameters
    ----------
    scaled_data: np.array
        Scaled data. Rows are samples and columns are features for clustering
    k: int
        Current k for applying KMeans
    alpha_k: float
        Manually tuned factor that gives penalty to the number of clusters

    Returns
    -------
    scaled_inertia: float
        Scaled inertia value for current k
    &#34;&#34;&#34;
    inertia_o = np.square((scaled_data - scaled_data.mean(axis=0))).sum()
    # fit k-means
    kmeans = KMeans(n_clusters=k, random_state=random_state).fit(scaled_data)
    scaled_inertia = kmeans.inertia_ / inertia_o + alpha_k * k
    return scaled_inertia</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.perform_umap"><code class="name flex">
<span>def <span class="ident">perform_umap</span></span>(<span>cluster_data, centroids, batch_labels, kmeans_labels, frac)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute umap coordinates for the given cluster_data</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cluster_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>containing data used to build kmeans model</dd>
<dt><strong><code>centroids</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>kmeans cluster centroids</dd>
<dt><strong><code>batch_labels</code></strong> :&ensp;<code>list</code></dt>
<dd>list containing batch label for each datapoint</dd>
<dt><strong><code>kmeans_label</code></strong> :&ensp;<code>list</code></dt>
<dd>list containing tissue ID labels for each datapoint</dd>
<dt><strong><code>frac</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>if None entire cluster_data is used to compute umap if float
that fraction of data is used to compute the umap</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>umap_centroid_data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>combined dataframe with cluster_data used for computation
of Umap, centroids, batch_labels and kmeans_labels</dd>
<dt><strong><code>standard_embedding</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>containing umap coordinates</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def perform_umap(cluster_data, centroids, batch_labels, kmeans_labels, frac):
    &#34;&#34;&#34;
    Compute umap coordinates for the given cluster_data

    Parameters
    ----------
    cluster_data : np.ndarray
        containing data used to build kmeans model
    centroids : np.ndarray
        kmeans cluster centroids
    batch_labels : list
        list containing batch label for each datapoint
    kmeans_label : list
        list containing tissue ID labels for each datapoint
    frac : None or float
        if None entire cluster_data is used to compute umap if float
        that fraction of data is used to compute the umap

    Returns
    -------
    umap_centroid_data : pd.DataFrame
        combined dataframe with cluster_data used for computation
        of Umap, centroids, batch_labels and kmeans_labels
    standard_embedding : pd.DataFrame
        containing umap coordinates
    &#34;&#34;&#34;
    df = pd.DataFrame(cluster_data, batch_labels)
    df[&#34;Kmeans_labels&#34;] = kmeans_labels
    # if cluster_data is too big randomly subsample a fraction of it otherwise use the
    # entire data
    if frac:
        umap_data = pd.DataFrame()
        for i in np.unique(batch_labels):
            umap_data = pd.concat([umap_data, df.loc[i].sample(frac=frac)])
    else:
        umap_data = df
    # append the centroids to the dataframe with a different index and kmeans labels
    centroids = pd.DataFrame(
        centroids, index=[umap_data.index[-1] + 1] * len(centroids)
    )
    centroids[&#34;Kmeans_labels&#34;] = [kmeans_labels.max() + 1] * len(centroids)
    umap_centroid_data = pd.concat([umap_data, centroids])
    # compute umap
    neighbours = int(len(umap_centroid_data) ** 0.5)
    mapper = umap.UMAP(random_state=42, n_neighbors=neighbours).fit(
        umap_centroid_data.loc[:, umap_centroid_data.columns != &#34;Kmeans_labels&#34;]
    )
    standard_embedding = mapper.transform(
        umap_centroid_data.loc[:, umap_centroid_data.columns != &#34;Kmeans_labels&#34;]
    )
    return umap_centroid_data, standard_embedding</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.prep_data_single_sample_mxif"><code class="name flex">
<span>def <span class="ident">prep_data_single_sample_mxif</span></span>(<span>image, use_path, mean, filter_name, sigma, features, fract, path_save)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform log normalization, and blurring on the given image data</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code><a title="MILWRM.MxIF.img" href="MxIF.html#MILWRM.MxIF.img">img</a></code> or <code>str</code></dt>
<dd>np.array containing MxIF data or path to the compressed npz file</dd>
<dt><strong><code>use_path</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>True if image is given as a path to the compressed npz file, False if image is
given as MILWRM.MxIF.img object</dd>
<dt><strong><code>mean</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Containing mean for each channel for that batch</dd>
<dt><strong><code>filter_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the filter to use - gaussian, median or bilateral</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Standard deviation of Gaussian kernel for blurring</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>fract</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Fraction of cluster data from each image to randomly select for model
building</dd>
<dt><strong><code>path_save</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to save final preprocessed files</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>Subsampled_data</code></strong> :&ensp;<code>np.array</code></dt>
<dd>np.array containing randomly sampled pixels for that image</dd>
<dt><strong><code>file_save</code></strong> :&ensp;<code>str</code></dt>
<dd>path to save preprocessed img object</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_data_single_sample_mxif(
    image, use_path, mean, filter_name, sigma, features, fract, path_save
):
    &#34;&#34;&#34;
    Perform log normalization, and blurring on the given image data

    Parameters
    ----------
    image : MILWRM.MxIF.img or str
        np.array containing MxIF data or path to the compressed npz file
    use_path : Boolean
        True if image is given as a path to the compressed npz file, False if image is
        given as MILWRM.MxIF.img object
    mean : numpy array
        Containing mean for each channel for that batch
    filter_name : str
        Name of the filter to use - gaussian, median or bilateral
    sigma : float, optional
        Standard deviation of Gaussian kernel for blurring
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    fract : float, optional
        Fraction of cluster data from each image to randomly select for model
        building
    path_save : str
        Path to save final preprocessed files
    Returns
    -------
    Subsampled_data : np.array
        np.array containing randomly sampled pixels for that image
    file_save : str
        path to save preprocessed img object
    &#34;&#34;&#34;
    if use_path == True:  # if images are given as path to the compressed npz file
        if path_save == None:  # check if path to save final processed file is given
            raise Exception(
                &#34;Path to save final preprocessed npz files is requird when given path to image files&#34;
            )
        image_path = image
        image = img.from_npz(image_path + &#34;.npz&#34;)
    # batch correction
    image.log_normalize(mean=mean)
    # apply the desired filter
    image.blurring(filter_name=filter_name, sigma=sigma)
    # min max scaling of each channel
    # for i in range(image.img.shape[2]):
    #     img_ar = image.img[:, :, i][image.mask != 0]
    #     img_ar_max = img_ar.max()
    #     img_ar_min = img_ar.min()
    #     # print(img_ar_max, img_ar_min)
    #     image_ar_scaled = (image.img[:, :, i] - img_ar_min) / (img_ar_max - img_ar_min)
    #     image.img[:, :, i] = image_ar_scaled
    # subsample pixels to build the kmeans model
    subsampled_data = image.subsample_pixels(features, fract)
    if use_path == True:
        new_image_path = os.path.join(path_save, &#34;_final_preprocessed_images&#34;)
        if not os.path.exists(new_image_path):
            os.mkdir(new_image_path)
        file_name = image_path.split(&#34;/&#34;)[-1] + &#34;_final_preprocessed&#34;
        file_save = os.path.join(new_image_path, file_name)
        image.to_npz(file_save)
        return subsampled_data, file_save
    return subsampled_data</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.prep_data_single_sample_st"><code class="name flex">
<span>def <span class="ident">prep_data_single_sample_st</span></span>(<span>adata, adata_i, use_rep, features, histo, fluor_channels, spatial_graph_key=None, n_rings=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare dataframe for tissue-level clustering from a single AnnData sample</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adata</code></strong> :&ensp;<code>anndata.AnnData</code></dt>
<dd>AnnData object containing Visium data</dd>
<dt><strong><code>adata_i</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of AnnData object for identification within <code><a title="MILWRM.MILWRM.st_labeler" href="#MILWRM.MILWRM.st_labeler">st_labeler</a></code> object</dd>
<dt><strong><code>use_rep</code></strong> :&ensp;<code>str</code></dt>
<dd>Representation from <code>adata.obsm</code> to use as clustering data (e.g. "X_pca")</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of features to use from <code>adata.obsm[use_rep]</code> (e.g. [0,1,2,3,4] to
use first 5 principal components when <code>use_rep</code>="X_pca"). If <code>None</code>, use
all features from <code>adata.obsm[use_rep]</code></dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>bool</code>, optional <code>(default </code>False<code>)</code></dt>
<dd>Use histology data from Visium anndata object (R,G,B brightfield features)
in addition to <code>adata.obsm[use_rep]</code>? If fluorescent imaging data rather
than brightfield, use <code>fluor_channels</code> argument instead.</dd>
<dt><strong><code>fluor_channels</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default </code>None<code>)</code></dt>
<dd>Channels from fluorescent image to use for model training (e.g. [1,3] for
channels 1 and 3 of Visium fluorescent imaging data). If <code>None</code>, do not
use imaging data for training.</dd>
<dt><strong><code>spatial_graph_key</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Key in <code>adata.obsp</code> containing spatial graph connectivities (i.e.
<code>"spatial_connectivities"</code>). If <code>None</code>, compute new spatial graph using
<code>n_rings</code> in <code>squidpy</code>.</dd>
<dt><strong><code>n_rings</code></strong> :&ensp;<code>int</code>, optional <code>(default=1)</code></dt>
<dd>Number of hexagonal rings around each spatial transcriptomics spot to blur
features by for capturing regional information. Assumes 10X Genomics Visium
platform.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Clustering data from <code>adata.obsm[use_rep]</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_data_single_sample_st(
    adata,
    adata_i,
    use_rep,
    features,
    histo,
    fluor_channels,
    spatial_graph_key=None,
    n_rings=1,
):
    &#34;&#34;&#34;
    Prepare dataframe for tissue-level clustering from a single AnnData sample

    Parameters
    ----------
    adata : anndata.AnnData
        AnnData object containing Visium data
    adata_i : int
        Index of AnnData object for identification within `st_labeler` object
    use_rep : str
        Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
    features : list of int or None, optional (default=`None`)
        List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
        use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
        all features from `adata.obsm[use_rep]`
    histo : bool, optional (default `False`)
        Use histology data from Visium anndata object (R,G,B brightfield features)
        in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
        than brightfield, use `fluor_channels` argument instead.
    fluor_channels : list of int or None, optional (default `None`)
        Channels from fluorescent image to use for model training (e.g. [1,3] for
        channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
        use imaging data for training.
    spatial_graph_key : str, optional (default=`None`)
        Key in `adata.obsp` containing spatial graph connectivities (i.e.
        `&#34;spatial_connectivities&#34;`). If `None`, compute new spatial graph using
        `n_rings` in `squidpy`.
    n_rings : int, optional (default=1)
        Number of hexagonal rings around each spatial transcriptomics spot to blur
        features by for capturing regional information. Assumes 10X Genomics Visium
        platform.

    Returns
    -------
    pd.DataFrame
        Clustering data from `adata.obsm[use_rep]`
    &#34;&#34;&#34;
    tmp = pd.DataFrame()
    tmp[[use_rep + &#34;_{}&#34;.format(x) for x in features]] = adata.obsm[use_rep][
        :, features
    ]
    if histo:
        assert (
            fluor_channels is None
        ), &#34;If histo is True, fluor_channels must be None. \
            Histology specifies brightfield H&amp;E with three (3) features.&#34;
        print(&#34;Adding mean RGB histology features for adata #{}&#34;.format(adata_i))
        tmp[[&#34;R_mean&#34;, &#34;G_mean&#34;, &#34;B_mean&#34;]] = adata.obsm[&#34;image_means&#34;]
    if fluor_channels:
        assert (
            histo is False
        ), &#34;If fluorescence channels are given, histo must be False. \
            Histology specifies brightfield H&amp;E with three (3) features.&#34;
        print(
            &#34;Adding mean fluorescent channels {} for adata #{}&#34;.format(
                fluor_channels, adata_i
            )
        )
        tmp[[&#34;ch_{}_mean&#34;.format(x) for x in fluor_channels]] = adata.obsm[
            &#34;image_means&#34;
        ][:, fluor_channels]
    if n_rings &gt; 0:
        # blur the features extracted in tmp
        tmp = blur_features_st(
            adata, tmp, spatial_graph_key=spatial_graph_key, n_rings=n_rings
        )
    return tmp</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="MILWRM.MILWRM.mxif_labeler"><code class="flex name class">
<span>class <span class="ident">mxif_labeler</span></span>
<span>(</span><span>image_df)</span>
</code></dt>
<dd>
<div class="desc"><p>Tissue domain labeling class for multiplex immunofluorescence (MxIF) data</p>
<p>Initialize MxIF tissue labeler class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image_df</code></strong> :&ensp;<code>pd.DataFrame object</code></dt>
<dd>Containing MILWRM.MxIF.img objects or str path to compressed npz files,
batch names, mean estimator and pixel count for each image in the
following column order ['Img', 'batch_names', 'mean estimators', 'pixels']</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.images</code> attribute is updated,
<code>self.cluster_data</code> attribute is initiated as <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class mxif_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue domain labeling class for multiplex immunofluorescence (MxIF) data
    &#34;&#34;&#34;

    def __init__(self, image_df):
        &#34;&#34;&#34;
        Initialize MxIF tissue labeler class

        Parameters
        ----------
        image_df : pd.DataFrame object
            Containing MILWRM.MxIF.img objects or str path to compressed npz files,
            batch names, mean estimator and pixel count for each image in the
            following column order [&#39;Img&#39;, &#39;batch_names&#39;, &#39;mean estimators&#39;, &#39;pixels&#39;]

        Returns
        -------
        Does not return anything. `self.images` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        # validate the format of the image_df dataframe
        if np.all(
            image_df.columns == [&#34;Img&#34;, &#34;batch_names&#34;, &#34;mean estimators&#34;, &#34;pixels&#34;]
        ):
            self.image_df = image_df
        else:
            raise Exception(
                &#34;Image_df must be given with these columns in this format [&#39;Img&#39;, &#39;batch_names&#39;, &#39;mean estimators&#39;, &#39;pixels&#39;]&#34;
            )
        if self.image_df[&#34;Img&#34;].apply(isinstance, args=[img]).all():
            self.use_paths = False
        elif self.image_df[&#34;Img&#34;].apply(isinstance, args=[str]).all():
            self.use_paths = True
        else:
            raise Exception(
                &#34;Img column in the dataframe should be either str for paths to the files or mxif.img object&#34;
            )

    def prep_cluster_data(
        self, features, filter_name=&#34;gaussian&#34;, sigma=2, fract=0.2, path_save=None
    ):
        &#34;&#34;&#34;
        Prepare master array for tissue level clustering

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        filter_name : str
            Name of the filter to use - gaussian, median or bilateral
        sigma : float, optional (default=2)
            Standard deviation of Gaussian kernel for blurring
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select for model
            building
        path_save : str (default = None)
            Path to save final preprocessed files, if self.use_path is True
            default path_save will raise Exception

        Returns
        -------
        Does not return anything. `self.images` are normalized, blurred and scaled
        according to user parameters. `self.cluster_data` becomes master `np.array`
        for cluster training. Parameters are also captured as attributes for posterity.

        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        # save the hyperparams as object attributes
        self.model_features = features
        use_path = self.use_paths
        # calculate the batch wise means
        mean_for_each_batch = {}
        for batch in self.image_df[&#34;batch_names&#34;].unique():
            list_mean_estimators = list(
                self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;mean estimators&#34;]
            )
            mean_estimator_batch = sum(map(np.array, list_mean_estimators))
            pixels = sum(self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;pixels&#34;])
            mean_for_each_batch[batch] = mean_estimator_batch / pixels
        # log_normalize, apply blurring filter, minmax scale each channel and subsample
        subsampled_data = []
        path_to_blurred_npz = []
        for image, batch in zip(self.image_df[&#34;Img&#34;], self.image_df[&#34;batch_names&#34;]):
            tmp = prep_data_single_sample_mxif(
                image,
                use_path=use_path,
                mean=mean_for_each_batch[batch],
                filter_name=filter_name,
                sigma=sigma,
                features=self.model_features,
                fract=fract,
                path_save=path_save,
            )
            if self.use_paths == True:
                subsampled_data.append(tmp[0])
                path_to_blurred_npz.append(tmp[1])
            else:
                subsampled_data.append(tmp)
        batch_labels = [
            [x] * len(subsampled_data[x]) for x in range(len(subsampled_data))
        ]  # batch labels for umap
        self.merged_batch_labels = list(itertools.chain(*batch_labels))
        if self.use_paths == True:
            self.image_df[&#34;Img&#34;] = path_to_blurred_npz
        cluster_data = np.row_stack(subsampled_data)
        # perform z-score normalization on cluster_Data
        scaler = StandardScaler()
        self.scaler = scaler.fit(cluster_data)
        scaled_data = scaler.transform(cluster_data)
        self.cluster_data = scaled_data

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        images.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if scaled inertia plot should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model
        n_jobs : int
            Number of cores to parallelize k-choosing and tissue ID assignment across.
            Default all available cores.

        Returns
        -------
        Does not return anything. `self.tissue_ID` is added, containing image with
        final tissue region IDs. `self.kmeans` contains trained `sklearn` clustering
        model. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # save the hyperparams as object attributes
        use_path = self.use_paths
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                alpha=alpha,
                plot_out=plot_out,
                random_state=random_state,
                n_jobs=n_jobs,
            )
        # call k-means model from parent class
        self.find_tissue_regions(k=k, random_state=random_state)
        # loop through image objects and create tissue label images
        print(&#34;Creating tissue_ID images for image objects...&#34;)
        self.tissue_IDs = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(add_tissue_ID_single_sample_mxif)(
                image, use_path, self.model_features, self.kmeans, self.scaler
            )
            for image in self.image_df[&#34;Img&#34;]
        )

    def plot_percentage_variance_explained(
        self, fig_size=(5, 5), R_square=False, save_to=None
    ):
        &#34;&#34;&#34;
        plot percentage variance_explained or not explained by clustering

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        R_square : Boolean
            Decides if R_square is plotted or S_square
        save_to : str or None
            Path to image file to save results. If `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        use_path = self.use_paths
        S_squre_for_each_image = []
        R_squre_for_each_image = []
        for image, tissue_ID in zip(self.image_df[&#34;Img&#34;], self.tissue_IDs):
            S_square = estimate_percentage_variance_mxif(
                image, use_path, scaler, centroids, features, tissue_ID
            )
            S_squre_for_each_image.append(S_square)
            R_squre_for_each_image.append(100 - S_square)

        if R_square == True:
            fig = plt.figure(figsize=fig_size)
            fig = plt.figure(figsize=(5, 5))
            plt.scatter(
                range(len(R_squre_for_each_image)),
                R_squre_for_each_image,
                color=&#34;black&#34;,
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(R_squre_for_each_image),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        else:
            fig = plt.figure(figsize=fig_size)
            plt.scatter(
                range(len(S_squre_for_each_image)),
                S_squre_for_each_image,
                color=&#34;black&#34;,
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(S_squre_for_each_image),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def confidence_score_images(self):
        &#34;&#34;&#34;
        estimate confidence score for each image

        Parameters
        ----------

        Returns
        -------
        self.confidence_IDs and self.confidence_score_df is added containing
        confidence score for each tissue ID assignment and mean confidence score for
        each tissue ID within each image
        &#34;&#34;&#34;
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        tissue_IDs = self.tissue_IDs
        use_path = self.use_paths
        # confidence score estimation for each image
        confidence_IDs = []
        confidence_score_df = pd.DataFrame()
        for i, image in enumerate(self.image_df[&#34;Img&#34;]):
            cID, scores_dict = estimate_confidence_score_mxif(
                image, use_path, scaler, centroids, features, tissue_IDs[i]
            )
            confidence_IDs.append(cID)
            df = pd.DataFrame(scores_dict.values(), columns=[i])
            confidence_score_df = pd.concat(
                [confidence_score_df, df.T], ignore_index=True
            )
        # adding confidence_IDs and confidence_score_df to tissue labeller object
        self.confidence_IDs = confidence_IDs
        self.confidence_score_df = confidence_score_df

    def plot_mse_mxif(
        self,
        figsize=(5, 5),
        ncols=None,
        labels=None,
        legend_cols=2,
        titles=None,
        loc=&#34;lower right&#34;,
        bbox_coordinates=(0, 0, 1.5, 1.5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        estimate mean square error within each tissue ID

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        labels : list of str, optional (default=`None`)
            Labels corresponding to each image in legend. If `None`, numeric index is
            used for each imaage
        legend_cols : int, optional (default = `2`)
            n_cols for legend
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        loc : str, optional (default = &#39;lower right&#39;)
            str for legend position
        bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
            coordinates for the legend box
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        images = self.image_df[&#34;Img&#34;]
        use_path = self.use_paths
        scaler = self.scaler
        centroids = self.kmeans.cluster_centers_
        features = self.model_features
        k = self.k
        features = self.model_features
        tissue_IDs = self.tissue_IDs
        mse_id = estimate_mse_mxif(
            images, use_path, tissue_IDs, scaler, centroids, features, k
        )
        if labels is None:
            labels = range(len(images))
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        n_panels = len(mse_id.keys())
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        colors = plt.cm.tab20(np.linspace(0, 1, len(images)))
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in mse_id.keys():
            plt.subplot(gs[i])
            df = pd.DataFrame.from_dict(mse_id[i])
            plt.boxplot(df, positions=range(len(features)), showfliers=False)
            plt.xticks(
                ticks=range(len(features)),
                labels=self.model_features,
                rotation=60,
                fontsize=8,
            )
            for col in df:
                for k in range(len(images)):
                    dots = plt.scatter(
                        col,
                        df[col][k],
                        s=k + 1,
                        color=colors[k],
                        label=labels[k] if col == 0 else &#34;&#34;,
                    )
                    offsets = dots.get_offsets()
                    jittered_offsets = offsets
                    # only jitter in the x-direction
                    jittered_offsets[:, 0] += np.random.uniform(
                        -0.3, 0.3, offsets.shape[0]
                    )
                    dots.set_offsets(jittered_offsets)
            plt.xlabel(&#34;marker&#34;)
            plt.ylabel(&#34;mean square error&#34;)
            plt.title(titles[i])
        plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates, ncol=legend_cols)
        gs.tight_layout(fig)
        if save_to:
            plt.savefig(fname=save_to, transparent=True, dpi=300)
        return fig

    def plot_tissue_ID_proportions_mxif(
        self,
        tID_labels=None,
        slide_labels=None,
        figsize=(5, 5),
        cmap=&#34;tab20&#34;,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot proportion of each tissue ID within each slide

        Parameters
        ----------
        tID_labels : list of str, optional (default=`None`)
            List of labels corresponding to MILWRM tissue IDs for plotting legend
        slide_labels : list of str, optional (default=`None`)
            List of labels for each slide batch for labeling x-axis
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        cmap : str, optional (default = `&#34;tab20&#34;`)
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        df_count = pd.DataFrame()
        for i in range(len(self.tissue_IDs)):
            unique, counts = np.unique(self.tissue_IDs[i], return_counts=True)
            dict_ = dict(zip(unique, counts))
            n_counts = []
            for k in range(self.k):
                if k not in dict_.keys():
                    n_counts.append(0)
                else:
                    n_counts.append(dict_[k])
            df = pd.DataFrame(n_counts, columns=[i])
            df_count = pd.concat([df_count, df], axis=1)
        df_count = df_count / df_count.sum()
        if tID_labels:
            assert (
                len(tID_labels) == df_count.shape[1]
            ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
            df_count.columns = tID_labels
        if slide_labels:
            assert (
                len(slide_labels) == df_count.shape[0]
            ), &#34;Length of given slide labels does not match number of slides!&#34;
            df_count.index = slide_labels
        self.tissue_ID_proportion = df_count
        ax = df_count.T.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
        ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
        ax.set_xlabel(&#34;images&#34;)
        ax.set_ylabel(&#34;tissue ID proportion&#34;)
        ax.set_ylim((0, 1))
        plt.tight_layout()
        if save_to is not None:
            ax.figure.savefig(save_to)
        else:
            return ax

    def make_umap(self, frac=None, cmap=&#34;tab20&#34;, save_to=None, alpha=0.8):
        &#34;&#34;&#34;
        plot umap for the cluster data

        Parameters
        ----------
        frac : None or float
            if None entire cluster data is used for the computation of umap
            else that percentage of cluster data is used.
        cmap : str
            str for cmap used for plotting. Default `&#34;tab20&#34;`.
        save_to : str or None
            Path to image file to save results. if `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        cluster_data = self.cluster_data
        centroids = self.kmeans.cluster_centers_
        batch_labels = self.merged_batch_labels
        kmeans_labels = self.kmeans.labels_
        k = self.k
        # perform umap on the cluster data
        umap_centroid_data, standard_embedding_1 = perform_umap(
            cluster_data=cluster_data,
            centroids=centroids,
            batch_labels=batch_labels,
            kmeans_labels=kmeans_labels,
            frac=frac,
        )
        # defining a size of datapoints for scatter plot and tick labels
        size = [0.01] * len(umap_centroid_data.index)
        size[-k:] = [10] * k
        ticks = np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;]))
        tick_label = list(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
        tick_label[-1] = &#34;centroids&#34;
        # plotting a fig with two subplots
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
        # defining color_map
        # TODO : add alpha here
        disc_cmap_1 = plt.cm.get_cmap(
            cmap, len(np.unique(np.array(umap_centroid_data.index)))
        )
        disc_cmap_2 = plt.cm.get_cmap(
            cmap, len(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
        )
        plot_1 = ax1.scatter(
            standard_embedding_1[:, 0],
            standard_embedding_1[:, 1],
            s=0.01,
            c=umap_centroid_data.index,
            cmap=disc_cmap_1,
            alpha=alpha,
        )
        ax1.set_title(&#34;Umap with batch labels&#34;)
        cbar_1 = plt.colorbar(plot_1, ax=ax1)
        plot_2 = ax2.scatter(
            standard_embedding_1[:, 0],
            standard_embedding_1[:, 1],
            s=size,
            c=umap_centroid_data[&#34;Kmeans_labels&#34;],
            cmap=disc_cmap_2,
            alpha=alpha,
        )
        ax2.set_title(&#34;Umap with tissue IDs&#34;)
        cbar_2 = plt.colorbar(plot_2, ax=ax2, ticks=ticks)
        cbar_2.ax.set_yticklabels(tick_label)
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def show_marker_overlay(
        self,
        image_index,
        channels=None,
        cmap=&#34;Set1&#34;,
        mask_out=True,
        ncols=4,
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot tissue_ID with individual markers as alpha values to distinguish
        expression in identified tissue domains

        Parameters
        ----------
        image_index : int
            Index of image from `self.images` to plot overlays for (e.g. 0 for first
            image)
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        cmap : str, optional (default=&#34;plasma&#34;)
            Matplotlib colormap to use for plotting tissue IDs
        mask_out : bool, optional (default=`True`)
            Mask out non-tissue pixels prior to showing
        ncols : int
            Number of columns for gridspec if plotting individual channels.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        # if image has multiple channels, plot them in gridspec
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self[image_index].ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self[image_index].ch.index(x) for x in channels]
        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self[image_index].n_ch)]
        assert (
            len(channels) &lt;= self[image_index].n_ch
        ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
            self[image_index].n_ch, len(channels)
        )
        # creating a copy of the image
        image_cp = self[image_index].copy()
        # re-scaling to set pixel value range between 0 to 1
        image_cp.scale()
        # defining cmap for discrete color bar
        cmap = plt.cm.get_cmap(cmap, self.k)
        # calculate gridspec dimensions
        if len(channels) + 1 &lt;= ncols:
            n_rows, n_cols = 1, len(channels) + 1
        else:
            n_rows, n_cols = ceil(len(channels) + 1 / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # plot tissue_ID first with colorbar
        ax = plt.subplot(gs[0])
        im = ax.imshow(self.tissue_IDs[image_index], cmap=cmap, **kwargs)
        ax.set_title(
            label=&#34;tissue_ID&#34;,
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        # colorbar scale for tissue_IDs
        _ = plt.colorbar(im, ticks=range(self.k), shrink=0.7)
        # add plots to axes
        i = 1
        for channel in channels:
            ax = plt.subplot(gs[i])
            # make copy for alpha
            im_tmp = image_cp.img[:, :, channel].copy()
            if self[image_index].mask is not None and mask_out:
                # area outside mask NaN
                self.tissue_IDs[image_index][self[image_index].mask == 0] = np.nan
                im = ax.imshow(
                    self.tissue_IDs[image_index], cmap=cmap, alpha=im_tmp, **kwargs
                )
            else:
                ax.imshow(self.tissue_IDs[image_index], alpha=im_tmp, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=self[image_index].ch[channel],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="MILWRM.MILWRM.tissue_labeler" href="#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.MILWRM.mxif_labeler.confidence_score_images"><code class="name flex">
<span>def <span class="ident">confidence_score_images</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>estimate confidence score for each image</p>
<h2 id="parameters">Parameters</h2>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self.confidence_IDs and self.confidence_score_df is added containing</code></dt>
<dd>&nbsp;</dd>
<dt><code>confidence score for each tissue ID assignment and mean confidence score for</code></dt>
<dd>&nbsp;</dd>
<dt><code>each tissue ID within each image</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confidence_score_images(self):
    &#34;&#34;&#34;
    estimate confidence score for each image

    Parameters
    ----------

    Returns
    -------
    self.confidence_IDs and self.confidence_score_df is added containing
    confidence score for each tissue ID assignment and mean confidence score for
    each tissue ID within each image
    &#34;&#34;&#34;
    scaler = self.scaler
    centroids = self.kmeans.cluster_centers_
    features = self.model_features
    tissue_IDs = self.tissue_IDs
    use_path = self.use_paths
    # confidence score estimation for each image
    confidence_IDs = []
    confidence_score_df = pd.DataFrame()
    for i, image in enumerate(self.image_df[&#34;Img&#34;]):
        cID, scores_dict = estimate_confidence_score_mxif(
            image, use_path, scaler, centroids, features, tissue_IDs[i]
        )
        confidence_IDs.append(cID)
        df = pd.DataFrame(scores_dict.values(), columns=[i])
        confidence_score_df = pd.concat(
            [confidence_score_df, df.T], ignore_index=True
        )
    # adding confidence_IDs and confidence_score_df to tissue labeller object
    self.confidence_IDs = confidence_IDs
    self.confidence_score_df = confidence_score_df</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.label_tissue_regions"><code class="name flex">
<span>def <span class="ident">label_tissue_regions</span></span>(<span>self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform tissue-level clustering and label pixels in the corresponding
images.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Number of tissue regions to define</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>boolean</code>, optional <code>(default=True)</code></dt>
<dd>Determines if scaled inertia plot should be output</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering model</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing and tissue ID assignment across.
Default all available cores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.tissue_ID</code> is added, containing image with
final tissue region IDs. <code>self.kmeans</code> contains trained <code>sklearn</code> clustering
model. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_tissue_regions(
    self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
):
    &#34;&#34;&#34;
    Perform tissue-level clustering and label pixels in the corresponding
    images.

    Parameters
    ----------
    k : int, optional (default=None)
        Number of tissue regions to define
    alpha: float
        Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
    plot_out : boolean, optional (default=True)
        Determines if scaled inertia plot should be output
    random_state : int, optional (default=18)
        Seed for k-means clustering model
    n_jobs : int
        Number of cores to parallelize k-choosing and tissue ID assignment across.
        Default all available cores.

    Returns
    -------
    Does not return anything. `self.tissue_ID` is added, containing image with
    final tissue region IDs. `self.kmeans` contains trained `sklearn` clustering
    model. Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    # save the hyperparams as object attributes
    use_path = self.use_paths
    # find optimal k with parent class
    if k is None:
        print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
        self.find_optimal_k(
            alpha=alpha,
            plot_out=plot_out,
            random_state=random_state,
            n_jobs=n_jobs,
        )
    # call k-means model from parent class
    self.find_tissue_regions(k=k, random_state=random_state)
    # loop through image objects and create tissue label images
    print(&#34;Creating tissue_ID images for image objects...&#34;)
    self.tissue_IDs = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(add_tissue_ID_single_sample_mxif)(
            image, use_path, self.model_features, self.kmeans, self.scaler
        )
        for image in self.image_df[&#34;Img&#34;]
    )</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.make_umap"><code class="name flex">
<span>def <span class="ident">make_umap</span></span>(<span>self, frac=None, cmap='tab20', save_to=None, alpha=0.8)</span>
</code></dt>
<dd>
<div class="desc"><p>plot umap for the cluster data</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>frac</code></strong> :&ensp;<code>None</code> or <code>float</code></dt>
<dd>if None entire cluster data is used for the computation of umap
else that percentage of cluster data is used.</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code></dt>
<dd>str for cmap used for plotting. Default <code>"tab20"</code>.</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. if <code>None</code>, show figure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_umap(self, frac=None, cmap=&#34;tab20&#34;, save_to=None, alpha=0.8):
    &#34;&#34;&#34;
    plot umap for the cluster data

    Parameters
    ----------
    frac : None or float
        if None entire cluster data is used for the computation of umap
        else that percentage of cluster data is used.
    cmap : str
        str for cmap used for plotting. Default `&#34;tab20&#34;`.
    save_to : str or None
        Path to image file to save results. if `None`, show figure.

    Returns
    -------
    Matplotlib object
    &#34;&#34;&#34;
    cluster_data = self.cluster_data
    centroids = self.kmeans.cluster_centers_
    batch_labels = self.merged_batch_labels
    kmeans_labels = self.kmeans.labels_
    k = self.k
    # perform umap on the cluster data
    umap_centroid_data, standard_embedding_1 = perform_umap(
        cluster_data=cluster_data,
        centroids=centroids,
        batch_labels=batch_labels,
        kmeans_labels=kmeans_labels,
        frac=frac,
    )
    # defining a size of datapoints for scatter plot and tick labels
    size = [0.01] * len(umap_centroid_data.index)
    size[-k:] = [10] * k
    ticks = np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;]))
    tick_label = list(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
    tick_label[-1] = &#34;centroids&#34;
    # plotting a fig with two subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    # defining color_map
    # TODO : add alpha here
    disc_cmap_1 = plt.cm.get_cmap(
        cmap, len(np.unique(np.array(umap_centroid_data.index)))
    )
    disc_cmap_2 = plt.cm.get_cmap(
        cmap, len(np.unique(np.array(umap_centroid_data[&#34;Kmeans_labels&#34;])))
    )
    plot_1 = ax1.scatter(
        standard_embedding_1[:, 0],
        standard_embedding_1[:, 1],
        s=0.01,
        c=umap_centroid_data.index,
        cmap=disc_cmap_1,
        alpha=alpha,
    )
    ax1.set_title(&#34;Umap with batch labels&#34;)
    cbar_1 = plt.colorbar(plot_1, ax=ax1)
    plot_2 = ax2.scatter(
        standard_embedding_1[:, 0],
        standard_embedding_1[:, 1],
        s=size,
        c=umap_centroid_data[&#34;Kmeans_labels&#34;],
        cmap=disc_cmap_2,
        alpha=alpha,
    )
    ax2.set_title(&#34;Umap with tissue IDs&#34;)
    cbar_2 = plt.colorbar(plot_2, ax=ax2, ticks=ticks)
    cbar_2.ax.set_yticklabels(tick_label)
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.plot_mse_mxif"><code class="name flex">
<span>def <span class="ident">plot_mse_mxif</span></span>(<span>self, figsize=(5, 5), ncols=None, labels=None, legend_cols=2, titles=None, loc='lower right', bbox_coordinates=(0, 0, 1.5, 1.5), save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>estimate mean square error within each tissue ID</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fig_size</code></strong> :&ensp;<code>Tuple</code></dt>
<dd>size for the bar plot</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Number of columns for gridspec. If <code>None</code>, uses number of tissue domains k.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Labels corresponding to each image in legend. If <code>None</code>, numeric index is
used for each imaage</dd>
<dt><strong><code>legend_cols</code></strong> :&ensp;<code>int</code>, optional <code>(default =</code>2<code>)</code></dt>
<dd>n_cols for legend</dd>
<dt><strong><code>titles</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Titles of plots corresponding to each MILWRM domain. If <code>None</code>, titles
will be numbers 0 through k.</dd>
<dt><strong><code>loc</code></strong> :&ensp;<code>str</code>, optional <code>(default = 'lower right')</code></dt>
<dd>str for legend position</dd>
<dt><strong><code>bbox_coordinates</code></strong> :&ensp;<code>Tuple</code>, optional <code>(default = (0,0,1.5,1.5))</code></dt>
<dd>coordinates for the legend box</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_mse_mxif(
    self,
    figsize=(5, 5),
    ncols=None,
    labels=None,
    legend_cols=2,
    titles=None,
    loc=&#34;lower right&#34;,
    bbox_coordinates=(0, 0, 1.5, 1.5),
    save_to=None,
):
    &#34;&#34;&#34;
    estimate mean square error within each tissue ID

    Parameters
    ----------
    fig_size : Tuple
        size for the bar plot
    ncols : int, optional (default=`None`)
        Number of columns for gridspec. If `None`, uses number of tissue domains k.
    labels : list of str, optional (default=`None`)
        Labels corresponding to each image in legend. If `None`, numeric index is
        used for each imaage
    legend_cols : int, optional (default = `2`)
        n_cols for legend
    titles : list of str, optional (default=`None`)
        Titles of plots corresponding to each MILWRM domain. If `None`, titles
        will be numbers 0 through k.
    loc : str, optional (default = &#39;lower right&#39;)
        str for legend position
    bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
        coordinates for the legend box
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    Matplotlib object
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    images = self.image_df[&#34;Img&#34;]
    use_path = self.use_paths
    scaler = self.scaler
    centroids = self.kmeans.cluster_centers_
    features = self.model_features
    k = self.k
    features = self.model_features
    tissue_IDs = self.tissue_IDs
    mse_id = estimate_mse_mxif(
        images, use_path, tissue_IDs, scaler, centroids, features, k
    )
    if labels is None:
        labels = range(len(images))
    if titles is None:
        titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
    n_panels = len(mse_id.keys())
    if ncols is None:
        ncols = len(titles)
    if n_panels &lt;= ncols:
        n_rows, n_cols = 1, n_panels
    else:
        n_rows, n_cols = ceil(n_panels / ncols), ncols
    colors = plt.cm.tab20(np.linspace(0, 1, len(images)))
    fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
    left, bottom = 0.1 / n_cols, 0.1 / n_rows
    gs = gridspec.GridSpec(
        nrows=n_rows,
        ncols=n_cols,
        left=left,
        bottom=bottom,
        right=1 - (n_cols - 1) * left - 0.01 / n_cols,
        top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
    )
    for i in mse_id.keys():
        plt.subplot(gs[i])
        df = pd.DataFrame.from_dict(mse_id[i])
        plt.boxplot(df, positions=range(len(features)), showfliers=False)
        plt.xticks(
            ticks=range(len(features)),
            labels=self.model_features,
            rotation=60,
            fontsize=8,
        )
        for col in df:
            for k in range(len(images)):
                dots = plt.scatter(
                    col,
                    df[col][k],
                    s=k + 1,
                    color=colors[k],
                    label=labels[k] if col == 0 else &#34;&#34;,
                )
                offsets = dots.get_offsets()
                jittered_offsets = offsets
                # only jitter in the x-direction
                jittered_offsets[:, 0] += np.random.uniform(
                    -0.3, 0.3, offsets.shape[0]
                )
                dots.set_offsets(jittered_offsets)
        plt.xlabel(&#34;marker&#34;)
        plt.ylabel(&#34;mean square error&#34;)
        plt.title(titles[i])
    plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates, ncol=legend_cols)
    gs.tight_layout(fig)
    if save_to:
        plt.savefig(fname=save_to, transparent=True, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.plot_percentage_variance_explained"><code class="name flex">
<span>def <span class="ident">plot_percentage_variance_explained</span></span>(<span>self, fig_size=(5, 5), R_square=False, save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>plot percentage variance_explained or not explained by clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fig_size</code></strong> :&ensp;<code>Tuple</code></dt>
<dd>size for the bar plot</dd>
<dt><strong><code>R_square</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>Decides if R_square is plotted or S_square</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_percentage_variance_explained(
    self, fig_size=(5, 5), R_square=False, save_to=None
):
    &#34;&#34;&#34;
    plot percentage variance_explained or not explained by clustering

    Parameters
    ----------
    fig_size : Tuple
        size for the bar plot
    R_square : Boolean
        Decides if R_square is plotted or S_square
    save_to : str or None
        Path to image file to save results. If `None`, show figure.

    Returns
    -------
    Matplotlib object
    &#34;&#34;&#34;
    scaler = self.scaler
    centroids = self.kmeans.cluster_centers_
    features = self.model_features
    use_path = self.use_paths
    S_squre_for_each_image = []
    R_squre_for_each_image = []
    for image, tissue_ID in zip(self.image_df[&#34;Img&#34;], self.tissue_IDs):
        S_square = estimate_percentage_variance_mxif(
            image, use_path, scaler, centroids, features, tissue_ID
        )
        S_squre_for_each_image.append(S_square)
        R_squre_for_each_image.append(100 - S_square)

    if R_square == True:
        fig = plt.figure(figsize=fig_size)
        fig = plt.figure(figsize=(5, 5))
        plt.scatter(
            range(len(R_squre_for_each_image)),
            R_squre_for_each_image,
            color=&#34;black&#34;,
        )
        plt.xlabel(&#34;images&#34;)
        plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
        plt.ylim((0, 100))
        plt.axhline(
            y=np.mean(R_squre_for_each_image),
            linestyle=&#34;dashed&#34;,
            linewidth=1,
            color=&#34;black&#34;,
        )

    else:
        fig = plt.figure(figsize=fig_size)
        plt.scatter(
            range(len(S_squre_for_each_image)),
            S_squre_for_each_image,
            color=&#34;black&#34;,
        )
        plt.xlabel(&#34;images&#34;)
        plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
        plt.ylim((0, 100))
        plt.axhline(
            y=np.mean(S_squre_for_each_image),
            linestyle=&#34;dashed&#34;,
            linewidth=1,
            color=&#34;black&#34;,
        )

    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.plot_tissue_ID_proportions_mxif"><code class="name flex">
<span>def <span class="ident">plot_tissue_ID_proportions_mxif</span></span>(<span>self, tID_labels=None, slide_labels=None, figsize=(5, 5), cmap='tab20', save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot proportion of each tissue ID within each slide</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tID_labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of labels corresponding to MILWRM tissue IDs for plotting legend</dd>
<dt><strong><code>slide_labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of labels for each slide batch for labeling x-axis</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(5,5))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional <code>(default =</code>"tab20"<code>)</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>gridspec.GridSpec</code> if <code>save_to</code> is <code>None</code>, else saves plot to file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_tissue_ID_proportions_mxif(
    self,
    tID_labels=None,
    slide_labels=None,
    figsize=(5, 5),
    cmap=&#34;tab20&#34;,
    save_to=None,
):
    &#34;&#34;&#34;
    Plot proportion of each tissue ID within each slide

    Parameters
    ----------
    tID_labels : list of str, optional (default=`None`)
        List of labels corresponding to MILWRM tissue IDs for plotting legend
    slide_labels : list of str, optional (default=`None`)
        List of labels for each slide batch for labeling x-axis
    figsize : tuple of float, optional (default=(5,5))
        Size of matplotlib figure
    cmap : str, optional (default = `&#34;tab20&#34;`)
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
    &#34;&#34;&#34;
    df_count = pd.DataFrame()
    for i in range(len(self.tissue_IDs)):
        unique, counts = np.unique(self.tissue_IDs[i], return_counts=True)
        dict_ = dict(zip(unique, counts))
        n_counts = []
        for k in range(self.k):
            if k not in dict_.keys():
                n_counts.append(0)
            else:
                n_counts.append(dict_[k])
        df = pd.DataFrame(n_counts, columns=[i])
        df_count = pd.concat([df_count, df], axis=1)
    df_count = df_count / df_count.sum()
    if tID_labels:
        assert (
            len(tID_labels) == df_count.shape[1]
        ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
        df_count.columns = tID_labels
    if slide_labels:
        assert (
            len(slide_labels) == df_count.shape[0]
        ), &#34;Length of given slide labels does not match number of slides!&#34;
        df_count.index = slide_labels
    self.tissue_ID_proportion = df_count
    ax = df_count.T.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
    ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
    ax.set_xlabel(&#34;images&#34;)
    ax.set_ylabel(&#34;tissue ID proportion&#34;)
    ax.set_ylim((0, 1))
    plt.tight_layout()
    if save_to is not None:
        ax.figure.savefig(save_to)
    else:
        return ax</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.prep_cluster_data"><code class="name flex">
<span>def <span class="ident">prep_cluster_data</span></span>(<span>self, features, filter_name='gaussian', sigma=2, fract=0.2, path_save=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare master array for tissue level clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>filter_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the filter to use - gaussian, median or bilateral</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code>, optional <code>(default=2)</code></dt>
<dd>Standard deviation of Gaussian kernel for blurring</dd>
<dt><strong><code>fract</code></strong> :&ensp;<code>float</code>, optional <code>(default=0.2)</code></dt>
<dd>Fraction of cluster data from each image to randomly select for model
building</dd>
<dt><strong><code>path_save</code></strong> :&ensp;<code>str (default = None)</code></dt>
<dd>Path to save final preprocessed files, if self.use_path is True
default path_save will raise Exception</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.images</code> are normalized, blurred and scaled
according to user parameters. <code>self.cluster_data</code> becomes master <code>np.array</code>
for cluster training. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_cluster_data(
    self, features, filter_name=&#34;gaussian&#34;, sigma=2, fract=0.2, path_save=None
):
    &#34;&#34;&#34;
    Prepare master array for tissue level clustering

    Parameters
    ----------
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    filter_name : str
        Name of the filter to use - gaussian, median or bilateral
    sigma : float, optional (default=2)
        Standard deviation of Gaussian kernel for blurring
    fract : float, optional (default=0.2)
        Fraction of cluster data from each image to randomly select for model
        building
    path_save : str (default = None)
        Path to save final preprocessed files, if self.use_path is True
        default path_save will raise Exception

    Returns
    -------
    Does not return anything. `self.images` are normalized, blurred and scaled
    according to user parameters. `self.cluster_data` becomes master `np.array`
    for cluster training. Parameters are also captured as attributes for posterity.

    &#34;&#34;&#34;
    if self.cluster_data is not None:
        print(&#34;WARNING: overwriting existing cluster data&#34;)
        self.cluster_data = None
    # save the hyperparams as object attributes
    self.model_features = features
    use_path = self.use_paths
    # calculate the batch wise means
    mean_for_each_batch = {}
    for batch in self.image_df[&#34;batch_names&#34;].unique():
        list_mean_estimators = list(
            self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;mean estimators&#34;]
        )
        mean_estimator_batch = sum(map(np.array, list_mean_estimators))
        pixels = sum(self.image_df[self.image_df[&#34;batch_names&#34;] == batch][&#34;pixels&#34;])
        mean_for_each_batch[batch] = mean_estimator_batch / pixels
    # log_normalize, apply blurring filter, minmax scale each channel and subsample
    subsampled_data = []
    path_to_blurred_npz = []
    for image, batch in zip(self.image_df[&#34;Img&#34;], self.image_df[&#34;batch_names&#34;]):
        tmp = prep_data_single_sample_mxif(
            image,
            use_path=use_path,
            mean=mean_for_each_batch[batch],
            filter_name=filter_name,
            sigma=sigma,
            features=self.model_features,
            fract=fract,
            path_save=path_save,
        )
        if self.use_paths == True:
            subsampled_data.append(tmp[0])
            path_to_blurred_npz.append(tmp[1])
        else:
            subsampled_data.append(tmp)
    batch_labels = [
        [x] * len(subsampled_data[x]) for x in range(len(subsampled_data))
    ]  # batch labels for umap
    self.merged_batch_labels = list(itertools.chain(*batch_labels))
    if self.use_paths == True:
        self.image_df[&#34;Img&#34;] = path_to_blurred_npz
    cluster_data = np.row_stack(subsampled_data)
    # perform z-score normalization on cluster_Data
    scaler = StandardScaler()
    self.scaler = scaler.fit(cluster_data)
    scaled_data = scaler.transform(cluster_data)
    self.cluster_data = scaled_data</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.mxif_labeler.show_marker_overlay"><code class="name flex">
<span>def <span class="ident">show_marker_overlay</span></span>(<span>self, image_index, channels=None, cmap='Set1', mask_out=True, ncols=4, save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot tissue_ID with individual markers as alpha values to distinguish
expression in identified tissue domains</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image_index</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of image from <code>self.images</code> to plot overlays for (e.g. 0 for first
image)</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channels by index or name to show</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional <code>(default="plasma")</code></dt>
<dd>Matplotlib colormap to use for plotting tissue IDs</dd>
<dt><strong><code>mask_out</code></strong> :&ensp;<code>bool</code>, optional <code>(default=</code>True<code>)</code></dt>
<dd>Mask out non-tissue pixels prior to showing</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of columns for gridspec if plotting individual channels.</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object (if plotting one feature</code> or <code>RGB)</code> or <code>gridspec object (for</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>multiple features). Saves plot to file if <code>save_to</code> is not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_marker_overlay(
    self,
    image_index,
    channels=None,
    cmap=&#34;Set1&#34;,
    mask_out=True,
    ncols=4,
    save_to=None,
    **kwargs,
):
    &#34;&#34;&#34;
    Plot tissue_ID with individual markers as alpha values to distinguish
    expression in identified tissue domains

    Parameters
    ----------
    image_index : int
        Index of image from `self.images` to plot overlays for (e.g. 0 for first
        image)
    channels : tuple of int or None, optional (default=`None`)
        List of channels by index or name to show
    cmap : str, optional (default=&#34;plasma&#34;)
        Matplotlib colormap to use for plotting tissue IDs
    mask_out : bool, optional (default=`True`)
        Mask out non-tissue pixels prior to showing
    ncols : int
        Number of columns for gridspec if plotting individual channels.
    save_to : str or None
        Path to image file to save results. If `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function.

    Returns
    -------
    Matplotlib object (if plotting one feature or RGB) or gridspec object (for
    multiple features). Saves plot to file if `save_to` is not `None`.
    &#34;&#34;&#34;
    # if image has multiple channels, plot them in gridspec
    if isinstance(channels, int):  # force channels into list if single integer
        channels = [channels]
    if isinstance(channels, str):  # force channels into int if single string
        channels = [self[image_index].ch.index(channels)]
    if checktype(channels):  # force channels into list of int if list of strings
        channels = [self[image_index].ch.index(x) for x in channels]
    if channels is None:  # if no channels are given, use all of them
        channels = [x for x in range(self[image_index].n_ch)]
    assert (
        len(channels) &lt;= self[image_index].n_ch
    ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
        self[image_index].n_ch, len(channels)
    )
    # creating a copy of the image
    image_cp = self[image_index].copy()
    # re-scaling to set pixel value range between 0 to 1
    image_cp.scale()
    # defining cmap for discrete color bar
    cmap = plt.cm.get_cmap(cmap, self.k)
    # calculate gridspec dimensions
    if len(channels) + 1 &lt;= ncols:
        n_rows, n_cols = 1, len(channels) + 1
    else:
        n_rows, n_cols = ceil(len(channels) + 1 / ncols), ncols
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # plot tissue_ID first with colorbar
    ax = plt.subplot(gs[0])
    im = ax.imshow(self.tissue_IDs[image_index], cmap=cmap, **kwargs)
    ax.set_title(
        label=&#34;tissue_ID&#34;,
        loc=&#34;left&#34;,
        fontweight=&#34;bold&#34;,
        fontsize=16,
    )
    ax.tick_params(labelbottom=False, labelleft=False)
    sns.despine(bottom=True, left=True)
    # colorbar scale for tissue_IDs
    _ = plt.colorbar(im, ticks=range(self.k), shrink=0.7)
    # add plots to axes
    i = 1
    for channel in channels:
        ax = plt.subplot(gs[i])
        # make copy for alpha
        im_tmp = image_cp.img[:, :, channel].copy()
        if self[image_index].mask is not None and mask_out:
            # area outside mask NaN
            self.tissue_IDs[image_index][self[image_index].mask == 0] = np.nan
            im = ax.imshow(
                self.tissue_IDs[image_index], cmap=cmap, alpha=im_tmp, **kwargs
            )
        else:
            ax.imshow(self.tissue_IDs[image_index], alpha=im_tmp, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=self[image_index].ch[channel],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        i = i + 1
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="MILWRM.MILWRM.tissue_labeler" href="#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></b></code>:
<ul class="hlist">
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_optimal_k" href="#MILWRM.MILWRM.tissue_labeler.find_optimal_k">find_optimal_k</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_tissue_regions" href="#MILWRM.MILWRM.tissue_labeler.find_tissue_regions">find_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_loadings">plot_feature_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_proportions">plot_feature_proportions</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="MILWRM.MILWRM.st_labeler"><code class="flex name class">
<span>class <span class="ident">st_labeler</span></span>
<span>(</span><span>adatas)</span>
</code></dt>
<dd>
<div class="desc"><p>Tissue domain labeling class for spatial transcriptomics (ST) data</p>
<p>Initialize ST tissue labeler class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adatas</code></strong> :&ensp;<code>list</code> of <code>anndata.AnnData</code></dt>
<dd>Single anndata object or list of objects to label consensus tissue domains</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> attribute is updated,
<code>self.cluster_data</code> attribute is initiated as <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class st_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue domain labeling class for spatial transcriptomics (ST) data
    &#34;&#34;&#34;

    def __init__(self, adatas):
        &#34;&#34;&#34;
        Initialize ST tissue labeler class

        Parameters
        ----------
        adatas : list of anndata.AnnData
            Single anndata object or list of objects to label consensus tissue domains

        Returns
        -------
        Does not return anything. `self.adatas` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        if not isinstance(adatas, list):  # force single anndata object to list
            adatas = [adatas]
        print(&#34;Initiating ST labeler with {} anndata objects&#34;.format(len(adatas)))
        self.adatas = adatas
        self.raw = adatas.copy()

    def prep_cluster_data(
        self,
        use_rep,
        features=None,
        n_rings=1,
        histo=False,
        fluor_channels=None,
        spatial_graph_key=None,
        n_jobs=-1,
    ):
        &#34;&#34;&#34;
        Prepare master dataframe for tissue-level clustering

        Parameters
        ----------
        use_rep : str
            Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
        features : list of int or None, optional (default=`None`)
            List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
            use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
            all features from `adata.obsm[use_rep]`
        n_rings : int, optional (default=1)
            Number of hexagonal rings around each spatial transcriptomics spot to blur
            features by for capturing regional information. Assumes 10X Genomics Visium
            platform.
        histo : bool, optional (default `False`)
            Use histology data from Visium anndata object (R,G,B brightfield features)
            in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
            than brightfield, use `fluor_channels` argument instead.
        fluor_channels : list of int or None, optional (default `None`)
            Channels from fluorescent image to use for model training (e.g. [1,3] for
            channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
            use imaging data for training.
        spatial_graph_key : str, optional (default=`None`)
            Key in `adata.obsp` containing spatial graph connectivities (i.e.
            `&#34;spatial_connectivities&#34;`). If `None`, compute new spatial graph using
            `n_rings` in `squidpy`.
        n_jobs : int, optional (default=-1)
            Number of cores to parallelize over. Default all available cores.

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;blur_*&#34; features
        to `.obs` if `n_rings &gt; 0`.
        `self.cluster_data` becomes master `np.array` for cluster training.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        if features is None:
            self.features = [x for x in range(self.adatas[0].obsm[use_rep].shape[1])]
        else:
            self.features = features
        # save the hyperparams as object attributes
        self.rep = use_rep
        self.histo = histo
        self.fluor_channels = fluor_channels
        self.n_rings = n_rings
        # collect clustering data from self.adatas in parallel
        print(
            &#34;Collecting and blurring {} features from .obsm[{}]...&#34;.format(
                len(self.features),
                use_rep,
            )
        )
        cluster_data = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(prep_data_single_sample_st)(
                adata,
                adata_i,
                use_rep,
                self.features,
                histo,
                fluor_channels,
                spatial_graph_key,
                n_rings,
            )
            for adata_i, adata in enumerate(self.adatas)
        )
        batch_labels = [
            [x] * len(cluster_data[x]) for x in range(len(cluster_data))
        ]  # batch labels for umap
        self.merged_batch_labels = list(itertools.chain(*batch_labels))
        # concatenate blurred features into cluster_data df for cluster training
        subsampled_data = pd.concat(cluster_data)
        # perform z-scaling on final cluster data
        scaler = StandardScaler()
        self.scaler = scaler.fit(subsampled_data)
        scaled_data = scaler.transform(subsampled_data)
        self.cluster_data = scaled_data
        print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        `anndata` objects.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if scaled inertia plot should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model.
        n_jobs : int
            Number of cores to parallelize k-choosing across

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;tissue_ID&#34; field
        to `.obs`. `self.kmeans` contains trained `sklearn` clustering model.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                plot_out=plot_out, alpha=alpha, random_state=random_state, n_jobs=n_jobs
            )
        # call k-means model from parent class
        self.find_tissue_regions(k=k, random_state=random_state)
        # loop through anndata object and add tissue labels to adata.obs dataframe
        start = 0
        print(&#34;Adding tissue_ID label to anndata objects&#34;)
        for i in range(len(self.adatas)):
            IDs = self.kmeans.labels_
            self.adatas[i].obs[&#34;tissue_ID&#34;] = IDs[start : start + self.adatas[i].n_obs]
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].astype(&#34;category&#34;)
            )
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].cat.set_categories(np.unique(IDs))
            )
            start += self.adatas[i].n_obs

    def confidence_score(self):
        &#34;&#34;&#34;
        estimate confidence score for each visium slide

        Parameters
        ----------

        Returns
        -------
        self.adatas[i].obs.confidence_IDs and self.confidence_score_df are added
        containing confidence score for each tissue ID assignment and mean confidence
        score for each tissue ID within each visium slide
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        i_slice = 0
        j_slice = 0
        confidence_score_df = pd.DataFrame()
        adatas = self.adatas
        cluster_data = self.cluster_data
        centroids = self.kmeans.cluster_centers_
        for i, adata in enumerate(adatas):
            j_slice = j_slice + adata.n_obs
            data = cluster_data[i_slice:j_slice]
            scores_dict = estimate_confidence_score_st(data, adata, centroids)
            df = pd.DataFrame(scores_dict.values(), columns=[i])
            confidence_score_df = pd.concat([confidence_score_df, df], axis=1)
            i_slice = i_slice + adata.n_obs
        self.confidence_score_df = confidence_score_df

    def plot_gene_loadings(
        self,
        PC_loadings,
        n_genes=10,
        ncols=None,
        titles=None,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot MILWRM loadings in gene space specifically for MILWRM done with PCs

        Parameters
        ----------
        PC_loadings : numpy.ndarray
            numpy.ndarray containing PC loadings shape format (genes, components)
        n_genes : int, optional (default=10)
            number of genes to plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object and PC loadings in gene space set as self.gene_loadings_df
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        assert (
            PC_loadings.shape[0] == self.adatas[0].n_vars
        ), f&#34;loadings matrix does not, \
        contain enough genes, there should be {self.adatas[0].n_vars} genes&#34;
        assert (
            PC_loadings.shape[1] &gt;= self.kmeans.cluster_centers_.shape[1]
        ), f&#34;loadings matrix \
        does not contain enough components, there should be atleast {self.adatas[0].n_vars} components&#34;
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        centroids = self.kmeans.cluster_centers_
        temp = PC_loadings.T
        loadings = temp[range(self.kmeans.cluster_centers_.shape[1])]
        gene_loadings = np.matmul(centroids, loadings)
        gene_loadings_df = pd.DataFrame(gene_loadings)
        gene_loadings_df = gene_loadings_df.T
        gene_loadings_df[&#34;genes&#34;] = self.adatas[0].var_names
        self.gene_loadings_df = gene_loadings_df
        n_panels = self.k
        if ncols is None:
            ncols = self.k
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=((ncols * n_cols, ncols * n_rows)))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in range(self.k):
            df = (
                gene_loadings_df[[i, &#34;genes&#34;]]
                .sort_values(i, axis=0, ascending=False)[:n_genes]
                .reset_index(drop=True)
            )
            plt.subplot(gs[i])
            df_rev = df.sort_values(i).reset_index(drop=True)
            for j, score in enumerate((df_rev[i])):
                plt.text(
                    x=score,
                    y=j + 0.1,
                    s=df_rev.loc[j, &#34;genes&#34;],
                    color=&#34;black&#34;,
                    verticalalignment=&#34;center&#34;,
                    horizontalalignment=&#34;right&#34;,
                    fontsize=&#34;medium&#34;,
                    fontstyle=&#34;italic&#34;,
                )
                plt.ylim([0, j + 1])
                plt.xlim([0, df.max().values[0] + 0.1])
                plt.tick_params(
                    axis=&#34;y&#34;,  # changes apply to the y-axis
                    which=&#34;both&#34;,  # both major and minor ticks are affected
                    left=False,
                    right=False,
                    labelleft=False,
                )
                plt.title(titles[i])
        gs.tight_layout(fig)
        if save_to is not None:
            print(&#34;Saving feature loadings to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return gs

    def plot_percentage_variance_explained(
        self, fig_size=(5, 5), R_square=False, save_to=None
    ):
        &#34;&#34;&#34;
        plot percentage variance_explained or not explained by clustering

        Parameters
        ----------
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        R_square : Boolean
            Decides if R_square is plotted or S_square
        save_to : str or None
            Path to image file to save results. If `None`, show figure.

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        centroids = self.kmeans.cluster_centers_
        adatas = self.adatas
        cluster_data = self.cluster_data
        S_squre_for_each_st = []
        R_squre_for_each_st = []
        i_slice = 0
        j_slice = 0
        for adata in adatas:
            j_slice = j_slice + adata.n_obs
            sub_cluster_data = cluster_data[i_slice:j_slice]
            S_square = estimate_percentage_variance_st(
                sub_cluster_data, adata, centroids
            )
            S_squre_for_each_st.append(S_square)
            R_squre_for_each_st.append(100 - S_square)
            i_slice = i_slice + adata.n_obs

        if R_square:
            fig = plt.figure(figsize=fig_size)
            plt.scatter(
                range(len(R_squre_for_each_st)), R_squre_for_each_st, color=&#34;black&#34;
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(R_squre_for_each_st),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        else:
            fig = plt.figure(figsize=fig_size)
            fig = plt.figure(figsize=(5, 5))
            plt.scatter(
                range(len(S_squre_for_each_st)), S_squre_for_each_st, color=&#34;black&#34;
            )
            plt.xlabel(&#34;images&#34;)
            plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
            plt.ylim((0, 100))
            plt.axhline(
                y=np.mean(S_squre_for_each_st),
                linestyle=&#34;dashed&#34;,
                linewidth=1,
                color=&#34;black&#34;,
            )

        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig

    def plot_mse_st(
        self,
        figsize=(5, 5),
        ncols=None,
        labels=None,
        titles=None,
        loc=&#34;lower right&#34;,
        bbox_coordinates=(0, 0, 1.5, 1.5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        estimate mean square error within each tissue ID

        Parameters
        ----------
        fig_size : Tuple
            size for the bar plot
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        labels : list of str, optional (default=`None`)
            Labels corresponding to each image in legend. If `None`, numeric index is
            used for each imaage
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        loc : str, optional (default = &#39;lower right&#39;)
            str for legend position
        bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
            coordinates for the legend box
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        Matplotlib object
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        cluster_data = self.cluster_data
        adatas = self.adatas
        k = self.k
        features = self.features
        centroids = self.kmeans.cluster_centers_
        mse_id = estimate_mse_st(cluster_data, adatas, centroids, k)
        colors = plt.cm.tab20(np.linspace(0, 1, len(adatas)))
        if titles is None:
            titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
        if labels is None:
            labels = range(len(adatas))
        n_panels = len(mse_id.keys())
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for i in mse_id.keys():
            plt.subplot(gs[i])
            df = pd.DataFrame.from_dict(mse_id[i])
            plt.boxplot(df, positions=features, showfliers=False)
            for col in df:
                for k in range(len(df[col])):
                    dots = plt.scatter(
                        col,
                        df[col][k],
                        s=k + 1,
                        color=colors[k],
                        label=labels[k] if col == 0 else &#34;&#34;,
                    )
                    offsets = dots.get_offsets()
                    jittered_offsets = offsets
                    # only jitter in the x-direction
                    jittered_offsets[:, 0] += np.random.uniform(
                        -0.3, 0.3, offsets.shape[0]
                    )
                    dots.set_offsets(jittered_offsets)
            plt.xlabel(&#34;slides&#34;)
            plt.ylabel(&#34;mean square error&#34;)
            plt.title(titles[i])
        plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates)
        gs.tight_layout(fig)
        if save_to:
            plt.savefig(fname=save_to, transparent=True, dpi=300)
        return fig

    def plot_tissue_ID_proportions_st(
        self,
        tID_labels=None,
        slide_labels=None,
        figsize=(5, 5),
        cmap=&#34;tab20&#34;,
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plot proportion of each tissue ID within each slide

        Parameters
        ----------
        tID_labels : list of str, optional (default=`None`)
            List of labels corresponding to MILWRM tissue IDs for plotting legend
        slide_labels : list of str, optional (default=`None`)
            List of labels for each slide batch for labeling x-axis
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        cmap : str, optional (default = `&#34;tab20&#34;`)
            Colormap from matplotlib
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        df_count = pd.DataFrame()
        for adata in self.adatas:
            df = adata.obs[&#34;tissue_ID&#34;].value_counts(normalize=True, sort=False)
            df_count = pd.concat([df_count, df], axis=1)
        df_count = df_count.T.reset_index(drop=True)
        if tID_labels:
            assert (
                len(tID_labels) == df_count.shape[1]
            ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
            df_count.columns = tID_labels
        if slide_labels:
            assert (
                len(slide_labels) == df_count.shape[0]
            ), &#34;Length of given slide labels does not match number of slides!&#34;
            df_count.index = slide_labels
        ax = df_count.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
        ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
        ax.set_xlabel(&#34;slides&#34;)
        ax.set_ylabel(&#34;tissue ID proportion&#34;)
        ax.set_ylim((0, 1))
        plt.tight_layout()
        if save_to is not None:
            ax.figure.savefig(save_to)
        else:
            return ax

    def show_feature_overlay(
        self,
        adata_index,
        pita,
        features=None,
        histo=None,
        cmap=&#34;tab20&#34;,
        label=&#34;feature&#34;,
        ncols=4,
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot tissue_ID with individual pita features as alpha values to distinguish
        expression in identified tissue domains

        Parameters
        ----------
        adata_index : int
            Index of adata from `self.adatas` to plot overlays for (e.g. 0 for first
            adata object)
        pita : np.array
            Image of desired expression in pixel space from `.assemble_pita()`
        features : list of int, optional (default=`None`)
            List of features by index to show in plot. If `None`, use all features.
        histo : np.array or `None`, optional (default=`None`)
            Histology image to show along with pita in gridspec. If `None`, ignore.
        cmap : str, optional (default=&#34;tab20&#34;)
            Matplotlib colormap to use for plotting tissue IDs
        label : str
            What to title each panel of the gridspec (i.e. &#34;PC&#34; or &#34;usage&#34;) or each
            channel in RGB image. Can also pass list of names e.g. [&#34;NeuN&#34;,&#34;GFAP&#34;,
            &#34;DAPI&#34;] corresponding to channels.
        ncols : int
            Number of columns for gridspec
        save_to : str or None
            Path to image file to save results. if `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        assert pita.ndim &gt; 1, &#34;Pita does not have enough dimensions: {} given&#34;.format(
            pita.ndim
        )
        assert pita.ndim &lt; 4, &#34;Pita has too many dimensions: {} given&#34;.format(pita.ndim)
        # create tissue_ID pita for plotting
        tIDs = assemble_pita(
            self.adatas[adata_index],
            features=&#34;tissue_ID&#34;,
            use_rep=&#34;obs&#34;,
            plot_out=False,
            verbose=False,
        )
        # if pita has multiple features, plot them in gridspec
        if isinstance(features, int):  # force features into list if single integer
            features = [features]
        # if no features are given, use all of them
        elif features is None:
            features = [x + 1 for x in range(pita.shape[2])]
        else:
            assert (
                pita.ndim &gt; 2
            ), &#34;Not enough features in pita: shape {}, expecting 3rd dim with length {}&#34;.format(
                pita.shape, len(features)
            )
            assert (
                len(features) &lt;= pita.shape[2]
            ), &#34;Too many features given: pita has {}, expected {}&#34;.format(
                pita.shape[2], len(features)
            )
        # min-max scale each feature in pita to convert to interpretable alpha values
        mms = MinMaxScaler()
        if pita.ndim == 3:
            pita_tmp = mms.fit_transform(
                pita.reshape((pita.shape[0] * pita.shape[1], pita.shape[2]))
            )
        elif pita.ndim == 2:
            pita_tmp = mms.fit_transform(
                pita.reshape((pita.shape[0] * pita.shape[1], 1))
            )
        # reshape back to original
        pita = pita_tmp.reshape(pita.shape)
        # figure out labels for gridspec plots
        if isinstance(label, str):
            # if label is single string, name channels numerically
            labels = [&#34;{}_{}&#34;.format(label, x) for x in features]
        else:
            assert len(label) == len(
                features
            ), &#34;Please provide the same number of labels as features; {} labels given, {} features given.&#34;.format(
                len(label), len(features)
            )
            labels = label
        # calculate gridspec dimensions
        if histo is not None:
            # determine where the histo image is in anndata
            assert (
                histo
                in self.adatas[adata_index]
                .uns[&#34;spatial&#34;][
                    list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
                ][&#34;images&#34;]
                .keys()
            ), &#34;Must provide one of {} for histo&#34;.format(
                self.adatas[adata_index]
                .uns[&#34;spatial&#34;][
                    list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
                ][&#34;images&#34;]
                .keys()
            )
            histo = self.adatas[adata_index].uns[&#34;spatial&#34;][
                list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
            ][&#34;images&#34;][histo]
            if len(features) + 2 &lt;= ncols:
                n_rows, n_cols = 1, len(features) + 2
            else:
                n_rows, n_cols = ceil((len(features) + 2) / ncols), ncols
            labels = [&#34;Histology&#34;, &#34;tissue_ID&#34;] + labels  # append to front of labels
        else:
            if len(features) + 1 &lt;= ncols:
                n_rows, n_cols = 1, len(features) + 1
            else:
                n_rows, n_cols = ceil(len(features) + 1 / ncols), ncols
            labels = [&#34;tissue_ID&#34;] + labels  # append to front of labels
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        if histo is not None:
            # add histology plot to first axes
            ax = plt.subplot(gs[i])
            im = ax.imshow(histo, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=labels[i],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        # plot tissue_ID first with colorbar
        ax = plt.subplot(gs[i])
        im = ax.imshow(tIDs, cmap=cmap, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        # colorbar scale for tissue_IDs
        _ = plt.colorbar(im, shrink=0.7)
        i = i + 1
        for feature in features:
            ax = plt.subplot(gs[i])
            im = ax.imshow(tIDs, alpha=pita[:, :, feature - 1], cmap=cmap, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=labels[i],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
        return fig</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="MILWRM.MILWRM.tissue_labeler" href="#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.MILWRM.st_labeler.confidence_score"><code class="name flex">
<span>def <span class="ident">confidence_score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>estimate confidence score for each visium slide</p>
<h2 id="parameters">Parameters</h2>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self.adatas[i].obs.confidence_IDs and self.confidence_score_df are added</code></dt>
<dd>&nbsp;</dd>
<dt><code>containing confidence score for each tissue ID assignment and mean confidence</code></dt>
<dd>&nbsp;</dd>
<dt><code>score for each tissue ID within each visium slide</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confidence_score(self):
    &#34;&#34;&#34;
    estimate confidence score for each visium slide

    Parameters
    ----------

    Returns
    -------
    self.adatas[i].obs.confidence_IDs and self.confidence_score_df are added
    containing confidence score for each tissue ID assignment and mean confidence
    score for each tissue ID within each visium slide
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    i_slice = 0
    j_slice = 0
    confidence_score_df = pd.DataFrame()
    adatas = self.adatas
    cluster_data = self.cluster_data
    centroids = self.kmeans.cluster_centers_
    for i, adata in enumerate(adatas):
        j_slice = j_slice + adata.n_obs
        data = cluster_data[i_slice:j_slice]
        scores_dict = estimate_confidence_score_st(data, adata, centroids)
        df = pd.DataFrame(scores_dict.values(), columns=[i])
        confidence_score_df = pd.concat([confidence_score_df, df], axis=1)
        i_slice = i_slice + adata.n_obs
    self.confidence_score_df = confidence_score_df</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.label_tissue_regions"><code class="name flex">
<span>def <span class="ident">label_tissue_regions</span></span>(<span>self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform tissue-level clustering and label pixels in the corresponding
<code>anndata</code> objects.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Number of tissue regions to define</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>boolean</code>, optional <code>(default=True)</code></dt>
<dd>Determines if scaled inertia plot should be output</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering model.</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing across</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> are updated, adding "tissue_ID" field
to <code>.obs</code>. <code>self.kmeans</code> contains trained <code>sklearn</code> clustering model.
Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_tissue_regions(
    self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
):
    &#34;&#34;&#34;
    Perform tissue-level clustering and label pixels in the corresponding
    `anndata` objects.

    Parameters
    ----------
    k : int, optional (default=None)
        Number of tissue regions to define
    alpha: float
        Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
    plot_out : boolean, optional (default=True)
        Determines if scaled inertia plot should be output
    random_state : int, optional (default=18)
        Seed for k-means clustering model.
    n_jobs : int
        Number of cores to parallelize k-choosing across

    Returns
    -------
    Does not return anything. `self.adatas` are updated, adding &#34;tissue_ID&#34; field
    to `.obs`. `self.kmeans` contains trained `sklearn` clustering model.
    Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    # find optimal k with parent class
    if k is None:
        print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
        self.find_optimal_k(
            plot_out=plot_out, alpha=alpha, random_state=random_state, n_jobs=n_jobs
        )
    # call k-means model from parent class
    self.find_tissue_regions(k=k, random_state=random_state)
    # loop through anndata object and add tissue labels to adata.obs dataframe
    start = 0
    print(&#34;Adding tissue_ID label to anndata objects&#34;)
    for i in range(len(self.adatas)):
        IDs = self.kmeans.labels_
        self.adatas[i].obs[&#34;tissue_ID&#34;] = IDs[start : start + self.adatas[i].n_obs]
        self.adatas[i].obs[&#34;tissue_ID&#34;] = (
            self.adatas[i].obs[&#34;tissue_ID&#34;].astype(&#34;category&#34;)
        )
        self.adatas[i].obs[&#34;tissue_ID&#34;] = (
            self.adatas[i].obs[&#34;tissue_ID&#34;].cat.set_categories(np.unique(IDs))
        )
        start += self.adatas[i].n_obs</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.plot_gene_loadings"><code class="name flex">
<span>def <span class="ident">plot_gene_loadings</span></span>(<span>self, PC_loadings, n_genes=10, ncols=None, titles=None, save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot MILWRM loadings in gene space specifically for MILWRM done with PCs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>PC_loadings</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>numpy.ndarray containing PC loadings shape format (genes, components)</dd>
<dt><strong><code>n_genes</code></strong> :&ensp;<code>int</code>, optional <code>(default=10)</code></dt>
<dd>number of genes to plot</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Number of columns for gridspec. If <code>None</code>, uses number of tissue domains k.</dd>
<dt><strong><code>titles</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Titles of plots corresponding to each MILWRM domain. If <code>None</code>, titles
will be numbers 0 through k.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(5,5))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object and PC loadings in gene space set as self.gene_loadings_df</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_gene_loadings(
    self,
    PC_loadings,
    n_genes=10,
    ncols=None,
    titles=None,
    save_to=None,
):
    &#34;&#34;&#34;
    Plot MILWRM loadings in gene space specifically for MILWRM done with PCs

    Parameters
    ----------
    PC_loadings : numpy.ndarray
        numpy.ndarray containing PC loadings shape format (genes, components)
    n_genes : int, optional (default=10)
        number of genes to plot
    ncols : int, optional (default=`None`)
        Number of columns for gridspec. If `None`, uses number of tissue domains k.
    titles : list of str, optional (default=`None`)
        Titles of plots corresponding to each MILWRM domain. If `None`, titles
        will be numbers 0 through k.
    figsize : tuple of float, optional (default=(5,5))
        Size of matplotlib figure
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    Matplotlib object and PC loadings in gene space set as self.gene_loadings_df
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    assert (
        PC_loadings.shape[0] == self.adatas[0].n_vars
    ), f&#34;loadings matrix does not, \
    contain enough genes, there should be {self.adatas[0].n_vars} genes&#34;
    assert (
        PC_loadings.shape[1] &gt;= self.kmeans.cluster_centers_.shape[1]
    ), f&#34;loadings matrix \
    does not contain enough components, there should be atleast {self.adatas[0].n_vars} components&#34;
    if titles is None:
        titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
    centroids = self.kmeans.cluster_centers_
    temp = PC_loadings.T
    loadings = temp[range(self.kmeans.cluster_centers_.shape[1])]
    gene_loadings = np.matmul(centroids, loadings)
    gene_loadings_df = pd.DataFrame(gene_loadings)
    gene_loadings_df = gene_loadings_df.T
    gene_loadings_df[&#34;genes&#34;] = self.adatas[0].var_names
    self.gene_loadings_df = gene_loadings_df
    n_panels = self.k
    if ncols is None:
        ncols = self.k
    if n_panels &lt;= ncols:
        n_rows, n_cols = 1, n_panels
    else:
        n_rows, n_cols = ceil(n_panels / ncols), ncols
    fig = plt.figure(figsize=((ncols * n_cols, ncols * n_rows)))
    left, bottom = 0.1 / n_cols, 0.1 / n_rows
    gs = gridspec.GridSpec(
        nrows=n_rows,
        ncols=n_cols,
        left=left,
        bottom=bottom,
        right=1 - (n_cols - 1) * left - 0.01 / n_cols,
        top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
    )
    for i in range(self.k):
        df = (
            gene_loadings_df[[i, &#34;genes&#34;]]
            .sort_values(i, axis=0, ascending=False)[:n_genes]
            .reset_index(drop=True)
        )
        plt.subplot(gs[i])
        df_rev = df.sort_values(i).reset_index(drop=True)
        for j, score in enumerate((df_rev[i])):
            plt.text(
                x=score,
                y=j + 0.1,
                s=df_rev.loc[j, &#34;genes&#34;],
                color=&#34;black&#34;,
                verticalalignment=&#34;center&#34;,
                horizontalalignment=&#34;right&#34;,
                fontsize=&#34;medium&#34;,
                fontstyle=&#34;italic&#34;,
            )
            plt.ylim([0, j + 1])
            plt.xlim([0, df.max().values[0] + 0.1])
            plt.tick_params(
                axis=&#34;y&#34;,  # changes apply to the y-axis
                which=&#34;both&#34;,  # both major and minor ticks are affected
                left=False,
                right=False,
                labelleft=False,
            )
            plt.title(titles[i])
    gs.tight_layout(fig)
    if save_to is not None:
        print(&#34;Saving feature loadings to {}&#34;.format(save_to))
        plt.savefig(save_to)
    else:
        return gs</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.plot_mse_st"><code class="name flex">
<span>def <span class="ident">plot_mse_st</span></span>(<span>self, figsize=(5, 5), ncols=None, labels=None, titles=None, loc='lower right', bbox_coordinates=(0, 0, 1.5, 1.5), save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>estimate mean square error within each tissue ID</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fig_size</code></strong> :&ensp;<code>Tuple</code></dt>
<dd>size for the bar plot</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Number of columns for gridspec. If <code>None</code>, uses number of tissue domains k.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Labels corresponding to each image in legend. If <code>None</code>, numeric index is
used for each imaage</dd>
<dt><strong><code>titles</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Titles of plots corresponding to each MILWRM domain. If <code>None</code>, titles
will be numbers 0 through k.</dd>
<dt><strong><code>loc</code></strong> :&ensp;<code>str</code>, optional <code>(default = 'lower right')</code></dt>
<dd>str for legend position</dd>
<dt><strong><code>bbox_coordinates</code></strong> :&ensp;<code>Tuple</code>, optional <code>(default = (0,0,1.5,1.5))</code></dt>
<dd>coordinates for the legend box</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_mse_st(
    self,
    figsize=(5, 5),
    ncols=None,
    labels=None,
    titles=None,
    loc=&#34;lower right&#34;,
    bbox_coordinates=(0, 0, 1.5, 1.5),
    save_to=None,
):
    &#34;&#34;&#34;
    estimate mean square error within each tissue ID

    Parameters
    ----------
    fig_size : Tuple
        size for the bar plot
    ncols : int, optional (default=`None`)
        Number of columns for gridspec. If `None`, uses number of tissue domains k.
    labels : list of str, optional (default=`None`)
        Labels corresponding to each image in legend. If `None`, numeric index is
        used for each imaage
    titles : list of str, optional (default=`None`)
        Titles of plots corresponding to each MILWRM domain. If `None`, titles
        will be numbers 0 through k.
    loc : str, optional (default = &#39;lower right&#39;)
        str for legend position
    bbox_coordinates : Tuple, optional (default = (0,0,1.5,1.5))
        coordinates for the legend box
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    Matplotlib object
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    cluster_data = self.cluster_data
    adatas = self.adatas
    k = self.k
    features = self.features
    centroids = self.kmeans.cluster_centers_
    mse_id = estimate_mse_st(cluster_data, adatas, centroids, k)
    colors = plt.cm.tab20(np.linspace(0, 1, len(adatas)))
    if titles is None:
        titles = [&#34;tissue_ID &#34; + str(x) for x in range(self.k)]
    if labels is None:
        labels = range(len(adatas))
    n_panels = len(mse_id.keys())
    if ncols is None:
        ncols = len(titles)
    if n_panels &lt;= ncols:
        n_rows, n_cols = 1, n_panels
    else:
        n_rows, n_cols = ceil(n_panels / ncols), ncols
    fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
    left, bottom = 0.1 / n_cols, 0.1 / n_rows
    gs = gridspec.GridSpec(
        nrows=n_rows,
        ncols=n_cols,
        left=left,
        bottom=bottom,
        right=1 - (n_cols - 1) * left - 0.01 / n_cols,
        top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
    )
    for i in mse_id.keys():
        plt.subplot(gs[i])
        df = pd.DataFrame.from_dict(mse_id[i])
        plt.boxplot(df, positions=features, showfliers=False)
        for col in df:
            for k in range(len(df[col])):
                dots = plt.scatter(
                    col,
                    df[col][k],
                    s=k + 1,
                    color=colors[k],
                    label=labels[k] if col == 0 else &#34;&#34;,
                )
                offsets = dots.get_offsets()
                jittered_offsets = offsets
                # only jitter in the x-direction
                jittered_offsets[:, 0] += np.random.uniform(
                    -0.3, 0.3, offsets.shape[0]
                )
                dots.set_offsets(jittered_offsets)
        plt.xlabel(&#34;slides&#34;)
        plt.ylabel(&#34;mean square error&#34;)
        plt.title(titles[i])
    plt.legend(loc=loc, bbox_to_anchor=bbox_coordinates)
    gs.tight_layout(fig)
    if save_to:
        plt.savefig(fname=save_to, transparent=True, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.plot_percentage_variance_explained"><code class="name flex">
<span>def <span class="ident">plot_percentage_variance_explained</span></span>(<span>self, fig_size=(5, 5), R_square=False, save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>plot percentage variance_explained or not explained by clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(5,5))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>R_square</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>Decides if R_square is plotted or S_square</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_percentage_variance_explained(
    self, fig_size=(5, 5), R_square=False, save_to=None
):
    &#34;&#34;&#34;
    plot percentage variance_explained or not explained by clustering

    Parameters
    ----------
    figsize : tuple of float, optional (default=(5,5))
        Size of matplotlib figure
    R_square : Boolean
        Decides if R_square is plotted or S_square
    save_to : str or None
        Path to image file to save results. If `None`, show figure.

    Returns
    -------
    Matplotlib object
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    centroids = self.kmeans.cluster_centers_
    adatas = self.adatas
    cluster_data = self.cluster_data
    S_squre_for_each_st = []
    R_squre_for_each_st = []
    i_slice = 0
    j_slice = 0
    for adata in adatas:
        j_slice = j_slice + adata.n_obs
        sub_cluster_data = cluster_data[i_slice:j_slice]
        S_square = estimate_percentage_variance_st(
            sub_cluster_data, adata, centroids
        )
        S_squre_for_each_st.append(S_square)
        R_squre_for_each_st.append(100 - S_square)
        i_slice = i_slice + adata.n_obs

    if R_square:
        fig = plt.figure(figsize=fig_size)
        plt.scatter(
            range(len(R_squre_for_each_st)), R_squre_for_each_st, color=&#34;black&#34;
        )
        plt.xlabel(&#34;images&#34;)
        plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
        plt.ylim((0, 100))
        plt.axhline(
            y=np.mean(R_squre_for_each_st),
            linestyle=&#34;dashed&#34;,
            linewidth=1,
            color=&#34;black&#34;,
        )

    else:
        fig = plt.figure(figsize=fig_size)
        fig = plt.figure(figsize=(5, 5))
        plt.scatter(
            range(len(S_squre_for_each_st)), S_squre_for_each_st, color=&#34;black&#34;
        )
        plt.xlabel(&#34;images&#34;)
        plt.ylabel(&#34;percentage variance explained by Kmeans&#34;)
        plt.ylim((0, 100))
        plt.axhline(
            y=np.mean(S_squre_for_each_st),
            linestyle=&#34;dashed&#34;,
            linewidth=1,
            color=&#34;black&#34;,
        )

    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.plot_tissue_ID_proportions_st"><code class="name flex">
<span>def <span class="ident">plot_tissue_ID_proportions_st</span></span>(<span>self, tID_labels=None, slide_labels=None, figsize=(5, 5), cmap='tab20', save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot proportion of each tissue ID within each slide</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tID_labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of labels corresponding to MILWRM tissue IDs for plotting legend</dd>
<dt><strong><code>slide_labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of labels for each slide batch for labeling x-axis</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(5,5))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional <code>(default =</code>"tab20"<code>)</code></dt>
<dd>Colormap from matplotlib</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>gridspec.GridSpec</code> if <code>save_to</code> is <code>None</code>, else saves plot to file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_tissue_ID_proportions_st(
    self,
    tID_labels=None,
    slide_labels=None,
    figsize=(5, 5),
    cmap=&#34;tab20&#34;,
    save_to=None,
):
    &#34;&#34;&#34;
    Plot proportion of each tissue ID within each slide

    Parameters
    ----------
    tID_labels : list of str, optional (default=`None`)
        List of labels corresponding to MILWRM tissue IDs for plotting legend
    slide_labels : list of str, optional (default=`None`)
        List of labels for each slide batch for labeling x-axis
    figsize : tuple of float, optional (default=(5,5))
        Size of matplotlib figure
    cmap : str, optional (default = `&#34;tab20&#34;`)
        Colormap from matplotlib
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
    &#34;&#34;&#34;
    df_count = pd.DataFrame()
    for adata in self.adatas:
        df = adata.obs[&#34;tissue_ID&#34;].value_counts(normalize=True, sort=False)
        df_count = pd.concat([df_count, df], axis=1)
    df_count = df_count.T.reset_index(drop=True)
    if tID_labels:
        assert (
            len(tID_labels) == df_count.shape[1]
        ), &#34;Length of given tissue ID labels does not match number of tissue IDs!&#34;
        df_count.columns = tID_labels
    if slide_labels:
        assert (
            len(slide_labels) == df_count.shape[0]
        ), &#34;Length of given slide labels does not match number of slides!&#34;
        df_count.index = slide_labels
    ax = df_count.plot.bar(stacked=True, cmap=cmap, figsize=figsize)
    ax.legend(loc=&#34;best&#34;, bbox_to_anchor=(1, 1))
    ax.set_xlabel(&#34;slides&#34;)
    ax.set_ylabel(&#34;tissue ID proportion&#34;)
    ax.set_ylim((0, 1))
    plt.tight_layout()
    if save_to is not None:
        ax.figure.savefig(save_to)
    else:
        return ax</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.prep_cluster_data"><code class="name flex">
<span>def <span class="ident">prep_cluster_data</span></span>(<span>self, use_rep, features=None, n_rings=1, histo=False, fluor_channels=None, spatial_graph_key=None, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare master dataframe for tissue-level clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>use_rep</code></strong> :&ensp;<code>str</code></dt>
<dd>Representation from <code>adata.obsm</code> to use as clustering data (e.g. "X_pca")</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of features to use from <code>adata.obsm[use_rep]</code> (e.g. [0,1,2,3,4] to
use first 5 principal components when <code>use_rep</code>="X_pca"). If <code>None</code>, use
all features from <code>adata.obsm[use_rep]</code></dd>
<dt><strong><code>n_rings</code></strong> :&ensp;<code>int</code>, optional <code>(default=1)</code></dt>
<dd>Number of hexagonal rings around each spatial transcriptomics spot to blur
features by for capturing regional information. Assumes 10X Genomics Visium
platform.</dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>bool</code>, optional <code>(default </code>False<code>)</code></dt>
<dd>Use histology data from Visium anndata object (R,G,B brightfield features)
in addition to <code>adata.obsm[use_rep]</code>? If fluorescent imaging data rather
than brightfield, use <code>fluor_channels</code> argument instead.</dd>
<dt><strong><code>fluor_channels</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default </code>None<code>)</code></dt>
<dd>Channels from fluorescent image to use for model training (e.g. [1,3] for
channels 1 and 3 of Visium fluorescent imaging data). If <code>None</code>, do not
use imaging data for training.</dd>
<dt><strong><code>spatial_graph_key</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Key in <code>adata.obsp</code> containing spatial graph connectivities (i.e.
<code>"spatial_connectivities"</code>). If <code>None</code>, compute new spatial graph using
<code>n_rings</code> in <code>squidpy</code>.</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code>, optional <code>(default=-1)</code></dt>
<dd>Number of cores to parallelize over. Default all available cores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> are updated, adding "blur_*" features
to <code>.obs</code> if <code>n_rings &gt; 0</code>.
<code>self.cluster_data</code> becomes master <code>np.array</code> for cluster training.
Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_cluster_data(
    self,
    use_rep,
    features=None,
    n_rings=1,
    histo=False,
    fluor_channels=None,
    spatial_graph_key=None,
    n_jobs=-1,
):
    &#34;&#34;&#34;
    Prepare master dataframe for tissue-level clustering

    Parameters
    ----------
    use_rep : str
        Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
    features : list of int or None, optional (default=`None`)
        List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
        use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
        all features from `adata.obsm[use_rep]`
    n_rings : int, optional (default=1)
        Number of hexagonal rings around each spatial transcriptomics spot to blur
        features by for capturing regional information. Assumes 10X Genomics Visium
        platform.
    histo : bool, optional (default `False`)
        Use histology data from Visium anndata object (R,G,B brightfield features)
        in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
        than brightfield, use `fluor_channels` argument instead.
    fluor_channels : list of int or None, optional (default `None`)
        Channels from fluorescent image to use for model training (e.g. [1,3] for
        channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
        use imaging data for training.
    spatial_graph_key : str, optional (default=`None`)
        Key in `adata.obsp` containing spatial graph connectivities (i.e.
        `&#34;spatial_connectivities&#34;`). If `None`, compute new spatial graph using
        `n_rings` in `squidpy`.
    n_jobs : int, optional (default=-1)
        Number of cores to parallelize over. Default all available cores.

    Returns
    -------
    Does not return anything. `self.adatas` are updated, adding &#34;blur_*&#34; features
    to `.obs` if `n_rings &gt; 0`.
    `self.cluster_data` becomes master `np.array` for cluster training.
    Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    if self.cluster_data is not None:
        print(&#34;WARNING: overwriting existing cluster data&#34;)
        self.cluster_data = None
    if features is None:
        self.features = [x for x in range(self.adatas[0].obsm[use_rep].shape[1])]
    else:
        self.features = features
    # save the hyperparams as object attributes
    self.rep = use_rep
    self.histo = histo
    self.fluor_channels = fluor_channels
    self.n_rings = n_rings
    # collect clustering data from self.adatas in parallel
    print(
        &#34;Collecting and blurring {} features from .obsm[{}]...&#34;.format(
            len(self.features),
            use_rep,
        )
    )
    cluster_data = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(prep_data_single_sample_st)(
            adata,
            adata_i,
            use_rep,
            self.features,
            histo,
            fluor_channels,
            spatial_graph_key,
            n_rings,
        )
        for adata_i, adata in enumerate(self.adatas)
    )
    batch_labels = [
        [x] * len(cluster_data[x]) for x in range(len(cluster_data))
    ]  # batch labels for umap
    self.merged_batch_labels = list(itertools.chain(*batch_labels))
    # concatenate blurred features into cluster_data df for cluster training
    subsampled_data = pd.concat(cluster_data)
    # perform z-scaling on final cluster data
    scaler = StandardScaler()
    self.scaler = scaler.fit(subsampled_data)
    scaled_data = scaler.transform(subsampled_data)
    self.cluster_data = scaled_data
    print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.st_labeler.show_feature_overlay"><code class="name flex">
<span>def <span class="ident">show_feature_overlay</span></span>(<span>self, adata_index, pita, features=None, histo=None, cmap='tab20', label='feature', ncols=4, save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot tissue_ID with individual pita features as alpha values to distinguish
expression in identified tissue domains</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adata_index</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of adata from <code>self.adatas</code> to plot overlays for (e.g. 0 for first
adata object)</dd>
<dt><strong><code>pita</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Image of desired expression in pixel space from <code>.assemble_pita()</code></dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of features by index to show in plot. If <code>None</code>, use all features.</dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>np.array</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Histology image to show along with pita in gridspec. If <code>None</code>, ignore.</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional <code>(default="tab20")</code></dt>
<dd>Matplotlib colormap to use for plotting tissue IDs</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code></dt>
<dd>What to title each panel of the gridspec (i.e. "PC" or "usage") or each
channel in RGB image. Can also pass list of names e.g. ["NeuN","GFAP",
"DAPI"] corresponding to channels.</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of columns for gridspec</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. if <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object (if plotting one feature</code> or <code>RGB)</code> or <code>gridspec object (for</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>multiple features). Saves plot to file if <code>save_to</code> is not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_feature_overlay(
    self,
    adata_index,
    pita,
    features=None,
    histo=None,
    cmap=&#34;tab20&#34;,
    label=&#34;feature&#34;,
    ncols=4,
    save_to=None,
    **kwargs,
):
    &#34;&#34;&#34;
    Plot tissue_ID with individual pita features as alpha values to distinguish
    expression in identified tissue domains

    Parameters
    ----------
    adata_index : int
        Index of adata from `self.adatas` to plot overlays for (e.g. 0 for first
        adata object)
    pita : np.array
        Image of desired expression in pixel space from `.assemble_pita()`
    features : list of int, optional (default=`None`)
        List of features by index to show in plot. If `None`, use all features.
    histo : np.array or `None`, optional (default=`None`)
        Histology image to show along with pita in gridspec. If `None`, ignore.
    cmap : str, optional (default=&#34;tab20&#34;)
        Matplotlib colormap to use for plotting tissue IDs
    label : str
        What to title each panel of the gridspec (i.e. &#34;PC&#34; or &#34;usage&#34;) or each
        channel in RGB image. Can also pass list of names e.g. [&#34;NeuN&#34;,&#34;GFAP&#34;,
        &#34;DAPI&#34;] corresponding to channels.
    ncols : int
        Number of columns for gridspec
    save_to : str or None
        Path to image file to save results. if `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function

    Returns
    -------
    Matplotlib object (if plotting one feature or RGB) or gridspec object (for
    multiple features). Saves plot to file if `save_to` is not `None`.
    &#34;&#34;&#34;
    assert pita.ndim &gt; 1, &#34;Pita does not have enough dimensions: {} given&#34;.format(
        pita.ndim
    )
    assert pita.ndim &lt; 4, &#34;Pita has too many dimensions: {} given&#34;.format(pita.ndim)
    # create tissue_ID pita for plotting
    tIDs = assemble_pita(
        self.adatas[adata_index],
        features=&#34;tissue_ID&#34;,
        use_rep=&#34;obs&#34;,
        plot_out=False,
        verbose=False,
    )
    # if pita has multiple features, plot them in gridspec
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    # if no features are given, use all of them
    elif features is None:
        features = [x + 1 for x in range(pita.shape[2])]
    else:
        assert (
            pita.ndim &gt; 2
        ), &#34;Not enough features in pita: shape {}, expecting 3rd dim with length {}&#34;.format(
            pita.shape, len(features)
        )
        assert (
            len(features) &lt;= pita.shape[2]
        ), &#34;Too many features given: pita has {}, expected {}&#34;.format(
            pita.shape[2], len(features)
        )
    # min-max scale each feature in pita to convert to interpretable alpha values
    mms = MinMaxScaler()
    if pita.ndim == 3:
        pita_tmp = mms.fit_transform(
            pita.reshape((pita.shape[0] * pita.shape[1], pita.shape[2]))
        )
    elif pita.ndim == 2:
        pita_tmp = mms.fit_transform(
            pita.reshape((pita.shape[0] * pita.shape[1], 1))
        )
    # reshape back to original
    pita = pita_tmp.reshape(pita.shape)
    # figure out labels for gridspec plots
    if isinstance(label, str):
        # if label is single string, name channels numerically
        labels = [&#34;{}_{}&#34;.format(label, x) for x in features]
    else:
        assert len(label) == len(
            features
        ), &#34;Please provide the same number of labels as features; {} labels given, {} features given.&#34;.format(
            len(label), len(features)
        )
        labels = label
    # calculate gridspec dimensions
    if histo is not None:
        # determine where the histo image is in anndata
        assert (
            histo
            in self.adatas[adata_index]
            .uns[&#34;spatial&#34;][
                list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
            ][&#34;images&#34;]
            .keys()
        ), &#34;Must provide one of {} for histo&#34;.format(
            self.adatas[adata_index]
            .uns[&#34;spatial&#34;][
                list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
            ][&#34;images&#34;]
            .keys()
        )
        histo = self.adatas[adata_index].uns[&#34;spatial&#34;][
            list(self.adatas[adata_index].uns[&#34;spatial&#34;].keys())[0]
        ][&#34;images&#34;][histo]
        if len(features) + 2 &lt;= ncols:
            n_rows, n_cols = 1, len(features) + 2
        else:
            n_rows, n_cols = ceil((len(features) + 2) / ncols), ncols
        labels = [&#34;Histology&#34;, &#34;tissue_ID&#34;] + labels  # append to front of labels
    else:
        if len(features) + 1 &lt;= ncols:
            n_rows, n_cols = 1, len(features) + 1
        else:
            n_rows, n_cols = ceil(len(features) + 1 / ncols), ncols
        labels = [&#34;tissue_ID&#34;] + labels  # append to front of labels
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # add plots to axes
    i = 0
    if histo is not None:
        # add histology plot to first axes
        ax = plt.subplot(gs[i])
        im = ax.imshow(histo, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        i = i + 1
    # plot tissue_ID first with colorbar
    ax = plt.subplot(gs[i])
    im = ax.imshow(tIDs, cmap=cmap, **kwargs)
    ax.tick_params(labelbottom=False, labelleft=False)
    sns.despine(bottom=True, left=True)
    ax.set_title(
        label=labels[i],
        loc=&#34;left&#34;,
        fontweight=&#34;bold&#34;,
        fontsize=16,
    )
    # colorbar scale for tissue_IDs
    _ = plt.colorbar(im, shrink=0.7)
    i = i + 1
    for feature in features:
        ax = plt.subplot(gs[i])
        im = ax.imshow(tIDs, alpha=pita[:, :, feature - 1], cmap=cmap, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        i = i + 1
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=300)
    return fig</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="MILWRM.MILWRM.tissue_labeler" href="#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></b></code>:
<ul class="hlist">
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_optimal_k" href="#MILWRM.MILWRM.tissue_labeler.find_optimal_k">find_optimal_k</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_tissue_regions" href="#MILWRM.MILWRM.tissue_labeler.find_tissue_regions">find_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_loadings">plot_feature_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_proportions">plot_feature_proportions</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="MILWRM.MILWRM.tissue_labeler"><code class="flex name class">
<span>class <span class="ident">tissue_labeler</span></span>
</code></dt>
<dd>
<div class="desc"><p>Master tissue domain labeling class</p>
<p>Initialize tissue labeler parent class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class tissue_labeler:
    &#34;&#34;&#34;
    Master tissue domain labeling class
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;
        Initialize tissue labeler parent class
        &#34;&#34;&#34;
        self.cluster_data = None  # start out with no data to cluster on
        self.k = None  # start out with no k value

    def find_optimal_k(self, plot_out=False, alpha=0.05, random_state=18, n_jobs=-1):
        &#34;&#34;&#34;
        Uses scaled inertia to decide on k clusters for clustering in the
        corresponding `anndata` objects

        Parameters
        ----------
        plot_out : boolean, optional (default=FALSE)
            Determines if scaled inertia graph should be output
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        random_state : int, optional (default=18)
            Seed for k-means clustering models
        n_jobs : int
            Number of cores to parallelize k-choosing across

        Returns
        -------
        Does not return anything. `self.k` contains integer value for number of
        clusters. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is None:
            raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
        self.random_state = random_state

        k_range = range(2, 21)  # choose k range
        # compute scaled inertia
        best_k, results = chooseBestKforKMeansParallel(
            self.cluster_data,
            k_range,
            n_jobs=n_jobs,
            random_state=random_state,
            alpha_k=alpha,
        )
        if plot_out:
            # plot the results
            plt.figure(figsize=(7, 4))
            plt.plot(results, &#34;o&#34;)
            plt.title(&#34;Adjusted Inertia for each K&#34;)
            plt.xlabel(&#34;K&#34;)
            plt.ylabel(&#34;Adjusted Inertia&#34;)
            plt.xticks(range(2, 21, 1))
            plt.show()
        # save optimal k to object
        print(&#34;The optimal number of clusters is {}&#34;.format(best_k))
        self.k = best_k

    def find_tissue_regions(self, k=None, random_state=18):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        `anndata` objects.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue domains to define
        random_state : int, optional (default=18)
            Seed for k-means clustering model.

        Returns
        -------
        Does not return anything. `self.kmeans` contains trained `sklearn` clustering
        model. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is None:
            raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
        if k is None and self.k is None:
            raise Exception(
                &#34;No k found or provided. Run find_optimal_k() first or pass a k value.&#34;
            )
        if k is not None:
            print(&#34;Overriding optimal k value with k={}.&#34;.format(k))
            self.k = k
        # save the hyperparams as object attributes
        self.random_state = random_state
        print(&#34;Performing k-means clustering with {} target clusters&#34;.format(self.k))
        self.kmeans = KMeans(n_clusters=self.k, random_state=random_state).fit(
            self.cluster_data
        )

    def plot_feature_proportions(self, labels=None, figsize=(10, 7), save_to=None):
        &#34;&#34;&#34;
        Plots contributions of each training feature to k-means cluster centers as
        percentages of total

        Parameters
        ----------
        labels : list of str, optional (default=`None`)
            Labels corresponding to each MILWRM training feature. If `None`, features
            will be numbered 0 through p.
        figsize : tuple of float, optional (default=(10,7))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `plt.figure` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        if &#34;st_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
                if self.histo:
                    labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
                if self.fluor_channels is not None:
                    labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
        elif &#34;mxif_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = self.model_features
        # create pandas df and calculate percentages of total
        ctr_df = pd.DataFrame(self.kmeans.cluster_centers_, columns=labels)
        totals = ctr_df.sum(axis=1)
        ctr_df_prop = ctr_df.div(totals, axis=0).multiply(100)
        # make plot
        fig, ax = plt.subplots(1, 1, figsize=figsize)
        ctr_df_prop.plot.bar(stacked=True, ax=ax, width=0.85)
        for p in ax.patches:
            ax.annotate(
                &#34;{} %&#34;.format(str(np.round(p.get_height(), 2))),
                (p.get_x() + 0.05, p.get_y() + (p.get_height() * 0.4)),
                fontsize=10,
            )
        plt.ylim([0, 100])
        plt.xlabel(&#34;tissue_ID&#34;)
        plt.xticks(rotation=0)
        plt.ylabel(&#34;% K-Means Loading&#34;)
        plt.legend(bbox_to_anchor=(1, 1), loc=&#34;upper left&#34;, title=&#34;Feature&#34;)
        plt.tight_layout()
        if save_to is not None:
            print(&#34;Saving feature proportions to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return fig

    def plot_feature_loadings(
        self,
        ncols=None,
        nfeatures=None,
        labels=None,
        titles=None,
        figsize=(5, 5),
        save_to=None,
    ):
        &#34;&#34;&#34;
        Plots contributions of each training feature to k-means cluster centers

        Parameters
        ----------
        ncols : int, optional (default=`None`)
            Number of columns for gridspec. If `None`, uses number of tissue domains k.
        nfeatures : int, optional (default=`None`)
            Number of top-loaded features to show for each tissue domain
        labels : list of str, optional (default=`None`)
            Labels corresponding to each MILWRM training feature. If `None`, features
            will be numbered 0 through p.
        titles : list of str, optional (default=`None`)
            Titles of plots corresponding to each MILWRM domain. If `None`, titles
            will be numbers 0 through k.
        figsize : tuple of float, optional (default=(5,5))
            Size of matplotlib figure
        save_to : str, optional (default=`None`)
            Path to image file to save plot

        Returns
        -------
        `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
        &#34;&#34;&#34;
        assert (
            self.kmeans is not None
        ), &#34;No cluster results found. Run \
        label_tissue_regions() first.&#34;
        if &#34;st_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
                if self.histo:
                    labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
                if self.fluor_channels is not None:
                    labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
        elif &#34;mxif_labeler&#34; in str(self.__class__):
            if labels is not None:
                assert len(labels) == len(
                    self.features
                ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
            else:
                labels = self.model_features
        if titles is None:
            titles = [
                &#34;tissue_ID &#34; + str(x)
                for x in range(self.kmeans.cluster_centers_.shape[0])
            ]
        if nfeatures is None:
            nfeatures = len(labels)
        scores = self.kmeans.cluster_centers_.copy()
        n_panels = len(titles)
        if ncols is None:
            ncols = len(titles)
        if n_panels &lt;= ncols:
            n_rows, n_cols = 1, n_panels
        else:
            n_rows, n_cols = ceil(n_panels / ncols), ncols
        fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
        left, bottom = 0.1 / n_cols, 0.1 / n_rows
        gs = gridspec.GridSpec(
            nrows=n_rows,
            ncols=n_cols,
            wspace=0.1,
            left=left,
            bottom=bottom,
            right=1 - (n_cols - 1) * left - 0.01 / n_cols,
            top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
        )
        for iscore, score in enumerate(scores):
            plt.subplot(gs[iscore])
            indices = np.argsort(score)[::-1][: nfeatures + 1]
            for ig, g in enumerate(indices[::-1]):
                plt.text(
                    x=score[g],
                    y=ig,
                    s=labels[g],
                    color=&#34;black&#34;,
                    verticalalignment=&#34;center&#34;,
                    horizontalalignment=&#34;right&#34;,
                    fontsize=&#34;medium&#34;,
                    fontstyle=&#34;italic&#34;,
                )
            plt.title(titles[iscore], fontsize=&#34;x-large&#34;)
            plt.ylim(-0.9, ig + 0.9)
            score_min, score_max = np.min(score[indices]), np.max(score[indices])
            plt.xlim(
                (0.95 if score_min &gt; 0 else 1.05) * score_min,
                (1.05 if score_max &gt; 0 else 0.95) * score_max,
            )
            plt.xticks(rotation=45)
            plt.tick_params(labelsize=&#34;medium&#34;)
            plt.tick_params(
                axis=&#34;y&#34;,  # changes apply to the y-axis
                which=&#34;both&#34;,  # both major and minor ticks are affected
                left=False,
                right=False,
                labelleft=False,
            )
            plt.grid(False)
        gs.tight_layout(fig)
        if save_to is not None:
            print(&#34;Saving feature loadings to {}&#34;.format(save_to))
            plt.savefig(save_to)
        else:
            return gs</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="MILWRM.MILWRM.mxif_labeler" href="#MILWRM.MILWRM.mxif_labeler">mxif_labeler</a></li>
<li><a title="MILWRM.MILWRM.st_labeler" href="#MILWRM.MILWRM.st_labeler">st_labeler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.MILWRM.tissue_labeler.find_optimal_k"><code class="name flex">
<span>def <span class="ident">find_optimal_k</span></span>(<span>self, plot_out=False, alpha=0.05, random_state=18, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Uses scaled inertia to decide on k clusters for clustering in the
corresponding <code>anndata</code> objects</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>boolean</code>, optional <code>(default=FALSE)</code></dt>
<dd>Determines if scaled inertia graph should be output</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering models</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing across</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.k</code> contains integer value for number of
clusters. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_optimal_k(self, plot_out=False, alpha=0.05, random_state=18, n_jobs=-1):
    &#34;&#34;&#34;
    Uses scaled inertia to decide on k clusters for clustering in the
    corresponding `anndata` objects

    Parameters
    ----------
    plot_out : boolean, optional (default=FALSE)
        Determines if scaled inertia graph should be output
    alpha: float
        Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
    random_state : int, optional (default=18)
        Seed for k-means clustering models
    n_jobs : int
        Number of cores to parallelize k-choosing across

    Returns
    -------
    Does not return anything. `self.k` contains integer value for number of
    clusters. Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    if self.cluster_data is None:
        raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
    self.random_state = random_state

    k_range = range(2, 21)  # choose k range
    # compute scaled inertia
    best_k, results = chooseBestKforKMeansParallel(
        self.cluster_data,
        k_range,
        n_jobs=n_jobs,
        random_state=random_state,
        alpha_k=alpha,
    )
    if plot_out:
        # plot the results
        plt.figure(figsize=(7, 4))
        plt.plot(results, &#34;o&#34;)
        plt.title(&#34;Adjusted Inertia for each K&#34;)
        plt.xlabel(&#34;K&#34;)
        plt.ylabel(&#34;Adjusted Inertia&#34;)
        plt.xticks(range(2, 21, 1))
        plt.show()
    # save optimal k to object
    print(&#34;The optimal number of clusters is {}&#34;.format(best_k))
    self.k = best_k</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.tissue_labeler.find_tissue_regions"><code class="name flex">
<span>def <span class="ident">find_tissue_regions</span></span>(<span>self, k=None, random_state=18)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform tissue-level clustering and label pixels in the corresponding
<code>anndata</code> objects.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Number of tissue domains to define</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.kmeans</code> contains trained <code>sklearn</code> clustering
model. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_tissue_regions(self, k=None, random_state=18):
    &#34;&#34;&#34;
    Perform tissue-level clustering and label pixels in the corresponding
    `anndata` objects.

    Parameters
    ----------
    k : int, optional (default=None)
        Number of tissue domains to define
    random_state : int, optional (default=18)
        Seed for k-means clustering model.

    Returns
    -------
    Does not return anything. `self.kmeans` contains trained `sklearn` clustering
    model. Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    if self.cluster_data is None:
        raise Exception(&#34;No cluster data found. Run prep_cluster_data() first.&#34;)
    if k is None and self.k is None:
        raise Exception(
            &#34;No k found or provided. Run find_optimal_k() first or pass a k value.&#34;
        )
    if k is not None:
        print(&#34;Overriding optimal k value with k={}.&#34;.format(k))
        self.k = k
    # save the hyperparams as object attributes
    self.random_state = random_state
    print(&#34;Performing k-means clustering with {} target clusters&#34;.format(self.k))
    self.kmeans = KMeans(n_clusters=self.k, random_state=random_state).fit(
        self.cluster_data
    )</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings"><code class="name flex">
<span>def <span class="ident">plot_feature_loadings</span></span>(<span>self, ncols=None, nfeatures=None, labels=None, titles=None, figsize=(5, 5), save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots contributions of each training feature to k-means cluster centers</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Number of columns for gridspec. If <code>None</code>, uses number of tissue domains k.</dd>
<dt><strong><code>nfeatures</code></strong> :&ensp;<code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Number of top-loaded features to show for each tissue domain</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Labels corresponding to each MILWRM training feature. If <code>None</code>, features
will be numbered 0 through p.</dd>
<dt><strong><code>titles</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Titles of plots corresponding to each MILWRM domain. If <code>None</code>, titles
will be numbers 0 through k.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(5,5))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>gridspec.GridSpec</code> if <code>save_to</code> is <code>None</code>, else saves plot to file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_feature_loadings(
    self,
    ncols=None,
    nfeatures=None,
    labels=None,
    titles=None,
    figsize=(5, 5),
    save_to=None,
):
    &#34;&#34;&#34;
    Plots contributions of each training feature to k-means cluster centers

    Parameters
    ----------
    ncols : int, optional (default=`None`)
        Number of columns for gridspec. If `None`, uses number of tissue domains k.
    nfeatures : int, optional (default=`None`)
        Number of top-loaded features to show for each tissue domain
    labels : list of str, optional (default=`None`)
        Labels corresponding to each MILWRM training feature. If `None`, features
        will be numbered 0 through p.
    titles : list of str, optional (default=`None`)
        Titles of plots corresponding to each MILWRM domain. If `None`, titles
        will be numbers 0 through k.
    figsize : tuple of float, optional (default=(5,5))
        Size of matplotlib figure
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    `gridspec.GridSpec` if `save_to` is `None`, else saves plot to file
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    if &#34;st_labeler&#34; in str(self.__class__):
        if labels is not None:
            assert len(labels) == len(
                self.features
            ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
        else:
            labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
            if self.histo:
                labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
            if self.fluor_channels is not None:
                labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
    elif &#34;mxif_labeler&#34; in str(self.__class__):
        if labels is not None:
            assert len(labels) == len(
                self.features
            ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
        else:
            labels = self.model_features
    if titles is None:
        titles = [
            &#34;tissue_ID &#34; + str(x)
            for x in range(self.kmeans.cluster_centers_.shape[0])
        ]
    if nfeatures is None:
        nfeatures = len(labels)
    scores = self.kmeans.cluster_centers_.copy()
    n_panels = len(titles)
    if ncols is None:
        ncols = len(titles)
    if n_panels &lt;= ncols:
        n_rows, n_cols = 1, n_panels
    else:
        n_rows, n_cols = ceil(n_panels / ncols), ncols
    fig = plt.figure(figsize=(n_cols * figsize[0], n_rows * figsize[1]))
    left, bottom = 0.1 / n_cols, 0.1 / n_rows
    gs = gridspec.GridSpec(
        nrows=n_rows,
        ncols=n_cols,
        wspace=0.1,
        left=left,
        bottom=bottom,
        right=1 - (n_cols - 1) * left - 0.01 / n_cols,
        top=1 - (n_rows - 1) * bottom - 0.1 / n_rows,
    )
    for iscore, score in enumerate(scores):
        plt.subplot(gs[iscore])
        indices = np.argsort(score)[::-1][: nfeatures + 1]
        for ig, g in enumerate(indices[::-1]):
            plt.text(
                x=score[g],
                y=ig,
                s=labels[g],
                color=&#34;black&#34;,
                verticalalignment=&#34;center&#34;,
                horizontalalignment=&#34;right&#34;,
                fontsize=&#34;medium&#34;,
                fontstyle=&#34;italic&#34;,
            )
        plt.title(titles[iscore], fontsize=&#34;x-large&#34;)
        plt.ylim(-0.9, ig + 0.9)
        score_min, score_max = np.min(score[indices]), np.max(score[indices])
        plt.xlim(
            (0.95 if score_min &gt; 0 else 1.05) * score_min,
            (1.05 if score_max &gt; 0 else 0.95) * score_max,
        )
        plt.xticks(rotation=45)
        plt.tick_params(labelsize=&#34;medium&#34;)
        plt.tick_params(
            axis=&#34;y&#34;,  # changes apply to the y-axis
            which=&#34;both&#34;,  # both major and minor ticks are affected
            left=False,
            right=False,
            labelleft=False,
        )
        plt.grid(False)
    gs.tight_layout(fig)
    if save_to is not None:
        print(&#34;Saving feature loadings to {}&#34;.format(save_to))
        plt.savefig(save_to)
    else:
        return gs</code></pre>
</details>
</dd>
<dt id="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions"><code class="name flex">
<span>def <span class="ident">plot_feature_proportions</span></span>(<span>self, labels=None, figsize=(10, 7), save_to=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots contributions of each training feature to k-means cluster centers as
percentages of total</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code> of <code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Labels corresponding to each MILWRM training feature. If <code>None</code>, features
will be numbered 0 through p.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional <code>(default=(10,7))</code></dt>
<dd>Size of matplotlib figure</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Path to image file to save plot</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>plt.figure</code> if <code>save_to</code> is <code>None</code>, else saves plot to file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_feature_proportions(self, labels=None, figsize=(10, 7), save_to=None):
    &#34;&#34;&#34;
    Plots contributions of each training feature to k-means cluster centers as
    percentages of total

    Parameters
    ----------
    labels : list of str, optional (default=`None`)
        Labels corresponding to each MILWRM training feature. If `None`, features
        will be numbered 0 through p.
    figsize : tuple of float, optional (default=(10,7))
        Size of matplotlib figure
    save_to : str, optional (default=`None`)
        Path to image file to save plot

    Returns
    -------
    `plt.figure` if `save_to` is `None`, else saves plot to file
    &#34;&#34;&#34;
    assert (
        self.kmeans is not None
    ), &#34;No cluster results found. Run \
    label_tissue_regions() first.&#34;
    if &#34;st_labeler&#34; in str(self.__class__):
        if labels is not None:
            assert len(labels) == len(
                self.features
            ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
        else:
            labels = [self.rep + &#34;_&#34; + str(x) for x in self.features]
            if self.histo:
                labels = labels + [&#34;R&#34;, &#34;G&#34;, &#34;B&#34;]
            if self.fluor_channels is not None:
                labels = labels + [&#34;ch_&#34; + str(x) for x in self.fluor_channels]
    elif &#34;mxif_labeler&#34; in str(self.__class__):
        if labels is not None:
            assert len(labels) == len(
                self.features
            ), &#34;&#39;labels&#39; must be the same length as self.features.&#34;
        else:
            labels = self.model_features
    # create pandas df and calculate percentages of total
    ctr_df = pd.DataFrame(self.kmeans.cluster_centers_, columns=labels)
    totals = ctr_df.sum(axis=1)
    ctr_df_prop = ctr_df.div(totals, axis=0).multiply(100)
    # make plot
    fig, ax = plt.subplots(1, 1, figsize=figsize)
    ctr_df_prop.plot.bar(stacked=True, ax=ax, width=0.85)
    for p in ax.patches:
        ax.annotate(
            &#34;{} %&#34;.format(str(np.round(p.get_height(), 2))),
            (p.get_x() + 0.05, p.get_y() + (p.get_height() * 0.4)),
            fontsize=10,
        )
    plt.ylim([0, 100])
    plt.xlabel(&#34;tissue_ID&#34;)
    plt.xticks(rotation=0)
    plt.ylabel(&#34;% K-Means Loading&#34;)
    plt.legend(bbox_to_anchor=(1, 1), loc=&#34;upper left&#34;, title=&#34;Feature&#34;)
    plt.tight_layout()
    if save_to is not None:
        print(&#34;Saving feature proportions to {}&#34;.format(save_to))
        plt.savefig(save_to)
    else:
        return fig</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="MILWRM" href="index.html">MILWRM</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="MILWRM.MILWRM.add_tissue_ID_single_sample_mxif" href="#MILWRM.MILWRM.add_tissue_ID_single_sample_mxif">add_tissue_ID_single_sample_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.chooseBestKforKMeansParallel" href="#MILWRM.MILWRM.chooseBestKforKMeansParallel">chooseBestKforKMeansParallel</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_confidence_score_mxif" href="#MILWRM.MILWRM.estimate_confidence_score_mxif">estimate_confidence_score_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_confidence_score_st" href="#MILWRM.MILWRM.estimate_confidence_score_st">estimate_confidence_score_st</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_mse_mxif" href="#MILWRM.MILWRM.estimate_mse_mxif">estimate_mse_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_mse_st" href="#MILWRM.MILWRM.estimate_mse_st">estimate_mse_st</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_percentage_variance_mxif" href="#MILWRM.MILWRM.estimate_percentage_variance_mxif">estimate_percentage_variance_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.estimate_percentage_variance_st" href="#MILWRM.MILWRM.estimate_percentage_variance_st">estimate_percentage_variance_st</a></code></li>
<li><code><a title="MILWRM.MILWRM.kMeansRes" href="#MILWRM.MILWRM.kMeansRes">kMeansRes</a></code></li>
<li><code><a title="MILWRM.MILWRM.perform_umap" href="#MILWRM.MILWRM.perform_umap">perform_umap</a></code></li>
<li><code><a title="MILWRM.MILWRM.prep_data_single_sample_mxif" href="#MILWRM.MILWRM.prep_data_single_sample_mxif">prep_data_single_sample_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.prep_data_single_sample_st" href="#MILWRM.MILWRM.prep_data_single_sample_st">prep_data_single_sample_st</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="MILWRM.MILWRM.mxif_labeler" href="#MILWRM.MILWRM.mxif_labeler">mxif_labeler</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.MILWRM.mxif_labeler.confidence_score_images" href="#MILWRM.MILWRM.mxif_labeler.confidence_score_images">confidence_score_images</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.label_tissue_regions" href="#MILWRM.MILWRM.mxif_labeler.label_tissue_regions">label_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.make_umap" href="#MILWRM.MILWRM.mxif_labeler.make_umap">make_umap</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.plot_mse_mxif" href="#MILWRM.MILWRM.mxif_labeler.plot_mse_mxif">plot_mse_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.plot_percentage_variance_explained" href="#MILWRM.MILWRM.mxif_labeler.plot_percentage_variance_explained">plot_percentage_variance_explained</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.plot_tissue_ID_proportions_mxif" href="#MILWRM.MILWRM.mxif_labeler.plot_tissue_ID_proportions_mxif">plot_tissue_ID_proportions_mxif</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.prep_cluster_data" href="#MILWRM.MILWRM.mxif_labeler.prep_cluster_data">prep_cluster_data</a></code></li>
<li><code><a title="MILWRM.MILWRM.mxif_labeler.show_marker_overlay" href="#MILWRM.MILWRM.mxif_labeler.show_marker_overlay">show_marker_overlay</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="MILWRM.MILWRM.st_labeler" href="#MILWRM.MILWRM.st_labeler">st_labeler</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.MILWRM.st_labeler.confidence_score" href="#MILWRM.MILWRM.st_labeler.confidence_score">confidence_score</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.label_tissue_regions" href="#MILWRM.MILWRM.st_labeler.label_tissue_regions">label_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.plot_gene_loadings" href="#MILWRM.MILWRM.st_labeler.plot_gene_loadings">plot_gene_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.plot_mse_st" href="#MILWRM.MILWRM.st_labeler.plot_mse_st">plot_mse_st</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.plot_percentage_variance_explained" href="#MILWRM.MILWRM.st_labeler.plot_percentage_variance_explained">plot_percentage_variance_explained</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.plot_tissue_ID_proportions_st" href="#MILWRM.MILWRM.st_labeler.plot_tissue_ID_proportions_st">plot_tissue_ID_proportions_st</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.prep_cluster_data" href="#MILWRM.MILWRM.st_labeler.prep_cluster_data">prep_cluster_data</a></code></li>
<li><code><a title="MILWRM.MILWRM.st_labeler.show_feature_overlay" href="#MILWRM.MILWRM.st_labeler.show_feature_overlay">show_feature_overlay</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="MILWRM.MILWRM.tissue_labeler" href="#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_optimal_k" href="#MILWRM.MILWRM.tissue_labeler.find_optimal_k">find_optimal_k</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_tissue_regions" href="#MILWRM.MILWRM.tissue_labeler.find_tissue_regions">find_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_loadings">plot_feature_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions" href="#MILWRM.MILWRM.tissue_labeler.plot_feature_proportions">plot_feature_proportions</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>