<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>MILWRM API documentation</title>
<meta name="description" content="Multiplex Image Labeling With Regional Morphology" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>MILWRM</code></h1>
</header>
<section id="section-intro">
<p>Multiplex Image Labeling With Regional Morphology</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Multiplex Image Labeling With Regional Morphology
&#34;&#34;&#34;
from .MILWRM import (
    mxif_labeler,
    st_labeler,
)
from .MxIF import img
from .ST import (
    map_pixels,
    trim_image,
    assemble_pita,
    show_pita,
)

__all__ = [
    &#34;img&#34;,
    &#34;map_pixels&#34;,
    &#34;trim_image&#34;,
    &#34;assemble_pita&#34;,
    &#34;show_pita&#34;,
    &#34;mxif_labeler&#34;,
    &#34;st_labeler&#34;,
]

from ._version import get_versions

__version__ = get_versions()[&#34;version&#34;]
del get_versions</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="MILWRM.MILWRM" href="MILWRM.html">MILWRM.MILWRM</a></code></dt>
<dd>
<div class="desc"><p>Classes for assigning tissue region IDs to multiplex immunofluorescence (MxIF) or 10X
Visium spatial transcriptomic (ST) and histological imaging data</p></div>
</dd>
<dt><code class="name"><a title="MILWRM.MxIF" href="MxIF.html">MILWRM.MxIF</a></code></dt>
<dd>
<div class="desc"><p>Functions and classes for analyzing multiplex imaging data</p></div>
</dd>
<dt><code class="name"><a title="MILWRM.ST" href="ST.html">MILWRM.ST</a></code></dt>
<dd>
<div class="desc"><p>Functions and classes for manipulating 10X Visium spatial transcriptomic (ST) and
histological imaging data</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="MILWRM.assemble_pita"><code class="name flex">
<span>def <span class="ident">assemble_pita</span></span>(<span>adata, features=None, use_rep=None, layer=None, plot_out=True, histo=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Cast feature into pixel space to construct gene expression image ("pita")</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adata</code></strong> :&ensp;<code>AnnData.anndata</code></dt>
<dd>the data</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Names or indices of features to cast onto spot image. If <code>None</code>, cast all
features. If <code>plot_out</code>, first feature in list will be plotted. If not
specified and <code>plot_out</code>, first feature (index 0) will be plotted.</dd>
<dt><strong><code>use_rep</code></strong> :&ensp;<code>str</code></dt>
<dd>Key from <code>adata.obsm</code> to use for plotting. If <code>None</code>, use <code>adata.X</code>.</dd>
<dt>layer :str</dt>
<dt>Key from <code>adata.layers</code> to use for plotting. Ignored if <code>use_rep</code> is not <code>None</code></dt>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code></dt>
<dd>Show resulting image?</dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>str</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Histology image to show along with pita in gridspec (i.e. "hires",
"hires_trim", "lowres"). If <code>None</code> or if <code>plot_out</code>==<code>False</code>, ignore.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code><a title="MILWRM.show_pita" href="#MILWRM.show_pita">show_pita()</a></code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>assembled</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Image of desired expression in pixel space</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assemble_pita(
    adata, features=None, use_rep=None, layer=None, plot_out=True, histo=None, **kwargs
):
    &#34;&#34;&#34;
    Cast feature into pixel space to construct gene expression image (&#34;pita&#34;)

    Parameters
    ----------
    adata : AnnData.anndata
        the data
    features : list of int or str
        Names or indices of features to cast onto spot image. If `None`, cast all
        features. If `plot_out`, first feature in list will be plotted. If not
        specified and `plot_out`, first feature (index 0) will be plotted.
    use_rep : str
        Key from `adata.obsm` to use for plotting. If `None`, use `adata.X`.
    layer :str
        Key from `adata.layers` to use for plotting. Ignored if `use_rep` is not `None`
    plot_out : bool
        Show resulting image?
    histo : str or `None`, optional (default=`None`)
        Histology image to show along with pita in gridspec (i.e. &#34;hires&#34;,
        &#34;hires_trim&#34;, &#34;lowres&#34;). If `None` or if `plot_out`==`False`, ignore.
    **kwargs
        Arguments to pass to `show_pita()` function

    Returns
    -------
    assembled : np.array
        Image of desired expression in pixel space
    &#34;&#34;&#34;
    assert (
        adata.uns[&#34;pixel_map_params&#34;] is not None
    ), &#34;Pixel map not yet created. Run map_pixels() first.&#34;

    # coerce features to list if only single string
    if features and not isinstance(features, list):
        features = [features]

    if use_rep is None:
        # use all genes if no gene features specified
        if not features:
            features = adata.var_names  # [adata.var.highly_variable == 1].tolist()
        if layer is None:
            print(&#34;Assembling pita with {} features from adata.X&#34;.format(len(features)))
            mapper = pd.DataFrame(
                adata.X[:, [adata.var_names.get_loc(x) for x in features]],
                index=adata.obs_names,
            )
        else:
            print(
                &#34;Assembling pita with {} features from adata.layers[&#39;{}&#39;]&#34;.format(
                    len(features), layer
                )
            )
            mapper = pd.DataFrame(
                adata.layers[layer][:, [adata.var_names.get_loc(x) for x in features]],
                index=adata.obs_names,
            )
    elif use_rep in [&#34;.obs&#34;, &#34;obs&#34;]:
        assert features is not None, &#34;Must provide feature(s) from adata.obs&#34;
        print(&#34;Assembling pita with {} features from adata.obs&#34;.format(len(features)))
        if all(isinstance(x, int) for x in features):
            mapper = adata.obs.iloc[:, features].copy()
        else:
            mapper = adata.obs[features].copy()
            features = None  # set features to None in case show==True
    else:
        if not features:
            print(
                &#34;Assembling pita with {} features from adata.obsm[&#39;{}&#39;]&#34;.format(
                    adata.obsm[use_rep].shape[1], use_rep
                )
            )
            mapper = pd.DataFrame(adata.obsm[use_rep], index=adata.obs_names)
        else:
            assert all(
                isinstance(x, int) for x in features
            ), &#34;Features must be integer indices if using rep from adata.obsm&#34;
            print(
                &#34;Assembling pita with {} features from adata.obsm[&#39;{}&#39;]&#34;.format(
                    len(features), use_rep
                )
            )
            mapper = pd.DataFrame(
                adata.obsm[use_rep][:, features], index=adata.obs_names
            )

    # cast barcodes into pixel dimensions for reindexing
    print(&#34;Casting barcodes to pixel dimensions and saving to adata.uns[&#39;pixel_map&#39;]&#34;)
    pixel_map = (
        adata.uns[&#34;pixel_map_df&#34;].pivot(index=&#34;y&#34;, columns=&#34;x&#34;, values=&#34;barcode&#34;).values
    )

    assembled = np.array(
        [mapper.reindex(index=pixel_map[x], copy=True) for x in range(len(pixel_map))]
    ).squeeze()

    if plot_out:
        # determine where the histo image is in anndata
        if histo is not None:
            assert (
                histo
                in adata.uns[&#34;spatial&#34;][list(adata.uns[&#34;spatial&#34;].keys())[0]][
                    &#34;images&#34;
                ].keys()
            ), &#34;Must provide one of {} for histo&#34;.format(
                adata.uns[&#34;spatial&#34;][list(adata.uns[&#34;spatial&#34;].keys())[0]][
                    &#34;images&#34;
                ].keys()
            )
            histo = adata.uns[&#34;spatial&#34;][list(adata.uns[&#34;spatial&#34;].keys())[0]][
                &#34;images&#34;
            ][histo]
        show_pita(pita=assembled, features=features, histo=histo, **kwargs)
    print(&#34;Done!&#34;)
    return assembled</code></pre>
</details>
</dd>
<dt id="MILWRM.map_pixels"><code class="name flex">
<span>def <span class="ident">map_pixels</span></span>(<span>adata, filter_label='in_tissue', img_key='hires', library_id=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Map spot IDs to 'pixel space' by assigning spot ID values to evenly spaced grid</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adata</code></strong> :&ensp;<code>AnnData.anndata</code></dt>
<dd>The data</dd>
<dt><strong><code>filter_label</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>adata.obs column key that contains binary labels for filtering barcodes. If
None, do not filter.</dd>
<dt><strong><code>img_key</code></strong> :&ensp;<code>str</code></dt>
<dd>adata.uns key containing the image to use for mapping</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>adata</code></strong> :&ensp;<code>AnnData.anndata</code></dt>
<dd>with the following attributes:
adata.uns["pixel_map_df"] : pd.DataFrame
Long-form dataframe of Visium spot barcode IDs, pixel coordinates, and
.obs metadata
adata.uns["pixel_map"] : np.array
Pixel space array of Visium spot barcode IDs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_pixels(adata, filter_label=&#34;in_tissue&#34;, img_key=&#34;hires&#34;, library_id=None):
    &#34;&#34;&#34;
    Map spot IDs to &#39;pixel space&#39; by assigning spot ID values to evenly spaced grid

    Parameters
    ----------
    adata : AnnData.anndata
        The data
    filter_label : str or None
        adata.obs column key that contains binary labels for filtering barcodes. If
        None, do not filter.
    img_key : str
        adata.uns key containing the image to use for mapping

    Returns
    -------
    adata : AnnData.anndata
        with the following attributes:
        adata.uns[&#34;pixel_map_df&#34;] : pd.DataFrame
            Long-form dataframe of Visium spot barcode IDs, pixel coordinates, and
            .obs metadata
        adata.uns[&#34;pixel_map&#34;] : np.array
            Pixel space array of Visium spot barcode IDs
    &#34;&#34;&#34;
    adata.uns[&#34;pixel_map_params&#34;] = {
        &#34;img_key&#34;: img_key
    }  # create params dict for future use
    # add library_id key to params
    if library_id is None:
        library_id = adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;] = list(
            adata.uns[&#34;spatial&#34;].keys()
        )[0]
    else:
        adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;] = library_id
    # first get center-to-face pixel distance of hexagonal Visium spots
    dist = euclidean_distances(adata.obsm[&#34;spatial&#34;])
    adata.uns[&#34;pixel_map_params&#34;][&#34;ctr_to_face&#34;] = (
        np.unique(dist)[np.unique(dist) != 0].min() / 2
    )
    # also save center-to-vertex pixel distance as vadata attribute
    adata.uns[&#34;pixel_map_params&#34;][&#34;ctr_to_vert&#34;] = adata.uns[&#34;pixel_map_params&#34;][
        &#34;ctr_to_face&#34;
    ] / np.cos(30 * (np.pi / 180))
    # get the spot radius from adata.uns[&#34;spatial&#34;] as well
    adata.uns[&#34;pixel_map_params&#34;][&#34;radius&#34;] = (
        adata.uns[&#34;spatial&#34;][library_id][&#34;scalefactors&#34;][&#34;spot_diameter_fullres&#34;] / 2
    )
    # get scale factor from adata.uns[&#34;spatial&#34;]
    adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;] = adata.uns[&#34;spatial&#34;][library_id][
        &#34;scalefactors&#34;
    ][f&#34;tissue_{img_key}_scalef&#34;]

    # determine pixel bounds from spot coords, adding center-to-face distance
    adata.uns[&#34;pixel_map_params&#34;][&#34;xmin_px&#34;] = int(
        np.floor(
            adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;]
            * (
                adata.obsm[&#34;spatial&#34;][:, 0].min()
                - adata.uns[&#34;pixel_map_params&#34;][&#34;radius&#34;]
            )
        )
    )
    adata.uns[&#34;pixel_map_params&#34;][&#34;xmax_px&#34;] = int(
        np.ceil(
            adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;]
            * (
                adata.obsm[&#34;spatial&#34;][:, 0].max()
                + adata.uns[&#34;pixel_map_params&#34;][&#34;radius&#34;]
            )
        )
    )
    adata.uns[&#34;pixel_map_params&#34;][&#34;ymin_px&#34;] = int(
        np.floor(
            adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;]
            * (
                adata.obsm[&#34;spatial&#34;][:, 1].min()
                - adata.uns[&#34;pixel_map_params&#34;][&#34;radius&#34;]
            )
        )
    )
    adata.uns[&#34;pixel_map_params&#34;][&#34;ymax_px&#34;] = int(
        np.ceil(
            adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;]
            * (
                adata.obsm[&#34;spatial&#34;][:, 1].max()
                + adata.uns[&#34;pixel_map_params&#34;][&#34;radius&#34;]
            )
        )
    )

    print(&#34;Creating pixel grid and mapping to nearest barcode coordinates&#34;)
    # define grid for pixel space
    grid_y, grid_x = np.mgrid[
        adata.uns[&#34;pixel_map_params&#34;][&#34;ymin_px&#34;] : adata.uns[&#34;pixel_map_params&#34;][
            &#34;ymax_px&#34;
        ],
        adata.uns[&#34;pixel_map_params&#34;][&#34;xmin_px&#34;] : adata.uns[&#34;pixel_map_params&#34;][
            &#34;xmax_px&#34;
        ],
    ]
    # map barcodes to pixel coordinates
    pixel_coords = np.column_stack((grid_x.ravel(order=&#34;C&#34;), grid_y.ravel(order=&#34;C&#34;)))
    barcode_list = griddata(
        np.multiply(adata.obsm[&#34;spatial&#34;], adata.uns[&#34;pixel_map_params&#34;][&#34;scalef&#34;]),
        adata.obs_names,
        (pixel_coords[:, 0], pixel_coords[:, 1]),
        method=&#34;nearest&#34;,
    )
    # save grid_x and grid_y to adata.uns
    adata.uns[&#34;grid_x&#34;], adata.uns[&#34;grid_y&#34;] = grid_x, grid_y

    # put results into DataFrame for filtering and reindexing
    print(&#34;Saving barcode mapping to adata.uns[&#39;pixel_map_df&#39;] and adding metadata&#34;)
    adata.uns[&#34;pixel_map_df&#34;] = pd.DataFrame(pixel_coords, columns=[&#34;x&#34;, &#34;y&#34;])
    # add barcodes to long-form dataframe
    adata.uns[&#34;pixel_map_df&#34;][&#34;barcode&#34;] = barcode_list
    # merge master df with self.adata.obs for metadata
    adata.uns[&#34;pixel_map_df&#34;] = adata.uns[&#34;pixel_map_df&#34;].merge(
        adata.obs, how=&#34;outer&#34;, left_on=&#34;barcode&#34;, right_index=True
    )
    # filter using label from adata.obs if desired (i.e. &#34;in_tissue&#34;)
    if filter_label is not None:
        print(
            &#34;Filtering barcodes using labels in self.adata.obs[&#39;{}&#39;]&#34;.format(
                filter_label
            )
        )
        # set empty pixels (no Visium spot) to &#34;none&#34;
        adata.uns[&#34;pixel_map_df&#34;].loc[
            adata.uns[&#34;pixel_map_df&#34;][filter_label] == 0,
            &#34;barcode&#34;,
        ] = &#34;none&#34;
        # subset the entire anndata object using filter_label
        adata = adata[adata.obs[filter_label] == 1, :].copy()
        print(&#34;New size: {} spots x {} genes&#34;.format(adata.n_obs, adata.n_vars))

    print(&#34;Done!&#34;)
    return adata</code></pre>
</details>
</dd>
<dt id="MILWRM.show_pita"><code class="name flex">
<span>def <span class="ident">show_pita</span></span>(<span>pita, features=None, RGB=False, histo=None, label='feature', ncols=4, figsize=(7, 7), save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot assembled pita using <code>plt.imshow()</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pita</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Image of desired expression in pixel space from <code>.<a title="MILWRM.assemble_pita" href="#MILWRM.assemble_pita">assemble_pita()</a></code></dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of features by index to show in plot. If <code>None</code>, use all features.</dd>
<dt><strong><code>RGB</code></strong> :&ensp;<code>bool</code>, optional <code>(default=</code>False<code>)</code></dt>
<dd>Treat 3-dimensional array as RGB image</dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>np.array</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>Histology image to show along with pita in gridspec. If <code>None</code>, ignore.</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code></dt>
<dd>What to title each panel of the gridspec (i.e. "PC" or "usage") or each
channel in RGB image. Can also pass list of names e.g. ["NeuN","GFAP",
"DAPI"] corresponding to channels.</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of columns for gridspec</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code></dt>
<dd>Size in inches of output figure</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. if <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object (if plotting one feature</code> or <code>RGB)</code> or <code>gridspec object (for</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>multiple features). Saves plot to file if <code>save_to</code> is not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_pita(
    pita,
    features=None,
    RGB=False,
    histo=None,
    label=&#34;feature&#34;,
    ncols=4,
    figsize=(7, 7),
    save_to=None,
    **kwargs,
):
    &#34;&#34;&#34;
    Plot assembled pita using `plt.imshow()`

    Parameters
    ----------
    pita : np.array
        Image of desired expression in pixel space from `.assemble_pita()`
    features : list of int, optional (default=`None`)
        List of features by index to show in plot. If `None`, use all features.
    RGB : bool, optional (default=`False`)
        Treat 3-dimensional array as RGB image
    histo : np.array or `None`, optional (default=`None`)
        Histology image to show along with pita in gridspec. If `None`, ignore.
    label : str
        What to title each panel of the gridspec (i.e. &#34;PC&#34; or &#34;usage&#34;) or each
        channel in RGB image. Can also pass list of names e.g. [&#34;NeuN&#34;,&#34;GFAP&#34;,
        &#34;DAPI&#34;] corresponding to channels.
    ncols : int
        Number of columns for gridspec
    figsize : tuple of float
        Size in inches of output figure
    save_to : str or None
        Path to image file to save results. if `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function

    Returns
    -------
    Matplotlib object (if plotting one feature or RGB) or gridspec object (for
    multiple features). Saves plot to file if `save_to` is not `None`.
    &#34;&#34;&#34;
    assert pita.ndim &gt; 1, &#34;Pita does not have enough dimensions: {} given&#34;.format(
        pita.ndim
    )
    assert pita.ndim &lt; 4, &#34;Pita has too many dimensions: {} given&#34;.format(pita.ndim)
    # if only one feature (2D), plot it quickly
    if (pita.ndim == 2) and histo is None:
        fig = plt.figure(figsize=figsize)
        plt.imshow(pita, **kwargs)
        plt.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        plt.colorbar(shrink=0.8)
        plt.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800)
        return fig
    if (pita.ndim == 2) and histo is not None:
        n_rows, n_cols = 1, 2  # two images here, histo and RGB
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        ax = plt.subplot(gs[0])
        im = ax.imshow(histo, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=&#34;Histology&#34;,
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        ax = plt.subplot(gs[1])
        im = ax.imshow(pita, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        cbar = plt.colorbar(im, shrink=0.8)
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800)
        return fig
    if RGB:
        # if third dim has 3 features, treat as RGB and plot it quickly
        assert (pita.ndim == 3) &amp; (
            pita.shape[2] == 3
        ), &#34;Need 3 dimensions and 3 given features for an RGB image; shape = {}; features given = {}&#34;.format(
            pita.shape, len(features)
        )
        print(&#34;Plotting pita as RGB image&#34;)
        if isinstance(label, str):
            # if label is single string, name channels numerically
            channels = [&#34;{}_{}&#34;.format(label, x) for x in range(pita.shape[2])]
        else:
            assert (
                len(label) == 3
            ), &#34;Please pass 3 channel names for RGB plot; {} labels given: {}&#34;.format(
                len(label), label
            )
            channels = label
        if histo is not None:
            n_rows, n_cols = 1, 2  # two images here, histo and RGB
            fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
            # arrange axes as subplots
            gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
            # add plots to axes
            ax = plt.subplot(gs[0])
            im = ax.imshow(histo, **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=&#34;Histology&#34;,
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            ax = plt.subplot(gs[1])
            im = ax.imshow(pita, **kwargs)
            # add legend for channel IDs
            custom_lines = [
                Line2D([0], [0], color=(1, 0, 0), lw=5),
                Line2D([0], [0], color=(0, 1, 0), lw=5),
                Line2D([0], [0], color=(0, 0, 1), lw=5),
            ]
            plt.legend(custom_lines, channels, fontsize=&#34;medium&#34;)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            fig.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
        else:
            fig = plt.figure(figsize=figsize)
            plt.imshow(pita, **kwargs)
            # add legend for channel IDs
            custom_lines = [
                Line2D([0], [0], color=(1, 0, 0), lw=5),
                Line2D([0], [0], color=(0, 1, 0), lw=5),
                Line2D([0], [0], color=(0, 0, 1), lw=5),
            ]
            plt.legend(custom_lines, channels, fontsize=&#34;medium&#34;)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
    # if pita has multiple features, plot them in gridspec
    if isinstance(features, int):  # force features into list if single integer
        features = [features]
    # if no features are given, use all of them
    if features is None:
        features = [x + 1 for x in range(pita.shape[2])]
    else:
        assert (
            pita.ndim &gt; 2
        ), &#34;Not enough features in pita: shape {}, expecting 3rd dim with length {}&#34;.format(
            pita.shape, len(features)
        )
        assert (
            len(features) &lt;= pita.shape[2]
        ), &#34;Too many features given: pita has {}, expected {}&#34;.format(
            pita.shape[2], len(features)
        )
    if isinstance(label, str):
        # if label is single string, name channels numerically
        labels = [&#34;{}_{}&#34;.format(label, x) for x in features]
    else:
        assert len(label) == len(
            features
        ), &#34;Please provide the same number of labels as features; {} labels given, {} features given.&#34;.format(
            len(label), len(features)
        )
        labels = label
    # calculate gridspec dimensions
    if histo is not None:
        labels = [&#34;Histology&#34;] + labels  # append histo to front of labels
        if len(features) + 1 &lt;= ncols:
            n_rows, n_cols = 1, len(features) + 1
        else:
            n_rows, n_cols = ceil((len(features) + 1) / ncols), ncols
    else:
        if len(features) &lt;= ncols:
            n_rows, n_cols = 1, len(features)
        else:
            n_rows, n_cols = ceil(len(features) / ncols), ncols
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # add plots to axes
    i = 0
    if histo is not None:
        # add histology plot to first axes
        ax = plt.subplot(gs[i])
        im = ax.imshow(histo, **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        i = i + 1
    for feature in features:
        ax = plt.subplot(gs[i])
        im = ax.imshow(pita[:, :, feature - 1], **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=labels[i],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        cbar = plt.colorbar(im, shrink=0.8)
        i = i + 1
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.trim_image"><code class="name flex">
<span>def <span class="ident">trim_image</span></span>(<span>adata, distance_trim=False, threshold=None, channels=None, plot_out=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Trim pixels in image using pixel map output from Visium barcodes</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adata</code></strong> :&ensp;<code>AnnData.anndata</code></dt>
<dd>The data</dd>
<dt><strong><code>distance_trim</code></strong> :&ensp;<code>bool</code></dt>
<dd>Manually trim pixels by distance to nearest Visium spot center</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>Number of pixels from nearest Visium spot center to call barcode ID. Ignored
if <code>distance_trim==False</code>.</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>None</code></dt>
<dd>Names of image channels in axis order. If None, channels are named "ch_0",
"ch_1", etc.</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>bool</code></dt>
<dd>Plot final trimmed image</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code><a title="MILWRM.show_pita" href="#MILWRM.show_pita">show_pita()</a></code> function if <code>plot_out==True</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>adata.uns["pixel_map_trim"] : np.array</code></dt>
<dd>Contains image with unused pixels set to <code>np.nan</code></dd>
<dt><code>adata.obsm["spatial_trim"] : np.array</code></dt>
<dd>Contains spatial coords with adjusted pixel values after image cropping</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_image(
    adata, distance_trim=False, threshold=None, channels=None, plot_out=True, **kwargs
):
    &#34;&#34;&#34;
    Trim pixels in image using pixel map output from Visium barcodes

    Parameters
    ----------
    adata : AnnData.anndata
        The data
    distance_trim : bool
        Manually trim pixels by distance to nearest Visium spot center
    threshold : int or None
        Number of pixels from nearest Visium spot center to call barcode ID. Ignored
        if `distance_trim==False`.
    channels : list of str or None
        Names of image channels in axis order. If None, channels are named &#34;ch_0&#34;,
        &#34;ch_1&#34;, etc.
    plot_out : bool
        Plot final trimmed image
    **kwargs
        Arguments to pass to `show_pita()` function if `plot_out==True`

    Returns
    -------
    adata.uns[&#34;pixel_map_trim&#34;] : np.array
        Contains image with unused pixels set to `np.nan`
    adata.obsm[&#34;spatial_trim&#34;] : np.array
        Contains spatial coords with adjusted pixel values after image cropping
    &#34;&#34;&#34;
    assert (
        adata.uns[&#34;pixel_map_params&#34;] is not None
    ), &#34;Pixel map not yet created. Run map_pixels() first.&#34;

    print(
        &#34;Cropping image to pixel dimensions and adding values to adata.uns[&#39;pixel_map_df&#39;]&#34;
    )
    cropped = adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][
        &#34;images&#34;
    ][adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;]].transpose(1, 0, 2)[
        int(adata.uns[&#34;pixel_map_params&#34;][&#34;xmin_px&#34;]) : int(
            (adata.uns[&#34;pixel_map_params&#34;][&#34;xmax_px&#34;])
        ),
        int(adata.uns[&#34;pixel_map_params&#34;][&#34;ymin_px&#34;]) : int(
            (adata.uns[&#34;pixel_map_params&#34;][&#34;ymax_px&#34;])
        ),
    ]
    # crop x,y coords and save to .obsm as well
    print(&#34;Cropping Visium spot coordinates and saving to adata.obsm[&#39;spatial_trim&#39;]&#34;)
    adata.obsm[&#34;spatial_trim&#34;] = adata.obsm[&#34;spatial&#34;] - np.repeat(
        [
            [
                adata.uns[&#34;pixel_map_params&#34;][&#34;xmin_px&#34;],
                adata.uns[&#34;pixel_map_params&#34;][&#34;ymin_px&#34;],
            ]
        ],
        adata.obsm[&#34;spatial&#34;].shape[0],
        axis=0,
    )

    # manual trimming of pixels by distance if desired
    if distance_trim:
        print(&#34;Calculating pixel distances from spot centers for thresholding&#34;)
        tree = cKDTree(adata.obsm[&#34;spatial&#34;])
        xi = interpnd._ndim_coords_from_arrays(
            (adata.uns[&#34;grid_x&#34;], adata.uns[&#34;grid_y&#34;]),
            ndim=adata.obsm[&#34;spatial&#34;].shape[1],
        )
        dists, _ = tree.query(xi)

        # determine distance threshold
        if threshold is None:
            threshold = int(adata.uns[&#34;pixel_map_params&#34;][&#34;ctr_to_vert&#34;] + 1)
            print(
                &#34;Using distance threshold of {} pixels from adata.uns[&#39;pixel_map_params&#39;][&#39;ctr_to_vert&#39;]&#34;.format(
                    threshold
                )
            )

        dist_mask = bin_threshold(dists, threshmax=threshold)
        if plot_out:
            # plot pixel distances from spot centers on image
            show_pita(pita=dists, figsize=(4, 4))
            # plot binary thresholded image
            show_pita(pita=dist_mask, figsize=(4, 4))

        print(
            &#34;Trimming pixels by spot distance and adjusting labels in adata.uns[&#39;pixel_map_df&#39;]&#34;
        )
        mask_df = pd.DataFrame(dist_mask.T.ravel(order=&#34;F&#34;), columns=[&#34;manual_trim&#34;])
        adata.uns[&#34;pixel_map_df&#34;] = adata.uns[&#34;pixel_map_df&#34;].merge(
            mask_df, left_index=True, right_index=True
        )
        adata.uns[&#34;pixel_map_df&#34;].loc[
            adata.uns[&#34;pixel_map_df&#34;][&#34;manual_trim&#34;] == 1, [&#34;barcode&#34;]
        ] = &#34;none&#34;  # set empty pixels to empty barcode
        adata.uns[&#34;pixel_map_df&#34;].drop(
            columns=&#34;manual_trim&#34;, inplace=True
        )  # remove unneeded label

    if channels is None:
        # if channel names not specified, name them numerically
        channels = [&#34;ch_{}&#34;.format(x) for x in range(cropped.shape[2])]
    # cast image intensity values to long-form and add to adata.uns[&#34;pixel_map_df&#34;]
    rgb = pd.DataFrame(
        np.column_stack(
            [cropped[:, :, x].ravel(order=&#34;F&#34;) for x in range(cropped.shape[2])]
        ),
        columns=channels,
    )
    adata.uns[&#34;pixel_map_df&#34;] = adata.uns[&#34;pixel_map_df&#34;].merge(
        rgb, left_index=True, right_index=True
    )
    adata.uns[&#34;pixel_map_df&#34;].loc[
        adata.uns[&#34;pixel_map_df&#34;][&#34;barcode&#34;] == &#34;none&#34;, channels
    ] = np.nan  # set empty pixels to invalid image intensity value

    # calculate mean image values for each channel and create .obsm key
    adata.obsm[&#34;image_means&#34;] = (
        adata.uns[&#34;pixel_map_df&#34;]
        .loc[adata.uns[&#34;pixel_map_df&#34;][&#34;barcode&#34;] != &#34;none&#34;, [&#34;barcode&#34;] + channels]
        .groupby(&#34;barcode&#34;)
        .mean()
        .values
    )

    print(
        &#34;Saving cropped and trimmed image to adata.uns[&#39;spatial&#39;][&#39;{}&#39;][&#39;images&#39;][&#39;{}_trim&#39;]&#34;.format(
            adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;],
            adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;],
        )
    )
    adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][&#34;images&#34;][
        &#34;{}_trim&#34;.format(adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;])
    ] = np.dstack(
        [
            adata.uns[&#34;pixel_map_df&#34;]
            .pivot(index=&#34;y&#34;, columns=&#34;x&#34;, values=[channels[x]])
            .values
            for x in range(len(channels))
        ]
    )
    # save scale factor as well
    adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][&#34;scalefactors&#34;][
        &#34;tissue_{}_trim_scalef&#34;.format(adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;])
    ] = adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][
        &#34;scalefactors&#34;
    ][
        &#34;tissue_{}_scalef&#34;.format(adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;])
    ]
    # plot results if desired
    if plot_out:
        if len(channels) == 3:
            show_pita(
                pita=adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][
                    &#34;images&#34;
                ][&#34;{}_trim&#34;.format(adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;])],
                RGB=True,
                label=channels,
                **kwargs,
            )
        else:
            show_pita(
                pita=adata.uns[&#34;spatial&#34;][adata.uns[&#34;pixel_map_params&#34;][&#34;library_id&#34;]][
                    &#34;images&#34;
                ][&#34;{}_trim&#34;.format(adata.uns[&#34;pixel_map_params&#34;][&#34;img_key&#34;])],
                RGB=False,
                label=channels,
                **kwargs,
            )
    print(&#34;Done!&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="MILWRM.img"><code class="flex name class">
<span>class <span class="ident">img</span></span>
<span>(</span><span>img_arr, channels=None, mask=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>img_arr</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image as a numpy array</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>str</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channel names corresponding to img.shape[2]. i.e. <code>("DAPI","GFAP",
"NeuH")&lt;code&gt;. If &lt;/code&gt;None</code>, channels are named "ch_0", "ch_1", etc.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Mask defining pixels containing tissue in the image</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.img" href="#MILWRM.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class img:
    def __init__(self, img_arr, channels=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class

        Parameters
        ----------
        img_arr : np.ndarray
            The image as a numpy array
        channels : tuple of str or None, optional (default=`None`)
            List of channel names corresponding to img.shape[2]. i.e. `(&#34;DAPI&#34;,&#34;GFAP&#34;,
            &#34;NeuH&#34;)`. If `None`, channels are named &#34;ch_0&#34;, &#34;ch_1&#34;, etc.
        mask : np.ndarray
            Mask defining pixels containing tissue in the image

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        assert (
            img_arr.ndim &gt; 1
        ), &#34;Image does not have enough dimensions: {} given&#34;.format(img_arr.ndim)
        self.img = img_arr  # save image array to .img attribute
        if img_arr.ndim &gt; 2:
            self.n_ch = img_arr.shape[2]  # save number of channels to attribute
        else:
            self.n_ch = 1
        if channels is None:
            # if channel names not specified, name them numerically
            self.ch = [&#34;ch_{}&#34;.format(x) for x in range(self.n_ch)]
        else:
            assert (
                len(channels) == self.n_ch
            ), &#34;Number of channels must match img_arr.shape[2]&#34;
            self.ch = channels
        if mask is not None:
            # validate that mask matches img_arr
            assert (
                mask.shape == img_arr.shape[:2]
            ), &#34;Shape of mask must match the first two dimensions of img_arr&#34;
        self.mask = mask  # set mask attribute, regardless of value given

    @classmethod
    def from_tiffs(cls, tiffdir, channels, common_strings=None, mask=None):
        &#34;&#34;&#34;
        Initialize img class from `.tif` files

        Parameters
        ----------
        tiffdir : str
            Path to directory containing `.tif` files for a multiplexed image
        channels : tuple of str
            List of channels present in `.tif` file names (case-sensitive)
            corresponding to img.shape[2] e.g. `(&#34;ACTG1&#34;,&#34;BCATENIN&#34;,&#34;DAPI&#34;,...)`
        common_strings : str, list of str, or `None`, optional (default=None)
            Strings to look for in all `.tif` files in `tiffdir` corresponding to
            `channels` e.g. `(&#34;WD86055_&#34;, &#34;_region_001.tif&#34;)` for files named
            &#34;WD86055_[MARKERNAME]_region_001.tif&#34;. If `None`, assume that only 1 image
            for each marker in `channels` is present in `tiffdir`.
        mask : str, optional (default=None)
            Name of mask defining pixels containing tissue in the image, present in
            `.tif` file names (case-sensitive) e.g. &#34;_01_TISSUE_MASK.tif&#34;

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        if common_strings is not None:
            # coerce single string to list
            if isinstance(common_strings, str):
                common_strings = [common_strings]
        A = []  # list for dumping numpy arrays
        for channel in channels:
            if common_strings is None:
                # find file matching all common_strings and channel name
                f = [f for f in os.listdir(tiffdir) if channel in f]
            else:
                # find file matching all common_strings and channel name
                f = [
                    f
                    for f in os.listdir(tiffdir)
                    if all(x in f for x in common_strings + [channel])
                ]
            # assertions so we only get one file per channel
            assert len(f) != 0, &#34;No file found with channel {}&#34;.format(channel)
            assert (
                len(f) == 1
            ), &#34;More than one match found for file with channel {}&#34;.format(channel)
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading marker {} from {}&#34;.format(channel, f))
            tmp = imread(f)  # read in .tif file
            A.append(tmp)  # append numpy array to list
        A_arr = np.dstack(
            A
        )  # stack numpy arrays in new dimension (third dim is channel)
        print(&#34;Final image array of shape: {}&#34;.format(A_arr.shape))
        # read in tissue mask if available
        if mask is not None:
            f = [f for f in os.listdir(tiffdir) if mask in f]
            # assertions so we only get one mask file
            assert len(f) != 0, &#34;No tissue mask file found&#34;
            assert len(f) == 1, &#34;More than one match found for tissue mask file&#34;
            f = os.path.join(tiffdir, f[0])  # get full path to file for reading
            print(&#34;Reading tissue mask from {}&#34;.format(f))
            A_mask = imread(f)  # read in .tif file
            assert (
                A_mask.shape == A_arr.shape[:2]
            ), &#34;Mask (shape: {}) is not the same shape as marker images (shape: {})&#34;.format(
                A_mask.shape, A_arr.shape[:2]
            )
            print(&#34;Final mask array of shape: {}&#34;.format(A_mask.shape))
        else:
            A_mask = None
        # generate img object
        return cls(img_arr=A_arr, channels=channels, mask=A_mask)

    @classmethod
    def from_npz(cls, file):
        &#34;&#34;&#34;
        Initialize img class from `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file containing saved img object and metadata

        Returns
        -------
        `img` object
        &#34;&#34;&#34;
        print(&#34;Loading img object from {}...&#34;.format(file))
        tmp = np.load(file)  # load from .npz compressed file
        assert (
            &#34;img&#34; in tmp.files
        ), &#34;Unexpected files in .npz: {}, expected [&#39;img&#39;,&#39;mask&#39;,&#39;ch&#39;].&#34;.format(
            tmp.files
        )
        A_mask = tmp[&#34;mask&#34;] if &#34;mask&#34; in tmp.files else None
        A_ch = list(tmp[&#34;ch&#34;]) if &#34;ch&#34; in tmp.files else None
        # generate img object
        return cls(img_arr=tmp[&#34;img&#34;], channels=A_ch, mask=A_mask)

    def to_npz(self, file):
        &#34;&#34;&#34;
        Save img object to compressed `.npz` file

        Parameters
        ----------
        file : str
            Path to `.npz` file in which to save img object and metadata

        Returns
        -------
        Writes object to `file`
        &#34;&#34;&#34;
        print(&#34;Saving img object to {}...&#34;.format(file))
        if self.mask is None:
            np.savez_compressed(file, img=self.img, ch=self.ch)
        else:
            np.savez_compressed(file, img=self.img, ch=self.ch, mask=self.mask)

    def clip(self, **kwargs):
        &#34;&#34;&#34;
        Clips outlier values

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `clip_values()` function

        Returns
        -------
        Clips outlier values from `self.img`
        &#34;&#34;&#34;
        self.img = clip_values(self.img, **kwargs)

    def scale(self, **kwargs):
        &#34;&#34;&#34;
        Scales intensities to [0.0, 1.0]

        Parameters
        ----------
        **kwargs
            Keyword args to pass to `scale_rgb()` function

        Returns
        -------
        Scales intensities of `self.img`
        &#34;&#34;&#34;
        self.img = scale_rgb(self.img, **kwargs)

    def log_normalize(self, pseudoval=1, mask=True):
        &#34;&#34;&#34;
        Log-normalizes values for each marker with `log10(arr/arr.mean() + pseudoval)`

        Parameters
        ----------
        pseudoval : float
            Value to add to image values prior to log-transforming to avoid issues
            with zeros
        mask : bool, optional (default=True)
            Use tissue mask to determine marker mean factor for normalization. Default
            `True`.

        Returns
        -------
        Log-normalizes values in each channel of `self.img`
        &#34;&#34;&#34;
        if mask:
            assert self.mask is not None, &#34;No tissue mask available&#34;
            for i in range(self.img.shape[2]):
                fact = self.img[:, :, i][self.mask != 0].mean()
                self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)

    def downsample(self, fact, func=np.mean):
        &#34;&#34;&#34;
        Downsamples image by applying `func` to `fact` pixels in both directions from
        each pixel

        Parameters
        ----------
        fact : int
            Number of pixels in each direction (x &amp; y) to downsample with
        func : function
            Numpy function to apply to squares of size (fact, fact, :) for downsampling
            (e.g. `np.mean`, `np.max`, `np.sum`)

        Returns
        -------
        self.img and self.mask are downsampled accordingly in place
        &#34;&#34;&#34;
        # downsample mask if mask available
        if self.mask is not None:
            self.mask = block_reduce(
                self.mask, block_size=(fact, fact), func=np.max, cval=0
            )
        # downsample image
        self.img = block_reduce(self.img, block_size=(fact, fact, 1), func=func, cval=0)

    def show(
        self,
        channels=None,
        RGB=False,
        cbar=False,
        ncols=4,
        figsize=(7, 7),
        save_to=None,
        **kwargs,
    ):
        &#34;&#34;&#34;
        Plot image

        Parameters
        ----------
        channels : tuple of int or None, optional (default=`None`)
            List of channels by index or name to show
        RGB : bool
            Treat 3- or 4-dimensional array as RGB image. If `False`, plot channels
            individually.
        cbar : bool
            Show colorbar for scale of image intensities if plotting individual
            channels.
        ncols : int
            Number of columns for gridspec if plotting individual channels.
        figsize : tuple of float
            Size in inches of output figure.
        save_to : str or None
            Path to image file to save results. If `None`, show figure.
        **kwargs
            Arguments to pass to `plt.imshow()` function.

        Returns
        -------
        Matplotlib object (if plotting one feature or RGB) or gridspec object (for
        multiple features). Saves plot to file if `save_to` is not `None`.
        &#34;&#34;&#34;
        # if only one feature (2D), plot it quickly
        if self.img.ndim == 2:
            fig = plt.figure(figsize=figsize)
            plt.imshow(self.img, **kwargs)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            if cbar:
                plt.colorbar(shrink=0.8)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
        # if image has multiple channels, plot them in gridspec
        if isinstance(channels, int):  # force channels into list if single integer
            channels = [channels]
        if isinstance(channels, str):  # force channels into int if single string
            channels = [self.ch.index(channels)]
        if checktype(channels):  # force channels into list of int if list of strings
            channels = [self.ch.index(x) for x in channels]
        if channels is None:  # if no channels are given, use all of them
            channels = [x for x in range(self.n_ch)]
        assert (
            len(channels) &lt;= self.n_ch
        ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
            self.n_ch, len(channels)
        )
        if RGB:
            # if third dim has 3 or 4 features, treat as RGB and plot it quickly
            assert (self.img.ndim == 3) &amp; (
                len(channels) == 3
            ), &#34;Need 3 dimensions and 3 given channels for an RGB image; shape = {}; channels given = {}&#34;.format(
                self.img.shape, len(channels)
            )
            fig = plt.figure(figsize=figsize)
            # rearrange channels to specified order
            im_tmp = np.dstack(
                [
                    self.img[:, :, channels[0]],
                    self.img[:, :, channels[1]],
                    self.img[:, :, channels[2]],
                ]
            )
            plt.imshow(im_tmp, **kwargs)
            # add legend for channel IDs
            custom_lines = [
                Line2D([0], [0], color=(1, 0, 0), lw=5),
                Line2D([0], [0], color=(0, 1, 0), lw=5),
                Line2D([0], [0], color=(0, 0, 1), lw=5),
            ]
            plt.legend(custom_lines, [self.ch[x] for x in channels], fontsize=&#34;medium&#34;)
            plt.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            plt.tight_layout()
            if save_to:
                plt.savefig(
                    fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
                )
            return fig
        # calculate gridspec dimensions
        if len(channels) &lt;= ncols:
            n_rows, n_cols = 1, len(channels)
        else:
            n_rows, n_cols = ceil(len(channels) / ncols), ncols
        fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
        # arrange axes as subplots
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        # add plots to axes
        i = 0
        for channel in channels:
            ax = plt.subplot(gs[i])
            im = ax.imshow(self.img[:, :, channel], **kwargs)
            ax.tick_params(labelbottom=False, labelleft=False)
            sns.despine(bottom=True, left=True)
            ax.set_title(
                label=self.ch[channel],
                loc=&#34;left&#34;,
                fontweight=&#34;bold&#34;,
                fontsize=16,
            )
            if cbar:
                _ = plt.colorbar(im, shrink=0.8)
            i = i + 1
        fig.tight_layout()
        if save_to:
            plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800)
        return fig</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="MILWRM.img.from_npz"><code class="name flex">
<span>def <span class="ident">from_npz</span></span>(<span>file)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class from <code>.npz</code> file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to <code>.npz</code> file containing saved img object and metadata</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.img" href="#MILWRM.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_npz(cls, file):
    &#34;&#34;&#34;
    Initialize img class from `.npz` file

    Parameters
    ----------
    file : str
        Path to `.npz` file containing saved img object and metadata

    Returns
    -------
    `img` object
    &#34;&#34;&#34;
    print(&#34;Loading img object from {}...&#34;.format(file))
    tmp = np.load(file)  # load from .npz compressed file
    assert (
        &#34;img&#34; in tmp.files
    ), &#34;Unexpected files in .npz: {}, expected [&#39;img&#39;,&#39;mask&#39;,&#39;ch&#39;].&#34;.format(
        tmp.files
    )
    A_mask = tmp[&#34;mask&#34;] if &#34;mask&#34; in tmp.files else None
    A_ch = list(tmp[&#34;ch&#34;]) if &#34;ch&#34; in tmp.files else None
    # generate img object
    return cls(img_arr=tmp[&#34;img&#34;], channels=A_ch, mask=A_mask)</code></pre>
</details>
</dd>
<dt id="MILWRM.img.from_tiffs"><code class="name flex">
<span>def <span class="ident">from_tiffs</span></span>(<span>tiffdir, channels, common_strings=None, mask=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize img class from <code>.tif</code> files</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tiffdir</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to directory containing <code>.tif</code> files for a multiplexed image</dd>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>str</code></dt>
<dd>List of channels present in <code>.tif</code> file names (case-sensitive)
corresponding to img.shape[2] e.g. <code>("ACTG1","BCATENIN","DAPI",...)</code></dd>
<dt><strong><code>common_strings</code></strong> :&ensp;<code>str, list</code> of <code>str,</code> or <code>None</code>, optional <code>(default=None)</code></dt>
<dd>Strings to look for in all <code>.tif</code> files in <code>tiffdir</code> corresponding to
<code>channels</code> e.g. <code>("WD86055_", "_region_001.tif")</code> for files named
"WD86055_[MARKERNAME]_region_001.tif". If <code>None</code>, assume that only 1 image
for each marker in <code>channels</code> is present in <code>tiffdir</code>.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>str</code>, optional <code>(default=None)</code></dt>
<dd>Name of mask defining pixels containing tissue in the image, present in
<code>.tif</code> file names (case-sensitive) e.g. "_01_TISSUE_MASK.tif"</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="MILWRM.img" href="#MILWRM.img">img</a></code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_tiffs(cls, tiffdir, channels, common_strings=None, mask=None):
    &#34;&#34;&#34;
    Initialize img class from `.tif` files

    Parameters
    ----------
    tiffdir : str
        Path to directory containing `.tif` files for a multiplexed image
    channels : tuple of str
        List of channels present in `.tif` file names (case-sensitive)
        corresponding to img.shape[2] e.g. `(&#34;ACTG1&#34;,&#34;BCATENIN&#34;,&#34;DAPI&#34;,...)`
    common_strings : str, list of str, or `None`, optional (default=None)
        Strings to look for in all `.tif` files in `tiffdir` corresponding to
        `channels` e.g. `(&#34;WD86055_&#34;, &#34;_region_001.tif&#34;)` for files named
        &#34;WD86055_[MARKERNAME]_region_001.tif&#34;. If `None`, assume that only 1 image
        for each marker in `channels` is present in `tiffdir`.
    mask : str, optional (default=None)
        Name of mask defining pixels containing tissue in the image, present in
        `.tif` file names (case-sensitive) e.g. &#34;_01_TISSUE_MASK.tif&#34;

    Returns
    -------
    `img` object
    &#34;&#34;&#34;
    if common_strings is not None:
        # coerce single string to list
        if isinstance(common_strings, str):
            common_strings = [common_strings]
    A = []  # list for dumping numpy arrays
    for channel in channels:
        if common_strings is None:
            # find file matching all common_strings and channel name
            f = [f for f in os.listdir(tiffdir) if channel in f]
        else:
            # find file matching all common_strings and channel name
            f = [
                f
                for f in os.listdir(tiffdir)
                if all(x in f for x in common_strings + [channel])
            ]
        # assertions so we only get one file per channel
        assert len(f) != 0, &#34;No file found with channel {}&#34;.format(channel)
        assert (
            len(f) == 1
        ), &#34;More than one match found for file with channel {}&#34;.format(channel)
        f = os.path.join(tiffdir, f[0])  # get full path to file for reading
        print(&#34;Reading marker {} from {}&#34;.format(channel, f))
        tmp = imread(f)  # read in .tif file
        A.append(tmp)  # append numpy array to list
    A_arr = np.dstack(
        A
    )  # stack numpy arrays in new dimension (third dim is channel)
    print(&#34;Final image array of shape: {}&#34;.format(A_arr.shape))
    # read in tissue mask if available
    if mask is not None:
        f = [f for f in os.listdir(tiffdir) if mask in f]
        # assertions so we only get one mask file
        assert len(f) != 0, &#34;No tissue mask file found&#34;
        assert len(f) == 1, &#34;More than one match found for tissue mask file&#34;
        f = os.path.join(tiffdir, f[0])  # get full path to file for reading
        print(&#34;Reading tissue mask from {}&#34;.format(f))
        A_mask = imread(f)  # read in .tif file
        assert (
            A_mask.shape == A_arr.shape[:2]
        ), &#34;Mask (shape: {}) is not the same shape as marker images (shape: {})&#34;.format(
            A_mask.shape, A_arr.shape[:2]
        )
        print(&#34;Final mask array of shape: {}&#34;.format(A_mask.shape))
    else:
        A_mask = None
    # generate img object
    return cls(img_arr=A_arr, channels=channels, mask=A_mask)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.img.clip"><code class="name flex">
<span>def <span class="ident">clip</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Clips outlier values</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword args to pass to <code>clip_values()</code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Clips outlier values from <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clip(self, **kwargs):
    &#34;&#34;&#34;
    Clips outlier values

    Parameters
    ----------
    **kwargs
        Keyword args to pass to `clip_values()` function

    Returns
    -------
    Clips outlier values from `self.img`
    &#34;&#34;&#34;
    self.img = clip_values(self.img, **kwargs)</code></pre>
</details>
</dd>
<dt id="MILWRM.img.downsample"><code class="name flex">
<span>def <span class="ident">downsample</span></span>(<span>self, fact, func=&lt;function mean&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Downsamples image by applying <code>func</code> to <code>fact</code> pixels in both directions from
each pixel</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fact</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of pixels in each direction (x &amp; y) to downsample with</dd>
<dt><strong><code>func</code></strong> :&ensp;<code>function</code></dt>
<dd>Numpy function to apply to squares of size (fact, fact, :) for downsampling
(e.g. <code>np.mean</code>, <code>np.max</code>, <code>np.sum</code>)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self.img and self.mask are downsampled accordingly in place</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def downsample(self, fact, func=np.mean):
    &#34;&#34;&#34;
    Downsamples image by applying `func` to `fact` pixels in both directions from
    each pixel

    Parameters
    ----------
    fact : int
        Number of pixels in each direction (x &amp; y) to downsample with
    func : function
        Numpy function to apply to squares of size (fact, fact, :) for downsampling
        (e.g. `np.mean`, `np.max`, `np.sum`)

    Returns
    -------
    self.img and self.mask are downsampled accordingly in place
    &#34;&#34;&#34;
    # downsample mask if mask available
    if self.mask is not None:
        self.mask = block_reduce(
            self.mask, block_size=(fact, fact), func=np.max, cval=0
        )
    # downsample image
    self.img = block_reduce(self.img, block_size=(fact, fact, 1), func=func, cval=0)</code></pre>
</details>
</dd>
<dt id="MILWRM.img.log_normalize"><code class="name flex">
<span>def <span class="ident">log_normalize</span></span>(<span>self, pseudoval=1, mask=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Log-normalizes values for each marker with <code>log10(arr/arr.mean() + pseudoval)</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pseudoval</code></strong> :&ensp;<code>float</code></dt>
<dd>Value to add to image values prior to log-transforming to avoid issues
with zeros</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>bool</code>, optional <code>(default=True)</code></dt>
<dd>Use tissue mask to determine marker mean factor for normalization. Default
<code>True</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Log-normalizes values in each channel of <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_normalize(self, pseudoval=1, mask=True):
    &#34;&#34;&#34;
    Log-normalizes values for each marker with `log10(arr/arr.mean() + pseudoval)`

    Parameters
    ----------
    pseudoval : float
        Value to add to image values prior to log-transforming to avoid issues
        with zeros
    mask : bool, optional (default=True)
        Use tissue mask to determine marker mean factor for normalization. Default
        `True`.

    Returns
    -------
    Log-normalizes values in each channel of `self.img`
    &#34;&#34;&#34;
    if mask:
        assert self.mask is not None, &#34;No tissue mask available&#34;
        for i in range(self.img.shape[2]):
            fact = self.img[:, :, i][self.mask != 0].mean()
            self.img[:, :, i] = np.log10(self.img[:, :, i] / fact + pseudoval)</code></pre>
</details>
</dd>
<dt id="MILWRM.img.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Scales intensities to [0.0, 1.0]</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword args to pass to <code>scale_rgb()</code> function</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Scales intensities of <code>self.img</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, **kwargs):
    &#34;&#34;&#34;
    Scales intensities to [0.0, 1.0]

    Parameters
    ----------
    **kwargs
        Keyword args to pass to `scale_rgb()` function

    Returns
    -------
    Scales intensities of `self.img`
    &#34;&#34;&#34;
    self.img = scale_rgb(self.img, **kwargs)</code></pre>
</details>
</dd>
<dt id="MILWRM.img.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self, channels=None, RGB=False, cbar=False, ncols=4, figsize=(7, 7), save_to=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>channels</code></strong> :&ensp;<code>tuple</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of channels by index or name to show</dd>
<dt><strong><code>RGB</code></strong> :&ensp;<code>bool</code></dt>
<dd>Treat 3- or 4-dimensional array as RGB image. If <code>False</code>, plot channels
individually.</dd>
<dt><strong><code>cbar</code></strong> :&ensp;<code>bool</code></dt>
<dd>Show colorbar for scale of image intensities if plotting individual
channels.</dd>
<dt><strong><code>ncols</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of columns for gridspec if plotting individual channels.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code> of <code>float</code></dt>
<dd>Size in inches of output figure.</dd>
<dt><strong><code>save_to</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Path to image file to save results. If <code>None</code>, show figure.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Arguments to pass to <code>plt.imshow()</code> function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Matplotlib object (if plotting one feature</code> or <code>RGB)</code> or <code>gridspec object (for</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>multiple features). Saves plot to file if <code>save_to</code> is not <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(
    self,
    channels=None,
    RGB=False,
    cbar=False,
    ncols=4,
    figsize=(7, 7),
    save_to=None,
    **kwargs,
):
    &#34;&#34;&#34;
    Plot image

    Parameters
    ----------
    channels : tuple of int or None, optional (default=`None`)
        List of channels by index or name to show
    RGB : bool
        Treat 3- or 4-dimensional array as RGB image. If `False`, plot channels
        individually.
    cbar : bool
        Show colorbar for scale of image intensities if plotting individual
        channels.
    ncols : int
        Number of columns for gridspec if plotting individual channels.
    figsize : tuple of float
        Size in inches of output figure.
    save_to : str or None
        Path to image file to save results. If `None`, show figure.
    **kwargs
        Arguments to pass to `plt.imshow()` function.

    Returns
    -------
    Matplotlib object (if plotting one feature or RGB) or gridspec object (for
    multiple features). Saves plot to file if `save_to` is not `None`.
    &#34;&#34;&#34;
    # if only one feature (2D), plot it quickly
    if self.img.ndim == 2:
        fig = plt.figure(figsize=figsize)
        plt.imshow(self.img, **kwargs)
        plt.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        if cbar:
            plt.colorbar(shrink=0.8)
        plt.tight_layout()
        if save_to:
            plt.savefig(
                fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
            )
        return fig
    # if image has multiple channels, plot them in gridspec
    if isinstance(channels, int):  # force channels into list if single integer
        channels = [channels]
    if isinstance(channels, str):  # force channels into int if single string
        channels = [self.ch.index(channels)]
    if checktype(channels):  # force channels into list of int if list of strings
        channels = [self.ch.index(x) for x in channels]
    if channels is None:  # if no channels are given, use all of them
        channels = [x for x in range(self.n_ch)]
    assert (
        len(channels) &lt;= self.n_ch
    ), &#34;Too many channels given: image has {}, expected {}&#34;.format(
        self.n_ch, len(channels)
    )
    if RGB:
        # if third dim has 3 or 4 features, treat as RGB and plot it quickly
        assert (self.img.ndim == 3) &amp; (
            len(channels) == 3
        ), &#34;Need 3 dimensions and 3 given channels for an RGB image; shape = {}; channels given = {}&#34;.format(
            self.img.shape, len(channels)
        )
        fig = plt.figure(figsize=figsize)
        # rearrange channels to specified order
        im_tmp = np.dstack(
            [
                self.img[:, :, channels[0]],
                self.img[:, :, channels[1]],
                self.img[:, :, channels[2]],
            ]
        )
        plt.imshow(im_tmp, **kwargs)
        # add legend for channel IDs
        custom_lines = [
            Line2D([0], [0], color=(1, 0, 0), lw=5),
            Line2D([0], [0], color=(0, 1, 0), lw=5),
            Line2D([0], [0], color=(0, 0, 1), lw=5),
        ]
        plt.legend(custom_lines, [self.ch[x] for x in channels], fontsize=&#34;medium&#34;)
        plt.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        plt.tight_layout()
        if save_to:
            plt.savefig(
                fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800
            )
        return fig
    # calculate gridspec dimensions
    if len(channels) &lt;= ncols:
        n_rows, n_cols = 1, len(channels)
    else:
        n_rows, n_cols = ceil(len(channels) / ncols), ncols
    fig = plt.figure(figsize=(ncols * n_cols, ncols * n_rows))
    # arrange axes as subplots
    gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
    # add plots to axes
    i = 0
    for channel in channels:
        ax = plt.subplot(gs[i])
        im = ax.imshow(self.img[:, :, channel], **kwargs)
        ax.tick_params(labelbottom=False, labelleft=False)
        sns.despine(bottom=True, left=True)
        ax.set_title(
            label=self.ch[channel],
            loc=&#34;left&#34;,
            fontweight=&#34;bold&#34;,
            fontsize=16,
        )
        if cbar:
            _ = plt.colorbar(im, shrink=0.8)
        i = i + 1
    fig.tight_layout()
    if save_to:
        plt.savefig(fname=save_to, transparent=True, bbox_inches=&#34;tight&#34;, dpi=800)
    return fig</code></pre>
</details>
</dd>
<dt id="MILWRM.img.to_npz"><code class="name flex">
<span>def <span class="ident">to_npz</span></span>(<span>self, file)</span>
</code></dt>
<dd>
<div class="desc"><p>Save img object to compressed <code>.npz</code> file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to <code>.npz</code> file in which to save img object and metadata</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Writes object to <code>file</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_npz(self, file):
    &#34;&#34;&#34;
    Save img object to compressed `.npz` file

    Parameters
    ----------
    file : str
        Path to `.npz` file in which to save img object and metadata

    Returns
    -------
    Writes object to `file`
    &#34;&#34;&#34;
    print(&#34;Saving img object to {}...&#34;.format(file))
    if self.mask is None:
        np.savez_compressed(file, img=self.img, ch=self.ch)
    else:
        np.savez_compressed(file, img=self.img, ch=self.ch, mask=self.mask)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="MILWRM.mxif_labeler"><code class="flex name class">
<span>class <span class="ident">mxif_labeler</span></span>
<span>(</span><span>images)</span>
</code></dt>
<dd>
<div class="desc"><p>Tissue region labeling class for multiplex immunofluorescence (MxIF) data</p>
<p>Initialize MxIF tissue labeler class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>list</code> of <code><a title="MILWRM.MxIF.img" href="MxIF.html#MILWRM.MxIF.img">img</a></code></dt>
<dd>Single MILWRM.MxIF.img object or list of objects to label consensus
tissue regions</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.images</code> attribute is updated,
<code>self.cluster_data</code> attribute is initiated as <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class mxif_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue region labeling class for multiplex immunofluorescence (MxIF) data
    &#34;&#34;&#34;

    def __init__(self, images):
        &#34;&#34;&#34;
        Initialize MxIF tissue labeler class

        Parameters
        ----------
        images : list of MILWRM.MxIF.img
            Single MILWRM.MxIF.img object or list of objects to label consensus
            tissue regions

        Returns
        -------
        Does not return anything. `self.images` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        if not isinstance(images, list):  # force single image object to list
            images = [images]
        print(&#34;Initiating MxIF labeler with {} images&#34;.format(len(images)))
        self.images = images

    def prep_cluster_data(
        self, features, downsample_factor=8, sigma=2, fract=0.2, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Prepare master dataframe for tissue-level clustering

        Parameters
        ----------
        features : list of int or str
            Indices or names of MxIF channels to use for tissue labeling
        downsample_factor : int
            Factor by which to downsample images from their original resolution
        sigma : float, optional (default=2)
            Standard deviation of Gaussian kernel for blurring
        fract : float, optional (default=0.2)
            Fraction of cluster data from each image to randomly select for model
            building
        n_jobs : int, optional (default=-1)
            Number of cores to parallelize over. Default all available cores.

        Returns
        -------
        Does not return anything. `self.images` are downsampled and blurred according
        to user parameters. `self.cluster_data` becomes master `np.array` for cluster
        training. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        # save the hyperparams as object attributes
        self.model_features = features
        self.downsample_factor = downsample_factor
        self.sigma = sigma
        # downsampling, blurring, subsampling, and compiling cluster_data in parallel
        print(
            &#34;Downsampling, log-normalizing, and blurring {} features from {} images...&#34;.format(
                len(features),
                len(self.images),
            )
        )
        out = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(prep_data_single_sample_mxif)(
                image, features, downsample_factor, sigma, fract
            )
            for image in self.images
        )
        # unpack results from parallel process
        self.images = [x[0] for x in out]
        cluster_data = [x[1] for x in out]
        # concatenate blurred features into cluster_data df for cluster training
        self.cluster_data = np.row_stack(cluster_data)
        # perform min-max scaling on final cluster data
        mms = MinMaxScaler()
        unscaled_data = self.cluster_data
        self.cluster_data = mms.fit_transform(unscaled_data)
        print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        images.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if silhouette plots should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model
        n_jobs : int
            Number of cores to parallelize k-choosing and tissue ID assignment across.
            Default all available cores.

        Returns
        -------
        Does not return anything. `self.tissue_ID` is added, containing image with
        final tissue region IDs. `self.kmeans` contains trained `sklearn` clustering
        model. Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                alpha=alpha, plot_out=plot_out, random_state=random_state, n_jobs=n_jobs
            )
        # call k-means model from parent class
        self.find_tissue_regions(random_state=random_state)
        # loop through image objects and create tissue label images
        print(&#34;Creating tissue_ID images for image objects...&#34;)
        self.tissue_IDs = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(add_tissue_ID_single_sample_mxif)(
                image, self.model_features, self.kmeans
            )
            for image in self.images
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="MILWRM.MILWRM.tissue_labeler" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.mxif_labeler.label_tissue_regions"><code class="name flex">
<span>def <span class="ident">label_tissue_regions</span></span>(<span>self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform tissue-level clustering and label pixels in the corresponding
images.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Number of tissue regions to define</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>boolean</code>, optional <code>(default=True)</code></dt>
<dd>Determines if silhouette plots should be output</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering model</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing and tissue ID assignment across.
Default all available cores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.tissue_ID</code> is added, containing image with
final tissue region IDs. <code>self.kmeans</code> contains trained <code>sklearn</code> clustering
model. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_tissue_regions(
    self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
):
    &#34;&#34;&#34;
    Perform tissue-level clustering and label pixels in the corresponding
    images.

    Parameters
    ----------
    k : int, optional (default=None)
        Number of tissue regions to define
    alpha: float
        Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
    plot_out : boolean, optional (default=True)
        Determines if silhouette plots should be output
    random_state : int, optional (default=18)
        Seed for k-means clustering model
    n_jobs : int
        Number of cores to parallelize k-choosing and tissue ID assignment across.
        Default all available cores.

    Returns
    -------
    Does not return anything. `self.tissue_ID` is added, containing image with
    final tissue region IDs. `self.kmeans` contains trained `sklearn` clustering
    model. Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    # find optimal k with parent class
    if k is None:
        print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
        self.find_optimal_k(
            alpha=alpha, plot_out=plot_out, random_state=random_state, n_jobs=n_jobs
        )
    # call k-means model from parent class
    self.find_tissue_regions(random_state=random_state)
    # loop through image objects and create tissue label images
    print(&#34;Creating tissue_ID images for image objects...&#34;)
    self.tissue_IDs = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(add_tissue_ID_single_sample_mxif)(
            image, self.model_features, self.kmeans
        )
        for image in self.images
    )</code></pre>
</details>
</dd>
<dt id="MILWRM.mxif_labeler.prep_cluster_data"><code class="name flex">
<span>def <span class="ident">prep_cluster_data</span></span>(<span>self, features, downsample_factor=8, sigma=2, fract=0.2, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare master dataframe for tissue-level clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code></dt>
<dd>Indices or names of MxIF channels to use for tissue labeling</dd>
<dt><strong><code>downsample_factor</code></strong> :&ensp;<code>int</code></dt>
<dd>Factor by which to downsample images from their original resolution</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code>, optional <code>(default=2)</code></dt>
<dd>Standard deviation of Gaussian kernel for blurring</dd>
<dt><strong><code>fract</code></strong> :&ensp;<code>float</code>, optional <code>(default=0.2)</code></dt>
<dd>Fraction of cluster data from each image to randomly select for model
building</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code>, optional <code>(default=-1)</code></dt>
<dd>Number of cores to parallelize over. Default all available cores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.images</code> are downsampled and blurred according
to user parameters. <code>self.cluster_data</code> becomes master <code>np.array</code> for cluster
training. Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_cluster_data(
    self, features, downsample_factor=8, sigma=2, fract=0.2, n_jobs=-1
):
    &#34;&#34;&#34;
    Prepare master dataframe for tissue-level clustering

    Parameters
    ----------
    features : list of int or str
        Indices or names of MxIF channels to use for tissue labeling
    downsample_factor : int
        Factor by which to downsample images from their original resolution
    sigma : float, optional (default=2)
        Standard deviation of Gaussian kernel for blurring
    fract : float, optional (default=0.2)
        Fraction of cluster data from each image to randomly select for model
        building
    n_jobs : int, optional (default=-1)
        Number of cores to parallelize over. Default all available cores.

    Returns
    -------
    Does not return anything. `self.images` are downsampled and blurred according
    to user parameters. `self.cluster_data` becomes master `np.array` for cluster
    training. Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    if self.cluster_data is not None:
        print(&#34;WARNING: overwriting existing cluster data&#34;)
        self.cluster_data = None
    # save the hyperparams as object attributes
    self.model_features = features
    self.downsample_factor = downsample_factor
    self.sigma = sigma
    # downsampling, blurring, subsampling, and compiling cluster_data in parallel
    print(
        &#34;Downsampling, log-normalizing, and blurring {} features from {} images...&#34;.format(
            len(features),
            len(self.images),
        )
    )
    out = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(prep_data_single_sample_mxif)(
            image, features, downsample_factor, sigma, fract
        )
        for image in self.images
    )
    # unpack results from parallel process
    self.images = [x[0] for x in out]
    cluster_data = [x[1] for x in out]
    # concatenate blurred features into cluster_data df for cluster training
    self.cluster_data = np.row_stack(cluster_data)
    # perform min-max scaling on final cluster data
    mms = MinMaxScaler()
    unscaled_data = self.cluster_data
    self.cluster_data = mms.fit_transform(unscaled_data)
    print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="MILWRM.MILWRM.tissue_labeler" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></b></code>:
<ul class="hlist">
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_optimal_k" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.find_optimal_k">find_optimal_k</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_tissue_regions" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.find_tissue_regions">find_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.plot_feature_loadings">plot_feature_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.plot_feature_proportions">plot_feature_proportions</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="MILWRM.st_labeler"><code class="flex name class">
<span>class <span class="ident">st_labeler</span></span>
<span>(</span><span>adatas)</span>
</code></dt>
<dd>
<div class="desc"><p>Tissue region labeling class for spatial transcriptomics (ST) data</p>
<p>Initialize ST tissue labeler class</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>adatas</code></strong> :&ensp;<code>list</code> of <code>anndata.AnnData</code></dt>
<dd>Single anndata object or list of objects to label consensus tissue regions</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> attribute is updated,
<code>self.cluster_data</code> attribute is initiated as <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class st_labeler(tissue_labeler):
    &#34;&#34;&#34;
    Tissue region labeling class for spatial transcriptomics (ST) data
    &#34;&#34;&#34;

    def __init__(self, adatas):
        &#34;&#34;&#34;
        Initialize ST tissue labeler class

        Parameters
        ----------
        adatas : list of anndata.AnnData
            Single anndata object or list of objects to label consensus tissue regions

        Returns
        -------
        Does not return anything. `self.adatas` attribute is updated,
        `self.cluster_data` attribute is initiated as `None`.
        &#34;&#34;&#34;
        tissue_labeler.__init__(self)  # initialize parent class
        if not isinstance(adatas, list):  # force single anndata object to list
            adatas = [adatas]
        print(&#34;Initiating ST labeler with {} anndata objects&#34;.format(len(adatas)))
        self.adatas = adatas

    def prep_cluster_data(
        self,
        use_rep,
        features=None,
        blur_pix=2,
        histo=False,
        fluor_channels=None,
        n_jobs=-1,
    ):
        &#34;&#34;&#34;
        Prepare master dataframe for tissue-level clustering

        Parameters
        ----------
        use_rep : str
            Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
        features : list of int or None, optional (default=`None`)
            List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
            use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
            all features from `adata.obsm[use_rep]`
        blur_pix : int, optional (default=2)
            Radius of nearest spatial transcriptomics spots to blur features by for
            capturing regional information. Assumes hexagonal spot grid (10X Genomics
            Visium platform).
        histo : bool, optional (default `False`)
            Use histology data from Visium anndata object (R,G,B brightfield features)
            in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
            than brightfield, use `fluor_channels` argument instead.
        fluor_channels : list of int or None, optional (default `None`)
            Channels from fluorescent image to use for model training (e.g. [1,3] for
            channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
            use imaging data for training.
        n_jobs : int, optional (default=-1)
            Number of cores to parallelize over. Default all available cores.

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;blur_*&#34; features
        to `.obs`. `self.cluster_data` becomes master `np.array` for cluster training.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        if self.cluster_data is not None:
            print(&#34;WARNING: overwriting existing cluster data&#34;)
            self.cluster_data = None
        if features is None:
            self.features = [x for x in range(self.adatas[0].obsm[use_rep].shape[1])]
        else:
            self.features = features
        # save the hyperparams as object attributes
        self.rep = use_rep
        self.histo = histo
        self.flour_channels = fluor_channels
        self.blur_pix = blur_pix
        # collect clustering data from self.adatas in parallel
        print(
            &#34;Collecting and blurring {} features from .obsm[{}]...&#34;.format(
                len(features),
                use_rep,
            )
        )
        cluster_data = Parallel(n_jobs=n_jobs, verbose=10)(
            delayed(prep_data_single_sample_st)(
                adata, adata_i, use_rep, features, blur_pix, histo, fluor_channels
            )
            for adata_i, adata in enumerate(self.adatas)
        )
        # concatenate blurred features into cluster_data df for cluster training
        self.cluster_data = pd.concat(cluster_data)
        # perform min-max scaling on final cluster data
        mms = MinMaxScaler()
        unscaled_data = self.cluster_data.values
        self.cluster_data = mms.fit_transform(unscaled_data)
        print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))

    def label_tissue_regions(
        self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
    ):
        &#34;&#34;&#34;
        Perform tissue-level clustering and label pixels in the corresponding
        `anndata` objects.

        Parameters
        ----------
        k : int, optional (default=None)
            Number of tissue regions to define
        alpha: float
            Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
        plot_out : boolean, optional (default=True)
            Determines if silhouette plots should be output
        random_state : int, optional (default=18)
            Seed for k-means clustering model.
        n_jobs : int
            Number of cores to parallelize k-choosing across

        Returns
        -------
        Does not return anything. `self.adatas` are updated, adding &#34;tissue_ID&#34; field
        to `.obs`. `self.kmeans` contains trained `sklearn` clustering model.
        Parameters are also captured as attributes for posterity.
        &#34;&#34;&#34;
        # find optimal k with parent class
        if k is None:
            print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
            self.find_optimal_k(
                plot_out=plot_out, alpha=alpha, random_state=random_state, n_jobs=n_jobs
            )
        # call k-means model from parent class
        self.find_tissue_regions(k=k, random_state=random_state)
        # loop through anndata object and add tissue labels to adata.obs dataframe
        start = 0
        print(&#34;Adding tissue_ID label to anndata objects&#34;)
        for i in range(len(self.adatas)):
            IDs = self.kmeans.labels_
            self.adatas[i].obs[&#34;tissue_ID&#34;] = IDs[start : start + self.adatas[i].n_obs]
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].astype(&#34;category&#34;)
            )
            self.adatas[i].obs[&#34;tissue_ID&#34;] = (
                self.adatas[i].obs[&#34;tissue_ID&#34;].cat.set_categories(np.unique(IDs))
            )
            start += self.adatas[i].n_obs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="MILWRM.MILWRM.tissue_labeler" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="MILWRM.st_labeler.label_tissue_regions"><code class="name flex">
<span>def <span class="ident">label_tissue_regions</span></span>(<span>self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform tissue-level clustering and label pixels in the corresponding
<code>anndata</code> objects.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code>, optional <code>(default=None)</code></dt>
<dd>Number of tissue regions to define</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters</dd>
<dt><strong><code>plot_out</code></strong> :&ensp;<code>boolean</code>, optional <code>(default=True)</code></dt>
<dd>Determines if silhouette plots should be output</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional <code>(default=18)</code></dt>
<dd>Seed for k-means clustering model.</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of cores to parallelize k-choosing across</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> are updated, adding "tissue_ID" field
to <code>.obs</code>. <code>self.kmeans</code> contains trained <code>sklearn</code> clustering model.
Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_tissue_regions(
    self, k=None, alpha=0.05, plot_out=True, random_state=18, n_jobs=-1
):
    &#34;&#34;&#34;
    Perform tissue-level clustering and label pixels in the corresponding
    `anndata` objects.

    Parameters
    ----------
    k : int, optional (default=None)
        Number of tissue regions to define
    alpha: float
        Manually tuned factor on [0.0, 1.0] that penalizes the number of clusters
    plot_out : boolean, optional (default=True)
        Determines if silhouette plots should be output
    random_state : int, optional (default=18)
        Seed for k-means clustering model.
    n_jobs : int
        Number of cores to parallelize k-choosing across

    Returns
    -------
    Does not return anything. `self.adatas` are updated, adding &#34;tissue_ID&#34; field
    to `.obs`. `self.kmeans` contains trained `sklearn` clustering model.
    Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    # find optimal k with parent class
    if k is None:
        print(&#34;Determining optimal cluster number k via scaled inertia&#34;)
        self.find_optimal_k(
            plot_out=plot_out, alpha=alpha, random_state=random_state, n_jobs=n_jobs
        )
    # call k-means model from parent class
    self.find_tissue_regions(k=k, random_state=random_state)
    # loop through anndata object and add tissue labels to adata.obs dataframe
    start = 0
    print(&#34;Adding tissue_ID label to anndata objects&#34;)
    for i in range(len(self.adatas)):
        IDs = self.kmeans.labels_
        self.adatas[i].obs[&#34;tissue_ID&#34;] = IDs[start : start + self.adatas[i].n_obs]
        self.adatas[i].obs[&#34;tissue_ID&#34;] = (
            self.adatas[i].obs[&#34;tissue_ID&#34;].astype(&#34;category&#34;)
        )
        self.adatas[i].obs[&#34;tissue_ID&#34;] = (
            self.adatas[i].obs[&#34;tissue_ID&#34;].cat.set_categories(np.unique(IDs))
        )
        start += self.adatas[i].n_obs</code></pre>
</details>
</dd>
<dt id="MILWRM.st_labeler.prep_cluster_data"><code class="name flex">
<span>def <span class="ident">prep_cluster_data</span></span>(<span>self, use_rep, features=None, blur_pix=2, histo=False, fluor_channels=None, n_jobs=-1)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare master dataframe for tissue-level clustering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>use_rep</code></strong> :&ensp;<code>str</code></dt>
<dd>Representation from <code>adata.obsm</code> to use as clustering data (e.g. "X_pca")</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default=</code>None<code>)</code></dt>
<dd>List of features to use from <code>adata.obsm[use_rep]</code> (e.g. [0,1,2,3,4] to
use first 5 principal components when <code>use_rep</code>="X_pca"). If <code>None</code>, use
all features from <code>adata.obsm[use_rep]</code></dd>
<dt><strong><code>blur_pix</code></strong> :&ensp;<code>int</code>, optional <code>(default=2)</code></dt>
<dd>Radius of nearest spatial transcriptomics spots to blur features by for
capturing regional information. Assumes hexagonal spot grid (10X Genomics
Visium platform).</dd>
<dt><strong><code>histo</code></strong> :&ensp;<code>bool</code>, optional <code>(default </code>False<code>)</code></dt>
<dd>Use histology data from Visium anndata object (R,G,B brightfield features)
in addition to <code>adata.obsm[use_rep]</code>? If fluorescent imaging data rather
than brightfield, use <code>fluor_channels</code> argument instead.</dd>
<dt><strong><code>fluor_channels</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>None</code>, optional <code>(default </code>None<code>)</code></dt>
<dd>Channels from fluorescent image to use for model training (e.g. [1,3] for
channels 1 and 3 of Visium fluorescent imaging data). If <code>None</code>, do not
use imaging data for training.</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code>, optional <code>(default=-1)</code></dt>
<dd>Number of cores to parallelize over. Default all available cores.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Does not return anything. <code>self.adatas</code> are updated, adding "blur_*" features
to <code>.obs</code>. <code>self.cluster_data</code> becomes master <code>np.array</code> for cluster training.
Parameters are also captured as attributes for posterity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prep_cluster_data(
    self,
    use_rep,
    features=None,
    blur_pix=2,
    histo=False,
    fluor_channels=None,
    n_jobs=-1,
):
    &#34;&#34;&#34;
    Prepare master dataframe for tissue-level clustering

    Parameters
    ----------
    use_rep : str
        Representation from `adata.obsm` to use as clustering data (e.g. &#34;X_pca&#34;)
    features : list of int or None, optional (default=`None`)
        List of features to use from `adata.obsm[use_rep]` (e.g. [0,1,2,3,4] to
        use first 5 principal components when `use_rep`=&#34;X_pca&#34;). If `None`, use
        all features from `adata.obsm[use_rep]`
    blur_pix : int, optional (default=2)
        Radius of nearest spatial transcriptomics spots to blur features by for
        capturing regional information. Assumes hexagonal spot grid (10X Genomics
        Visium platform).
    histo : bool, optional (default `False`)
        Use histology data from Visium anndata object (R,G,B brightfield features)
        in addition to `adata.obsm[use_rep]`? If fluorescent imaging data rather
        than brightfield, use `fluor_channels` argument instead.
    fluor_channels : list of int or None, optional (default `None`)
        Channels from fluorescent image to use for model training (e.g. [1,3] for
        channels 1 and 3 of Visium fluorescent imaging data). If `None`, do not
        use imaging data for training.
    n_jobs : int, optional (default=-1)
        Number of cores to parallelize over. Default all available cores.

    Returns
    -------
    Does not return anything. `self.adatas` are updated, adding &#34;blur_*&#34; features
    to `.obs`. `self.cluster_data` becomes master `np.array` for cluster training.
    Parameters are also captured as attributes for posterity.
    &#34;&#34;&#34;
    if self.cluster_data is not None:
        print(&#34;WARNING: overwriting existing cluster data&#34;)
        self.cluster_data = None
    if features is None:
        self.features = [x for x in range(self.adatas[0].obsm[use_rep].shape[1])]
    else:
        self.features = features
    # save the hyperparams as object attributes
    self.rep = use_rep
    self.histo = histo
    self.flour_channels = fluor_channels
    self.blur_pix = blur_pix
    # collect clustering data from self.adatas in parallel
    print(
        &#34;Collecting and blurring {} features from .obsm[{}]...&#34;.format(
            len(features),
            use_rep,
        )
    )
    cluster_data = Parallel(n_jobs=n_jobs, verbose=10)(
        delayed(prep_data_single_sample_st)(
            adata, adata_i, use_rep, features, blur_pix, histo, fluor_channels
        )
        for adata_i, adata in enumerate(self.adatas)
    )
    # concatenate blurred features into cluster_data df for cluster training
    self.cluster_data = pd.concat(cluster_data)
    # perform min-max scaling on final cluster data
    mms = MinMaxScaler()
    unscaled_data = self.cluster_data.values
    self.cluster_data = mms.fit_transform(unscaled_data)
    print(&#34;Collected clustering data of shape: {}&#34;.format(self.cluster_data.shape))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="MILWRM.MILWRM.tissue_labeler" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler">tissue_labeler</a></b></code>:
<ul class="hlist">
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_optimal_k" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.find_optimal_k">find_optimal_k</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.find_tissue_regions" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.find_tissue_regions">find_tissue_regions</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_loadings" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.plot_feature_loadings">plot_feature_loadings</a></code></li>
<li><code><a title="MILWRM.MILWRM.tissue_labeler.plot_feature_proportions" href="MILWRM.html#MILWRM.MILWRM.tissue_labeler.plot_feature_proportions">plot_feature_proportions</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="MILWRM.MILWRM" href="MILWRM.html">MILWRM.MILWRM</a></code></li>
<li><code><a title="MILWRM.MxIF" href="MxIF.html">MILWRM.MxIF</a></code></li>
<li><code><a title="MILWRM.ST" href="ST.html">MILWRM.ST</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="MILWRM.assemble_pita" href="#MILWRM.assemble_pita">assemble_pita</a></code></li>
<li><code><a title="MILWRM.map_pixels" href="#MILWRM.map_pixels">map_pixels</a></code></li>
<li><code><a title="MILWRM.show_pita" href="#MILWRM.show_pita">show_pita</a></code></li>
<li><code><a title="MILWRM.trim_image" href="#MILWRM.trim_image">trim_image</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="MILWRM.img" href="#MILWRM.img">img</a></code></h4>
<ul class="two-column">
<li><code><a title="MILWRM.img.clip" href="#MILWRM.img.clip">clip</a></code></li>
<li><code><a title="MILWRM.img.downsample" href="#MILWRM.img.downsample">downsample</a></code></li>
<li><code><a title="MILWRM.img.from_npz" href="#MILWRM.img.from_npz">from_npz</a></code></li>
<li><code><a title="MILWRM.img.from_tiffs" href="#MILWRM.img.from_tiffs">from_tiffs</a></code></li>
<li><code><a title="MILWRM.img.log_normalize" href="#MILWRM.img.log_normalize">log_normalize</a></code></li>
<li><code><a title="MILWRM.img.scale" href="#MILWRM.img.scale">scale</a></code></li>
<li><code><a title="MILWRM.img.show" href="#MILWRM.img.show">show</a></code></li>
<li><code><a title="MILWRM.img.to_npz" href="#MILWRM.img.to_npz">to_npz</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="MILWRM.mxif_labeler" href="#MILWRM.mxif_labeler">mxif_labeler</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.mxif_labeler.label_tissue_regions" href="#MILWRM.mxif_labeler.label_tissue_regions">label_tissue_regions</a></code></li>
<li><code><a title="MILWRM.mxif_labeler.prep_cluster_data" href="#MILWRM.mxif_labeler.prep_cluster_data">prep_cluster_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="MILWRM.st_labeler" href="#MILWRM.st_labeler">st_labeler</a></code></h4>
<ul class="">
<li><code><a title="MILWRM.st_labeler.label_tissue_regions" href="#MILWRM.st_labeler.label_tissue_regions">label_tissue_regions</a></code></li>
<li><code><a title="MILWRM.st_labeler.prep_cluster_data" href="#MILWRM.st_labeler.prep_cluster_data">prep_cluster_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>